{"version":3,"file":"js/sigin.1345ebbe.js","mappings":"6KAAA,IAAIA,EAAS,WAAkB,IAAIC,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACE,YAAY,2BAA2B,CAACF,EAAG,MAAM,CAACE,YAAY,WAAW,CAACF,EAAG,OAAO,CAACE,YAAY,8EAA8EC,GAAG,CAAC,OAAS,SAASC,GAAgC,OAAxBA,EAAOC,iBAAwBP,EAAIQ,OAAOC,MAAM,KAAMC,UAAU,IAAI,CAACR,EAAG,KAAK,CAACE,YAAY,UAAU,CAACJ,EAAIW,GAAG,eAAeT,EAAG,QAAQ,CAACE,YAAY,kBAAkBQ,MAAM,CAAC,IAAM,UAAU,CAACZ,EAAIW,GAAG,WAAWT,EAAG,QAAQ,CAACW,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOhB,EAAIiB,MAAOC,WAAW,UAAUd,YAAY,mDAAmDQ,MAAM,CAAC,GAAK,QAAQ,KAAO,QAAQ,KAAO,QAAQ,YAAc,qBAAqBO,SAAS,CAAC,MAASnB,EAAIiB,OAAQZ,GAAG,CAAC,MAAQ,SAASC,GAAWA,EAAOc,OAAOC,YAAiBrB,EAAIiB,MAAMX,EAAOc,OAAOJ,MAAK,KAAKd,EAAG,QAAQ,CAACE,YAAY,kBAAkBQ,MAAM,CAAC,IAAM,aAAa,CAACZ,EAAIW,GAAG,cAAcT,EAAG,QAAQ,CAACW,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOhB,EAAIsB,SAAUJ,WAAW,aAAad,YAAY,mDAAmDQ,MAAM,CAAC,GAAK,WAAW,KAAO,WAAW,KAAO,WAAW,YAAc,YAAYO,SAAS,CAAC,MAASnB,EAAIsB,UAAWjB,GAAG,CAAC,MAAQ,SAASC,GAAWA,EAAOc,OAAOC,YAAiBrB,EAAIsB,SAAShB,EAAOc,OAAOJ,MAAK,KAAKd,EAAG,SAAS,CAACE,YAAY,oHAAoHQ,MAAM,CAAC,KAAO,WAAW,CAACZ,EAAIW,GAAG,oBACn+C,EACIY,EAAkB,G,oBCqCtB,GACAC,KAAAA,KAAAA,CACAP,MAAAA,GACAK,SAAAA,KAEAG,QAAAA,CACA,eACA,kBACA,yDACA,0BAEA,kDACA,cAAAC,KAAAA,QAAAC,KAAAA,0BACA,cACA,mBAEA,mBAAAC,KAAAA,cAAAA,EAAAA,WAAAC,OAAAA,IACA,cAAAH,KAAAA,UAAAC,KAAAA,uBAPA,cAAAD,KAAAA,QAAAC,KAAAA,gCAUA,IC3D0P,I,UCOtPG,GAAY,OACd,EACA/B,EACAwB,GACA,EACA,KACA,KACA,MAIF,EAAeO,EAAiB,O,iFClBhC,IAAI/B,EAAS,WAAkB,IAAIC,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACE,YAAY,2BAA2B,CAACF,EAAG,MAAM,CAACE,YAAY,WAAW,CAACF,EAAG,OAAO,CAACE,YAAY,8EAA8EC,GAAG,CAAC,OAAS,SAASC,GAAgC,OAAxBA,EAAOC,iBAAwBP,EAAI+B,OAAOtB,MAAM,KAAMC,UAAU,IAAI,CAACR,EAAG,KAAK,CAACE,YAAY,UAAU,CAACJ,EAAIW,GAAG,eAAeT,EAAG,QAAQ,CAACE,YAAY,kBAAkBQ,MAAM,CAAC,IAAM,SAAS,CAACZ,EAAIW,GAAG,UAAUT,EAAG,QAAQ,CAACW,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOhB,EAAIgC,SAAUd,WAAW,aAAad,YAAY,mDAAmDQ,MAAM,CAAC,GAAK,OAAO,KAAO,OAAO,KAAO,OAAO,YAAc,YAAYO,SAAS,CAAC,MAASnB,EAAIgC,UAAW3B,GAAG,CAAC,MAAQ,SAASC,GAAWA,EAAOc,OAAOC,YAAiBrB,EAAIgC,SAAS1B,EAAOc,OAAOJ,MAAK,KAAKd,EAAG,QAAQ,CAACE,YAAY,kBAAkBQ,MAAM,CAAC,IAAM,UAAU,CAACZ,EAAIW,GAAG,WAAWT,EAAG,QAAQ,CAACW,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOhB,EAAIiB,MAAOC,WAAW,UAAUd,YAAY,mDAAmDQ,MAAM,CAAC,GAAK,QAAQ,KAAO,QAAQ,KAAO,QAAQ,YAAc,qBAAqBO,SAAS,CAAC,MAASnB,EAAIiB,OAAQZ,GAAG,CAAC,MAAQ,SAASC,GAAWA,EAAOc,OAAOC,YAAiBrB,EAAIiB,MAAMX,EAAOc,OAAOJ,MAAK,KAAKd,EAAG,QAAQ,CAACE,YAAY,kBAAkBQ,MAAM,CAAC,IAAM,aAAa,CAACZ,EAAIW,GAAG,cAAcT,EAAG,QAAQ,CAACW,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOhB,EAAIsB,SAAUJ,WAAW,aAAad,YAAY,mDAAmDQ,MAAM,CAAC,GAAK,WAAW,KAAO,WAAW,KAAO,WAAW,YAAc,YAAYO,SAAS,CAAC,MAASnB,EAAIsB,UAAWjB,GAAG,CAAC,MAAQ,SAASC,GAAWA,EAAOc,OAAOC,YAAiBrB,EAAIsB,SAAShB,EAAOc,OAAOJ,MAAK,KAAKd,EAAG,SAAS,CAACE,YAAY,oHAAoHQ,MAAM,CAAC,KAAO,WAAW,CAACZ,EAAIW,GAAG,eAAeX,EAAIiC,GAAG,QAC97D,EACIV,EAAkB,CAAC,WAAY,IAAIvB,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,IAAI,CAACF,EAAIW,GAAG,6BAA6BT,EAAG,IAAI,CAACE,YAAY,aAAaQ,MAAM,CAAC,KAAO,YAAY,CAACZ,EAAIW,GAAG,cACtL,G,oBC+CA,GACAG,KAAAA,SACAU,KAAAA,KAAAA,CACAQ,SAAAA,GACAf,MAAAA,GACAK,SAAAA,KAEAG,QAAAA,CACA,eACA,kBACA,+DACA,UACA,mBACAO,SAAAA,KAAAA,SACAV,SAAAA,KAAAA,SACAL,MAAAA,KAAAA,QACA,UACA,mBAAAW,KAAAA,cAAAA,EAAAA,WAAAC,OAAAA,GAAA,IAEA,cAAAH,KAAAA,UAAAC,KAAAA,iCAGA,ICxE0P,I,UCOtPG,GAAY,OACd,EACA/B,EACAwB,GACA,EACA,KACA,KACA,MAIF,EAAeO,EAAiB,O,mBClBhC,SAASI,EAAyBC,GAGjC,OAAOC,QAAQC,UAAUC,MAAK,WAC7B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBL,EAAM,KAEjD,MADAI,EAAEE,KAAO,mBACHF,CACP,GACD,CACAL,EAAyBQ,KAAO,WAAa,MAAO,EAAI,EACxDR,EAAyBG,QAAUH,EACnCA,EAAyBS,GAAK,KAC9BC,EAAOC,QAAUX,C,qFCJV,MAAMY,EAA8BC,MACzCC,EACAC,EACAC,UAEaD,EAAG,CACdE,cAAe,KACP,IAKCC,EAAkB,CAC7BC,KAAM,kBAENC,QAAS,mBAETC,MAAO,aAEPC,gBAAiB,kBACjBC,iBAAkB,mBAClBC,UAAW,YACXC,YAAa,cACbC,gBAAiB,kBACjBC,YAAa,cACbC,SAAU,WACVC,WAAY,aACZC,YAAa,eCnCf,SAASC,EAAYjD,GACZ,OAAU,OAAVA,QAA4B,IAAVA,CAC3B,CAEO,SAASkD,EAAWC,GAClB,OAAAA,EAAIC,OAAOH,EACpB,CAQO,SAASI,EAASrD,GAChB,OAAAsD,QAAQtD,IAA2B,kBAAVA,IAAuBuD,MAAMC,QAAQxD,EACvE,CAEO,SAASyD,EAAazD,GACpB,OAAU,OAAVA,QAA4B,IAAVA,CAC3B,CAEO,SAAS0D,EAAS1D,GACvB,OAAOyD,EAAUzD,IAA2B,kBAAVA,CACpC,CAEO,SAAS2D,EAAc3D,GACrB,OAAAyD,EAAUzD,IAAUuD,MAAMC,QAAQxD,IAAUA,EAAM4D,MAAMF,EACjE,CAEO,SAASG,EAAS7D,GACvB,OAAOyD,EAAUzD,IAA2B,kBAAVA,CACpC,CAEO,SAAS8D,EAAS9D,GACnB,IACF,OAAO+D,KAAK/D,EAG4B,CAHvB,MACVgE,GACP,MAAMC,EAAMC,OACZ,OAAOD,EAAIE,KAAKnE,GAAOoE,SAAS,SAAQ,CAE5C,CAEgB,SAAAC,EAAwEC,EAAMC,GACtF,MAAAC,EAA8B,IAAKF,GAEzC,IAAK,MAAOG,EAAKzE,KAAU0E,OAAOC,QAAQJ,GACpClB,EAASrD,IAAUqD,EAASmB,EAAOC,IACrCD,EAAOC,GAAOJ,EAAUG,EAAOC,GAAMzE,GAErCwE,EAAOC,GAAOzE,EAIX,OAAAwE,CACT,CCtCO,SAASI,IAEV,IACF,GAAIvB,EAASwB,UAAYxB,EAAS,sCACzB,OACLyB,OAAQ,qCAAYC,cAAgBC,IACpCC,YAAa,qCAAYC,mBAAqBC,IAC9CC,OAAQ,qCAAYC,aAAeC,IACnCC,UAAWV,CAAAA,SAAAA,aAAAA,SAAAA,KAAYW,uBAAyBX,CAAAA,SAAAA,aAAAA,SAAAA,KAAYY,iBAAmBZ,CAAAA,SAAAA,aAAAA,SAAAA,KAAYa,OAC3FC,eAAgB,qCAAYC,sBAAwBC,IAGxD,CADA,MACO7B,GAAP,CAIE,IAEF,GAAIX,EAASyC,OAASzC,EAASyC,KAAKC,KAC3B,OACLjB,OAAQgB,KAAKC,IAAIC,IAAI,iBAAmBhB,IACxCC,YAAaa,KAAKC,IAAIC,IAAI,sBAAwBb,IAClDC,OAAQU,KAAKC,IAAIC,IAAI,gBAAkBV,IACvCC,UAAWO,KAAKC,IAAIC,IAAI,0BAA4BF,KAAKC,IAAIC,IAAI,oBAAsBF,KAAKC,IAAIC,IAAI,UACpGL,eAAgBG,KAAKC,IAAIC,IAAI,yBAA2BH,IAG5D,CADA,MACO7B,GAAP,CAIK,OACLc,OAAQE,IACRC,YAAaE,IACbC,OAAQE,IACRC,eAAW,EACXI,eAAgBE,IAEpB,CAEA,SAASb,IACH,IACK,OAAAD,YAEA,CAFA,MACAf,GACA,OAEX,CAEA,SAASmB,IACH,IACK,OAAAD,iBAEA,CAFA,MACAlB,GACA,OAEX,CAEA,SAASsB,IACH,IACK,OAAAD,WAEA,CAFA,MACArB,GACA,OAEX,CAEA,SAAS6B,IACH,IACK,OAAAD,oBAEA,CAFA,MACA5B,GACA,OAEX,CAEA,eAAsBiC,IACpB,MAAMC,EAAM,CAAC,MAAO,SAAU,kBACxBC,EAAUD,EAAIE,KAAK,KAGnBC,EAAa,CAAC,QAAS,WAAWD,KAAK,KAEvCE,EAAc,CAAEC,SAAU,QAASC,MAAO,CAAC,SAAU,OAAQ,WAG/D,IAEE,GAAmB,oBAAZC,QAET,OAAOA,QAAQJ,GAAYK,SAASP,EAASG,GAAaK,OAI5D,MAAM,SAAED,SAAmB,QAAOL,GAClC,OAAOK,EAASP,EAASG,GAAalC,WAAWuC,MACjD,CADsD,MAC/C3C,GAAP,CAKE,IACE,GAAAX,EAASyC,MAAO,CACZjB,MAAAA,EAAUiB,KAAKc,IAAI,CAAEV,MAAKW,OAAQ,QAASC,OAAQ,SAClD,WAAIC,aAAcC,aAAanC,EAAQoC,UAAUN,MAAK,CAE/D,CADA,MACO3C,GAAP,CAGJ,CCxHO,SAASkD,IACV,IACI,aAAEpC,GAAWF,IACZ,OAAAE,CAEA,CAFA,MACAd,GACA,OAEX,CCPO,SAASmD,EAAuBC,GACrC,MAAMC,EAA+B,qBAAVC,MAAwBA,WAAQ,EACrDC,EAAYH,GAAaC,EAC/B,IAAKE,EAEH,MAAM,IAAI/F,MACR,sGAGG,OAAA+F,CACT,CCZO,MAAMjF,EAAU,SCIvB,MAAMkF,UAAuBhG,MAG3BiG,YAAYC,EAAkBC,GAE5BC,MAAMF,EAASC,EAAO,EAInB,MAAME,UAAqBL,EAKhCC,YAAYK,EAAgBtH,EAAgBuH,GACpC,MAAAC,EAAWxH,IAEjBvB,KAAK6I,OAASA,EACd7I,KAAKgJ,OAASC,EAAY1H,GAAQA,EAAKyH,YAAS,EAChDhJ,KAAK8I,UAAYA,EAEbvH,aAAgBgB,QAClBvC,KAAKkJ,MAAQ3H,EAAK2H,MAClBlJ,KAAKmJ,MAAS5H,EAAwB4H,MACxC,CAGFhE,WACQ,MAAAiE,EAAQT,MAAMxD,WAEpB,MAAW,IAAAnF,KAAK6I,YAAY7I,KAAK8I,WAAa,eAAeM,GAAA,EAUjE,SAASH,EAAYG,GACnB,OAAOhF,EAASgF,IAAU9E,MAAMC,QAAQ6E,EAAMJ,OAChD,CAEA,SAASK,EACPD,GAEA,OAAOhF,EAASgF,IAAU3E,EAAS2E,EAAMX,QAC3C,CAEA,SAASM,EAAWxH,GAClB,OAAIA,aAAgBgB,MACXhB,EAAKkH,QACHhE,EAASlD,GACXA,EACE8H,EAAmB9H,GACrBA,EAAKkH,QACHQ,EAAY1H,GACd,wBAEA,kBAEX,CC7DA,MAAM+H,EAAa,CACjBC,EACAC,EAAmC,CAAC,EACpCC,EAAuD,CAAC,KAGlD,MAAAC,EAAmBjE,OAAOC,QAAQ8D,GAAaG,QAAQ,CAAAC,GAAMpE,EAAKzE,UACxD,IAAVA,GAAiC,OAAVA,EAAuB6I,EAC3C,IAAKA,EAAK,CAACpE,GAAMzE,IACvB,CAAC,GAEE8I,EAAQ,IAAIC,gBAAgBJ,GAAkBvE,WAC9C4E,EAAcF,EAAMG,OAAS,EAAI,IAAIH,IAAU,GAI/CI,EAAkBxE,OAAOC,QAAQ+D,GAAYE,QAAQ,CAAAC,GAAMpE,EAAKzE,MAC7D,IAAK6I,EAAK,CAACpE,GAAM0E,mBAAmBC,OAAOpJ,GAAS,KAAKqJ,QAAQ,MAAO,QAC9E,CAAC,GAEG,OAAAb,EAAIa,QAAQ,YAAa5E,GAAQyE,EAAgBzE,EAAI6E,MAAM,GAAK,MAAMN,CAAA,EA0C/E,SAASO,GAAa,SACpBC,EAAQ,KACR5I,EAAI,iBACJ6I,EAAgB,OAChBC,EAAM,WACNhB,EAAa,CAAC,IAQd,GAAiB,cAAbc,EAA0B,CACtB,MAAAhB,EAAM9E,EAAS+F,GAAoB,GAAGA,IAAmB7I,IAAS6I,EAAiB7I,EAAM8H,GAEzFiB,EAAmBjG,EAASgF,EAAWkB,WACzCpB,EAAIa,QAAQ,gBAAiBD,OAAOV,EAAWkB,YAC/CpB,EAEG,OAAA9E,EAASgF,EAAWmB,QACvBF,EAAiBN,QAAQ,WAAYD,OAAOV,EAAWmB,SACvDF,CAAA,CAGN,MAAO,GAAGD,IAAS9I,GACrB,CAIA,SAASkJ,EAAWtB,GAClB,MAAMuB,EAAU,2BACV,OAAEC,GAAWD,EAAQE,KAAKzB,IAAQ,CAAC,EAEzC,OAAOwB,GAAQE,KAAO,CAAEC,KAAMH,EAAOE,MAAS,CAAC,CACjD,CAEA,eAAsB5C,GAQpBkB,IAAK5H,EAAA,OACLwJ,EAAM,KACNC,EAAI,QACJC,EAAO,WACP5B,EAAU,YACVD,EAAW,UACXlB,EAAS,OACTzC,EAAM,SACN0E,EAAQ,OACRE,EAAM,iBACND,EAAgB,MAChBc,EAAK,OACLC,EAAM,SACNC,EAAQ,UACRC,IAEO,OAAAH,EACL,GAAGH,EAAOO,iBAAiB/J,KAC3BmB,OAASI,oBACD,MAAAyI,EAAUrB,EAAa,CAAEC,WAAU5I,OAAM6I,mBAAkBf,aAAYgB,WACvEmB,EAAUtC,EAAWqC,EAASnC,EAAaC,GAI3CF,EAAMqC,EAAQC,SAAS,aAAeD,EAAQxB,QAAQ,WAAY,WAAawB,EACvE1I,EAAAA,CACZ,CAACC,EAAgBU,UAAW0F,EAC5B,CAACpG,EAAgBY,aAAcuF,EAAW3H,EAAM6H,EAAaC,KAGzD,MAAAqC,QAAiBxD,EAAUiB,EAAK,CACpC4B,OAAQA,EAAOO,cACfN,KAAMA,EAAOW,KAAKC,UAAUZ,QAAQ,EACpCC,QAAS,CACP,eAAgB,mBAChB,aAAgC,kBAAAhI,IAChC,mBAAoBmI,GAAY,GAChC,oBAAqBC,GAAa,MAC/BJ,KACAR,EAAWe,GACdK,cAAyB,UAAApG,KAE3B0F,WAIE,GAAoB,MAApBO,EAASjD,OACX,MAAO,CAAC,EAGV,MAAM,KAAEoC,EAAMiB,SAAAA,GAAaC,EAASL,EAASvC,KACvCT,EAAYgD,EAAST,SAAStE,IAAI,sBAAmB,EAC7C7D,EAAAA,CACZ,CAACC,EAAgBC,MAAO,OACxB,CAACD,EAAgBI,iBAAkBuF,EACnC,CAAC3F,EAAgBK,kBAAmBsI,EAASjD,OAC7C,CAAC1F,EAAgBM,WAAYwH,EAC7B,CAAC9H,EAAgBO,aAAcwI,GAAU9B,QAAQ,IAAK,MAGpD,IACI,MAAAgC,QAAqBN,EAASO,OAEpC,GAAIP,EAASQ,GACJ,OAAAF,EAGT,MAAM,IAAIxD,EAAakD,EAASjD,OAAQuD,EAAmCtD,EAEnB,CAF4B,MAC7EM,GACP,MAAM,IAAIR,EAAakD,EAASjD,OAAQO,EAAON,EAAS,IAG5D,CAAE,CAAC3F,EAAgBS,aAAcuH,EAAOO,cAAe,CAACvI,EAAgBW,YAAanC,GAEzF,CAEA,SAASwK,EAAS5C,GACZ,IACF,MAAM,KAAE0B,EAAMiB,SAAAA,GAAa,IAAIK,IAAIhD,GAE5B,OAAE0B,OAAMiB,WAEP,CAFgB,MACjB9C,GACP,MAAO,CAAC,EAEZ,CCzKa,MAAAoD,EAAiB1J,SAU5B,EAAiE,IAAK4F,EAAS6B,SAAU,cCJ9EkC,EAA4B,CAACC,EAA+CnB,IACvFiB,EAOE,CAAEjD,IAAK,OAAQ4B,OAAQ,SAAUuB,EAAWnB,WAiCnCoB,EAAgB,CAACD,EAAmCnB,IAC/DiB,EAA6G,CAC3GjD,IAAK,gBACL4B,OAAQ,SACLuB,EACHnB,WAmDSqB,EAA2B,CAACF,EAA8CnB,IACrFiB,EAOE,CAAEjD,IAAK,gBAAiB4B,OAAQ,SAAUuB,EAAWnB,WAqC5CsB,EAA2B,CAACH,EAA8CnB,IACrFiB,EAOE,CAAEjD,IAAK,gBAAiB4B,OAAQ,YAAauB,EAAWnB,WAiC/CuB,EAAgC,CAC3CJ,EACAnB,IAEAiB,EAOE,CAAEjD,IAAK,yBAA0B4B,OAAQ,SAAUuB,EAAWnB,WA2CrDwB,EAAmC,CAC9CL,EACAnB,IAEAiB,EAOE,CAAEjD,IAAK,yBAA0B4B,OAAQ,WAAYuB,EAAWnB,WA8BvDyB,EAAmB,CAACN,EAAsCnB,IACrEiB,EAAuG,CACrGjD,IAAK,qBACL4B,OAAQ,SACLuB,EACHnB,WAyDS0B,EAAe,CAACP,EAAkCnB,IAC7DiB,EAOE,CAAEjD,IAAK,qBAAsB4B,OAAQ,SAAUuB,EAAWnB,WAqCjD2B,EAAe,CAACR,EAAkCnB,IAC7DiB,EAAmG,CACjGjD,IAAK,qBACL4B,OAAQ,YACLuB,EACHnB,WAmCS4B,EAAuB,CAACT,EAA0CnB,IAC7EiB,EAAqH,CACnHjD,IAAK,8BACL4B,OAAQ,SACLuB,EACHnB,WA+BS6B,EAAoB,CAACV,EAAuCnB,IACvEiB,EAA+G,CAC7GjD,IAAK,8BACL4B,OAAQ,SACLuB,EACHnB,WA8CS8B,EAAiB,CAACX,EAAoCnB,IACjEiB,EAAyG,CACvGjD,IAAK,2BACL4B,OAAQ,SACLuB,EACHnB,WAmDS+B,EAAwB,CAACZ,EAA2CnB,IAC/EiB,EAOE,CAAEjD,IAAK,4BAA6B4B,OAAQ,SAAUuB,EAAWnB,WA4DxDgC,EAAsB,CAACb,EAAyCnB,IAC3EiB,EAOE,CAAEjD,IAAK,4BAA6B4B,OAAQ,UAAWuB,EAAWnB,WA2CzDiC,EAAyB,CAACd,EAA4CnB,IACjFiB,EAOE,CAAEjD,IAAK,4BAA6B4B,OAAQ,YAAauB,EAAWnB,WAuE3DkC,EAAgB,CAACf,EAAmCnB,IAC/DiB,EAOE,CAAEjD,IAAK,8BAA+B4B,OAAQ,SAAUuB,EAAWnB,WAyC1DmC,EAA4B,CAAChB,EAA+CnB,IACvFiB,EAOE,CAAEjD,IAAK,gCAAiC4B,OAAQ,SAAUuB,EAAWnB,WAkC5DoC,EAAyB,CAACjB,EAA4CnB,IACjFiB,EAOE,CAAEjD,IAAK,qCAAsC4B,OAAQ,UAAWuB,EAAWnB,WAuClEqC,EAA6B,CAAClB,EAAgDnB,IACzFiB,EAOE,CAAEjD,IAAK,wCAAyC4B,OAAQ,UAAWuB,EAAWnB,WA2CrEsC,EAAyB,CAACnB,EAA4CnB,IACjFiB,EAOE,CAAEjD,IAAK,iCAAkC4B,OAAQ,UAAWuB,EAAWnB,WAsD9DuC,GAAyB,CAACpB,EAA4CnB,IACjFiB,EAOE,CAAEjD,IAAK,2BAA4B4B,OAAQ,UAAWuB,EAAWnB,WAkCxDwC,GAAsB,CAACrB,EAAyCnB,IAC3EiB,EAAqH,CACnHjD,IAAK,sCACL4B,OAAQ,SACLuB,EACHnB,WAmDSyC,GAAyB,CAACtB,EAA4CnB,IACjFiB,EAOE,CAAEjD,IAAK,sCAAuC4B,OAAQ,WAAYuB,EAAWnB,WAoEpE0C,GAA+B,CAACvB,EAAkDnB,IAC7FiB,EAOE,CAAEjD,IAAK,8CAA+C4B,OAAQ,UAAWuB,EAAWnB,WAkC3E2C,GAA0B,CAACxB,EAA6CnB,IACnFiB,EAOE,CAAEjD,IAAK,8CAA+C4B,OAAQ,UAAWuB,EAAWnB,WAsC3E4C,GAA8B,CAACzB,EAAiDnB,IAC3FiB,EAOE,CAAEjD,IAAK,4CAA6C4B,OAAQ,SAAUuB,EAAWnB,WAkCxE6C,GAAwB,CAAC1B,EAA2CnB,IAC/EiB,EAA+G,CAC7GjD,IAAK,4CACL4B,OAAQ,UACLuB,EACHnB,WAiES8C,GAAyB,CAAC3B,EAA4CnB,IACjFiB,EAOE,CAAEjD,IAAK,oCAAqC4B,OAAQ,UAAWuB,EAAWnB,WAmCjE+C,GAA8B,CAAC5B,EAAiDnB,IAC3FiB,EAOE,CAAEjD,IAAK,oCAAqC4B,OAAQ,UAAWuB,EAAWnB,WAmCjEgD,GAAuB,CAAC7B,EAA0CnB,IAC7EiB,EAOE,CAAEjD,IAAK,iDAAkD4B,OAAQ,UAAWuB,EAAWnB,WA+B9EiD,GAAqB,CAAC9B,EAAwCnB,IACzEiB,EAOE,CAAEjD,IAAK,mCAAoC4B,OAAQ,UAAWuB,EAAWnB,WAwChEkD,GAA0B,CAAC/B,EAA6CnB,IACnFiB,EAOE,CAAEjD,IAAK,oCAAqC4B,OAAQ,UAAWuB,EAAWnB,WAmCjEmD,GAAwB,CAAChC,EAA2CnB,IAC/EiB,EAOE,CAAEjD,IAAK,kCAAmC4B,OAAQ,UAAWuB,EAAWnB,WAkD/DoD,GAAc,CAACjC,EAAiCnB,IAC3DiB,EAAgG,CAC9FjD,IAAK,wCACL4B,OAAQ,SACLuB,EACHnB,WAsCSqD,GAAc,CAAClC,EAAiCnB,IAC3DiB,EAAgG,CAC9FjD,IAAK,wCACL4B,OAAQ,YACLuB,EACHnB,WAwDSsD,GAAc,CAACnC,EAAiCnB,IAC3DiB,EAOE,CAAEjD,IAAK,wCAAyC4B,OAAQ,WAAYuB,EAAWnB,WAsCtEuD,GAAiB,CAACpC,EAAoCnB,IACjEiB,EAAyG,CACvGjD,IAAK,+CACL4B,OAAQ,SACLuB,EACHnB,WA4CSwD,GAAiB,CAACrC,EAAoCnB,IACjEiB,EAOE,CAAEjD,IAAK,+CAAgD4B,OAAQ,SAAUuB,EAAWnB,WA0C3EyD,GAAkB,CAACtC,EAAqCnB,IACnEiB,EAA4G,CAC1GjD,IAAK,gDACL4B,OAAQ,SACLuB,EACHnB,WAyCS0D,GAAiB,CAACvC,EAAoCnB,IACjEiB,EACE,CAAEjD,IAAK,gDAAiD4B,OAAQ,UAAWuB,EAAWnB,WA0C7E2D,GAAY,CAACxC,EAA+BnB,IACvDiB,EAAuF,CACrFjD,IAAK,6DACL4B,OAAQ,SACLuB,EACHnB,WAkDS4D,GAAe,CAACzC,EAAkCnB,IAC7DiB,EAOE,CAAEjD,IAAK,6DAA8D4B,OAAQ,WAAYuB,EAAWnB,WAyC3F6D,GAAe,CAAC1C,EAAkCnB,IAC7DiB,EAA6G,CAC3GjD,IAAK,6DACL4B,OAAQ,YACLuB,EACHnB,WA+CS8D,GAAe,CAAC3C,EAAkCnB,IAC7DiB,EAOE,CAAEjD,IAAK,6CAA8C4B,OAAQ,UAAWuB,EAAWnB,WAiD1E+D,GAAY,CAAC5C,EAA+BnB,IACvDiB,EAAmH,CACjHjD,IAAK,wDACL4B,OAAQ,SACLuB,EACHnB,WAyDSgE,GAAqB,CAAC7C,EAAwCnB,IACzEiB,EAOE,CAAEjD,IAAK,wDAAyD4B,OAAQ,SAAUuB,EAAWnB,WAoDpFiE,GAAqB,CAAC9C,EAAwCnB,IACzEiB,EAOE,CAAEjD,IAAK,wDAAyD4B,OAAQ,WAAYuB,EAAWnB,WAoDtFkE,GAAqB,CAAC/C,EAAwCnB,IACzEiB,EAOE,CAAEjD,IAAK,wDAAyD4B,OAAQ,UAAWuB,EAAWnB,WA8CrFmE,GAAe,CAAChD,EAAkCnB,IAC7DiB,EAOE,CAAEjD,IAAK,wDAAyD4B,OAAQ,YAAauB,EAAWnB,WAsDvFoE,GAAyB,CAACjD,EAA4CnB,IACjFiB,EAOE,CAAEjD,IAAK,6CAA8C4B,OAAQ,UAAWuB,EAAWnB,WAwwB1EqE,GAAa,CAAClD,EAAgCnB,IACzDiB,EAA8G,CAC5GjD,IAAK,8CACL4B,OAAQ,UACLuB,EACHnB,WA8DSsE,GAAe,CAACnD,EAAkCnB,IAC7DiB,EAAqH,CACnHjD,IAAK,4BACL4B,OAAQ,UACLuB,EACHnB,WA0DSuE,GAAc,CAACpD,EAAiCnB,IAC3DiB,EAAkH,CAChHjD,IAAK,+CACL4B,OAAQ,UACLuB,EACHnB,WAsHSwE,GAAiB,CAACrD,EAAoCnB,IACjEiB,EAOE,CAAEjD,IAAK,kDAAmD4B,OAAQ,UAAWuB,EAAWnB,WAgD/EyE,GAAiB,CAACtD,EAAoCnB,IACjEiB,EAOE,CAAEjD,IAAK,kDAAmD4B,OAAQ,UAAWuB,EAAWnB,WAE/E0E,GAAkB,CAC7BC,SAAU,CACRzD,4BACAG,2BACAC,2BACAC,gCACAC,oCAEF5G,OAAQ,CACNwG,gBACAK,mBACAC,eACAC,eACAC,uBACAC,oBACAC,iBACAC,wBACAC,sBACAC,yBACAC,iBAEF0C,WAAY,CACVzC,4BACAC,yBACAC,6BACAS,0BACAC,+BACAC,wBACAC,sBACAC,2BACAC,0BAEF0B,kBAAmB,CACjBvC,yBACAC,0BACAC,uBACAC,0BACAC,gCACAC,2BACAC,+BACAC,0BAEFiC,MAAO,CACL1B,eACAC,eACAC,eACAC,kBACAC,kBACAC,mBACAC,kBACAC,aACAC,gBACAC,iBAEFkB,QAAS,CACPjB,gBACAC,aACAC,sBACAC,sBACAC,sBACAC,gBACAC,2BAEFY,gBAAiB,CAAEX,cAAYC,gBAAcC,eAAaC,kBAAgBC,oBCvmH/DQ,GAAoB1N,SAU/B,EAAiE,IAAK4F,EAAS6B,SAAU,iBCP9EkG,GAAU,CAAC/D,EAA6BnB,IACnDiF,GAA2E,CACzEjH,IAAK,QACL4B,OAAQ,SACLuB,EACHnB,WAyBSmF,GAAa,CAAChE,EAAgCnB,IACzDiF,GAAiF,CAC/EjH,IAAK,QACL4B,OAAQ,SACLuB,EACHnB,WAuBSoF,GAAa,CAACjE,EAAgCnB,IACzDiF,GAAqE,CACnEjH,IAAK,QACL4B,OAAQ,YACLuB,EACHnB,WA8BSqF,GAAiB,CAAClE,EAAoCnB,IACjEiF,GAAsF,CACpFjH,IAAK,aACL4B,OAAQ,SACLuB,EACHnB,WAsCSsF,GAAmB,CAACnE,EAAsCnB,IACrEiF,GAAkH,CAChHjH,IAAK,uBACL4B,OAAQ,UACLuB,EACHnB,WAgCSuF,GAAmB,CAACpE,EAAsCnB,IACrEiF,GAAmG,CACjGjH,IAAK,uBACL4B,OAAQ,YACLuB,EACHnB,WAgCSwF,GAAoB,CAACrE,EAAuCnB,IACvEiF,GAA4F,CAC1FjH,IAAK,cACL4B,OAAQ,SACLuB,EACHnB,WAyBSyF,GAAkB,CAACtE,EAAqCnB,IACnEiF,GAA8F,CAC5FjH,IAAK,cACL4B,OAAQ,UACLuB,EACHnB,WAgCS0F,GAAe,CAACvE,EAAkCnB,IAC7DiF,GAAmG,CACjGjH,IAAK,4BACL4B,OAAQ,SACLuB,EACHnB,WAiCS2F,GAAkB,CAACxE,EAAqCnB,IACnEiF,GAAqH,CACnHjH,IAAK,4BACL4B,OAAQ,SACLuB,EACHnB,WAgCS4F,GAAkB,CAACzE,EAAqCnB,IACnEiF,GAAiG,CAC/FjH,IAAK,4BACL4B,OAAQ,YACLuB,EACHnB,WAgCS6F,GAA0B,CAAC1E,EAA6CnB,IACnFiF,GAOE,CAAEjH,IAAK,oCAAqC4B,OAAQ,SAAUuB,EAAWnB,WAwChE8F,GAA4B,CAAC3E,EAA+CnB,IACvFiF,GAOE,CAAEjH,IAAK,6CAA8C4B,OAAQ,SAAUuB,EAAWnB,WAmCzE+F,GAAwB,CAAC5E,EAA2CnB,IAC/EiF,GAA6G,CAC3GjH,IAAK,6CACL4B,OAAQ,YACLuB,EACHnB,WA6CSgG,GAAwB,CAAC7E,EAA2CnB,IAC/EiF,GAOE,CAAEjH,IAAK,oCAAqC4B,OAAQ,UAAWuB,EAAWnB,WA4CjEiG,GAA8B,CAAC9E,EAAiDnB,IAC3FiF,GAOE,CAAEjH,IAAK,+CAAgD4B,OAAQ,WAAYuB,EAAWnB,WAmC7EkG,GAA8B,CAAC/E,EAAiDnB,IAC3FiF,GAOE,CAAEjH,IAAK,+CAAgD4B,OAAQ,YAAauB,EAAWnB,WAmC9EmG,GAA8B,CAAChF,EAAiDnB,IAC3FiF,GAOE,CAAEjH,IAAK,uDAAwD4B,OAAQ,UAAWuB,EAAWnB,WAmCpFoG,GAA8B,CAACjF,EAAiDnB,IAC3FiF,GAOE,CAAEjH,IAAK,sDAAuD4B,OAAQ,UAAWuB,EAAWnB,WA2BnFqG,GAAkB,CAAClF,EAAqCnB,IACnEiF,GAAqH,CACnHjH,IAAK,gCACL4B,OAAQ,SACLuB,EACHnB,WAyDSsG,GAAiB,CAACnF,EAAoCnB,IACjEiF,GAOE,CAAEjH,IAAK,yCAA0C4B,OAAQ,SAAUuB,EAAWnB,WAuCrEuG,GAAiB,CAACpF,EAAoCnB,IACjEiF,GAA4G,CAC1GjH,IAAK,yCACL4B,OAAQ,YACLuB,EACHnB,WAoCSwG,GAAsB,CAACrF,EAAyCnB,IAC3EiF,GAOE,CAAEjH,IAAK,yCAA0C4B,OAAQ,SAAUuB,EAAWnB,WA6CrEyG,GAAyB,CAACtF,EAA4CnB,IACjFiF,GAOE,CAAEjH,IAAK,yCAA0C4B,OAAQ,WAAYuB,EAAWnB,WA2BvE0G,GAAc,CAACvF,EAAiCnB,IAC3DiF,GAA2G,CACzGjH,IAAK,oCACL4B,OAAQ,SACLuB,EACHnB,WAGS0E,GAAkB,CAC7BiC,MAAO,CAAEzB,WAASC,cAAYC,eAC9BwB,eAAgB,CAAEvB,kBAAgBC,oBAAkBC,qBACpDsB,WAAY,CACVrB,qBACAC,mBACAC,gBACAC,mBACAC,mBACAC,2BACAC,6BACAC,0BAEFe,QAAS,CACPd,yBACAC,+BACAC,+BACAC,+BACAC,gCAEFW,UAAW,CACTV,mBACAC,kBACAC,kBACAC,uBACAC,0BACAC,iBChhC2B7M,EAAU,GAAqBmN,ICqCvD,SAASC,GAAwBjJ,GAClC,IAAC9E,EAAS8E,GAAa,YAE3B,MAAMkJ,EAAQ,mDACRC,EAAe,gEAEfC,EAAQpJ,EAAIoJ,MAAMF,IAAUlJ,EAAIoJ,MAAMD,GAC5C,OAAKC,EAGE,CAAEhI,UAAWgI,EAAM,GAAI/H,OAAQ+H,EAAM,IAAM,aAH/B,IAIrB,CCnCEC,IAAAA,QACAC,IAAAA,QClBK,MAAeC,ICJf,SAASC,KACd,MAAO,uCAAuC3I,QAAQ,SAAS,SAAU4I,GACjE,MAAAC,EAAqB,GAAhBC,KAAKC,SAAiB,EAC/BC,EAAS,KAALJ,EAAWC,EAAS,EAAJA,EAAW,EAC1B,OAAAG,EAAEjO,SAAS,GAAE,GAExB,CC2GO,SAASkO,GAAYlP,GAC1B,IAAKA,EAAe,OAEpB,MAAMmP,EAAS7N,OAAO6N,OAAOnP,GAC1BA,OAAOE,SACPF,QAAQpD,IAAWuD,MAAMC,QAAQxD,IAASA,EAAMiJ,OAAS,IAErD,OAAAsJ,EAAOtJ,OAAS,EAAI7F,OAAS,CACtC,C,ICzHA,M,iVAsBO,MAAMoP,GAWX/K,YAAYqB,EAA8B2J,EAA2BlD,EAAoB,IAVzFmD,GAAAA,KAAAA,QAAAA,GAWEC,GAAAA,KAAKC,GAAS9J,GACd7J,KAAKwT,KAAOA,EACZxT,KAAKsQ,QAAU,IAAIsD,GAAY5T,KAAMsQ,EAAO,CAS9CxN,eAAe+Q,EAAeC,GAC5B,OAAOC,GAAK,SAAOC,aAAa,CAAEC,WAAY,CAAEJ,OAAMC,SAAQI,MAAOlU,KAAKwT,KAAKW,KAAKC,SAAU,CAShGtR,mBAAmB+Q,EAAeC,GAChC,OAAOC,GAAK,SAAOC,aAAa,CAAEC,WAAY,CAAEJ,OAAMC,SAAQO,OAAQrU,KAAKwT,KAAKW,KAAKC,SAAU,CASjGtR,gBAAgB+Q,EAAeC,GAC7B,OAAOC,GAAK,SAAOC,aAAa,CAAEC,WAAY,CAAEJ,OAAMC,SAAQQ,MAAOtU,KAAKwT,KAAKW,KAAKC,SAAU,CAShGtR,eAAe+Q,EAAeC,GAC5B,OAAOC,GAAK,SAAOC,aAAa,CAAEC,WAAY,CAAEJ,OAAMC,SAAQS,KAAMvU,KAAKwT,KAAKW,KAAKC,SAAU,CAO/FI,cACS,OAAAxU,KAAKwT,KAAKW,KAAKM,IAAA,EA7DxBd,GAAAA,IAAAA,QAoEK,MAAMe,GAAsB,IACtBC,GAA0B,GAIhC,SAASC,GACdlM,GAEA,OACElE,EAAUkE,KACTlE,EAAUkE,EAAQ4L,QAAU9P,EAAUkE,EAAQ6L,OAAS/P,EAAUkE,EAAQwL,QAAU1P,EAAUkE,EAAQ2L,QAE1G,CAEO,MAAMQ,GAAN,cAAqDvQ,MAI1DkE,eAAesM,GACbnM,SAASkM,GAAYE,0BAA0BD,IAJjDrB,GAAAA,KAAAA,QAAAA,GAOOC,GAAAA,KAAAA,GAAQtP,EAAS0Q,EAAK,IAAItB,MAAQsB,EAAK,GAAK,CAAEtB,KAAM,CAAEW,KAAM,CAAEC,OAAQ,GAAIK,MAAM,IAAWnE,QAAS,IAAG,CAG9G0E,iCAAiCF,GAE/B,GAAoB,IAAhBA,EAAK9K,QAAmC,kBAAZ8K,EAAK,GAC5B,WAAIxQ,MAAMwQ,EAAK,IAIxB,GAAIA,EAAK9K,QAAU,GAAK5F,EAAS0Q,EAAK,IAAItB,OAASlP,MAAMC,QAAQuQ,EAAK,IAAM,IAAK,CAC/E,MAAMvP,EAASuP,EAAK,IAAMA,EAAK,GAAGxE,SAAW,GACtC,WAAIhM,SAASiB,EAAM,CAIrB,WAAIjB,SAASwQ,EAAI,CAG1BG,UACS,WAAI3Q,SAAStE,KAAI,CAG1BkV,IAAOC,EAAkEC,GACvE,OAAOpV,KAAKiV,UAAUC,IAAIC,EAAYC,EAAO,CAQ/CtS,eAAe+Q,EAAeC,GAC5B,MAAMuB,QAAgBtB,GAAAA,KAAKuB,IAAMC,SAAS1B,EAAMC,GACzC,WAAIe,GAAYQ,EAAO,CAQhCvS,mBAAmB+Q,EAAeC,GAChC,MAAMuB,QAAgBtB,GAAAA,KAAKuB,IAAME,aAAa3B,EAAMC,GAC7C,WAAIe,GAAYQ,EAAO,CAQhCvS,gBAAgB+Q,EAAeC,GAC7B,MAAMuB,QAAgBtB,GAAAA,KAAKuB,IAAMG,UAAU5B,EAAMC,GAC1C,WAAIe,GAAYQ,EAAO,CAQhCvS,eAAe+Q,EAAeC,GAC5B,MAAMuB,QAAgBtB,GAAAA,KAAKuB,IAAMI,SAAS7B,EAAMC,GACzC,WAAIe,GAAYQ,EAAO,CAMhCb,cACS,UAAAxU,KAAKsV,IAAM9B,KAAKW,KAAKM,IAAA,GA/EzB,IAAMb,GAAN,GACL0B,GAAAA,IAAAA,Q,IC1GF,e,iYAgDO,MAAMK,GAAN,MASLnN,YACEoN,EACAvF,EACA9O,EACAsU,GAoIFpC,GAAAA,KAAAA,IAhJAA,GAAAA,KAAAA,QAAAA,GACAA,GAAAA,KAAAA,QAAAA,GAC8BA,GAAAA,KAAAA,GAAAA,CAAEtP,OAAQ,KAG/B,KAAAqP,KAA4B,CAAEW,KAAM,CAAEC,OAAQ,QAASK,MAAM,IACtE,KAASnE,QAA+B,IAAIsD,GAAoB5T,KAAM,IAQpE0T,GAAAA,KAAKoC,GAASzF,GAGZqD,GAAAA,KAAKqC,GADHH,GAGiB5V,MAIf,MAAAgW,EAASC,GAAY1U,EAAMsU,GAEjC9B,GAAAA,KAAKmC,IAAM/R,OAAS5C,EAAK4C,QAAU6R,GAAQ7R,QAAU,CAAC,EACtD4P,GAAAA,KAAKmC,IAAM/R,OAAOgS,KAAO5U,EAAK4C,QAAQgS,MAAQH,GAAQ7R,QAAQgS,KAC9DpC,GAAAA,KAAKmC,IAAM/R,OAAOiS,KAAO7U,EAAK4C,QAAQiS,MAAQJ,GAAQ7R,QAAQiS,KAC9DrC,GAAAA,KAAKmC,IAAM/R,OAAOkS,KAAO9U,EAAK4C,QAAQkS,MAAQL,GAAQ7R,QAAQkS,KAC9DtC,GAAAA,KAAKmC,IAAM/R,OAAOmS,MAAQ/U,EAAK4C,QAAQmS,OAASN,GAAQ7R,QAAQmS,MAChEvC,GAAAA,KAAKmC,IAAMK,KAAOhV,EAAKgV,MAAQP,GAAQO,KACvCxC,GAAAA,KAAKmC,IAAMM,QAAUjV,EAAKiV,SAAWR,GAAQQ,QAC7CzC,GAAAA,KAAKmC,IAAMjC,WAAa1S,EAAK0S,YAAc+B,GAAQ/B,WACnDF,GAAAA,KAAKmC,IAAMO,MAAQlV,EAAKkV,OAAST,GAAQS,MAEzCzW,KAAK0W,IAAM1W,KAAK0W,IAAIC,KAAK3W,MACzBA,KAAK4W,IAAM5W,KAAK4W,IAAID,KAAK3W,MACzBA,KAAK6W,IAAM7W,KAAK6W,IAAIF,KAAK3W,MACzBA,KAAKmE,OAASnE,KAAKmE,OAAOwS,KAAK3W,MAC/BA,KAAKuW,KAAOvW,KAAKuW,KAAKI,KAAK3W,MAC3BA,KAAK8W,KAAO9W,KAAK8W,KAAKH,KAAK3W,MAE3ByF,OAAOsR,eAAe/W,KAAM,QAAS,CAAEgX,YAAY,IACnDvR,OAAOsR,eAAe/W,KAAM,aAAc,CAAEgX,YAAY,GAAO,CAGjEC,kBACE,OAAOlD,GAAK,SAGdvO,MACE,MAAM,QAAEgR,EAAU,GAAC,OAAGrS,EAAS,CAAC,OAAGoS,EAAO,GAAItC,WAAAA,EAAa,CAAC,GAAMF,GAAK,SACjEvO,EAAMuG,KAAKC,UAAU,CAAEwK,UAASrS,SAAQoS,OAAMtC,eACpD,OAAOpP,EAASW,EAAG,CAQrBkR,OAAOQ,GACC,MAAAf,EAAOe,EAAQhC,KAAKrL,GAAUA,EAAMoN,kBAAkB9S,QAAU,KACtE,OAAO,IAAIwR,GAAsB5B,GAAK,SAAaA,GAAK,SAAQ,CAAE5P,OAAQ,CAAEgS,SAAUpC,GAAAA,KAAKmC,IAAK,CAQlGU,OAAOM,GACC,MAAAd,EAAOc,EAAQhC,KAAKrL,GAAUA,EAAMoN,kBAAkB9S,QAAU,KACtE,OAAO,IAAIwR,GAAsB5B,GAAK,SAAaA,GAAK,SAAQ,CAAE5P,OAAQ,CAAEiS,SAAUrC,GAAAA,KAAKmC,IAAK,CAQlGW,OAAOK,GACC,MAAAb,EAAOa,EAAQhC,KAAKrL,GAAUA,EAAMoN,kBAAkB9S,QAAU,KACtE,OAAO,IAAIwR,GAAsB5B,GAAK,SAAaA,GAAK,SAAQ,CAAE5P,OAAQ,CAAEkS,SAAUtC,GAAAA,KAAKmC,IAAK,CAQlGY,QAAQI,GACA,MAAAZ,EAAQY,EAAQhC,KAAKrL,GAAUA,EAAMoN,kBAAkB9S,QAAU,KACvE,OAAO,IAAIwR,GAAsB5B,GAAK,SAAaA,GAAK,SAAQ,CAAE5P,OAAQ,CAAEmS,UAAWvC,GAAAA,KAAKmC,IAAK,CAmCnG/R,OAAOkB,EAAQC,GACT,GAAqB,IAArB7E,UAAUuJ,OAAc,CAC1B,MAAMmN,EAAc1R,OAAOC,QAAQL,GAAK,CAAC,GAAG6P,KAAI,EAAEkC,EAAQC,MAAiB,CACzE,CAACD,GAASE,GAAK,YAALC,KAAAA,KAA4BH,EAAQC,OAE1CjB,EAAOnS,EAAQ,CAAC8P,GAAAA,KAAKmC,IAAM/R,QAAQiS,MAAMoB,OAAOC,OAAON,IAE7D,OAAO,IAAIxB,GAAsB5B,GAAK,SAAaA,GAAK,SAAQ,CAAE5P,OAAQ,CAAEiS,SAAUrC,GAAAA,KAAKmC,IAAK,CAC3F,CACL,MAAMiB,EAAc3S,EAAUa,IAAMb,EAAUc,GAAK,CAAC,CAAE,CAACD,GAAIiS,GAAK,YAALC,KAAAA,KAA4BlS,EAAGC,UAAQ,EAC5F8Q,EAAOnS,EAAQ,CAAC8P,GAAAA,KAAKmC,IAAM/R,QAAQiS,MAAMoB,OAAOC,OAAON,IAE7D,OAAO,IAAIxB,GAAsB5B,GAAK,SAAaA,GAAK,SAAQ,CAAE5P,OAAQ,CAAEiS,SAAUrC,GAAAA,KAAKmC,IAAK,CAClG,CAwBFK,KAA4Ca,EAAWM,EAA2B,OAC1E,MAAAC,EAAe,CAAC5D,GAAK,SAAMwC,MAAQ,IAAIiB,OACvCjB,EAAO,IAAIoB,EAAc,CAAEP,SAAQM,cAClC,WAAI/B,GAAsB,GAAA3V,KAAK+V,IAAa,GAAA/V,KAAK8V,IAAQ,CAAES,QAAQ,GAAAvW,KAAKkW,IAAK,CAQtF0B,OAA2CpB,GACzC,OAAO,IAAIb,GACT5B,GAAK,SACLA,GAAK,SACL,CAAEyC,WACFzC,GAAK,SACP,CA4BFC,aAAwCtL,EAAgC,IAChE,MAAAmB,EAAQ,IAAI8L,GAAsB,GAAA3V,KAAK+V,IAAahC,GAAK,SAAQrL,EAAS,GAAA1I,KAAKkW,KAC9E,UAAAlW,KAAK+V,IAAYlM,MAAMA,EAAK,CASrC/G,OAAQ+U,OAAOC,iBACI,gBAACC,KAAW/X,KAAKgY,YAAY,CAAEC,UAAW,UACnDF,CACR,CA8BFjV,kBACE4F,EAAyD,IAEnD,gBAAEuP,EAAY,GAAMvP,EAE1B,IAAIyL,QAAanU,KAAKgU,aAAa,IAAKtL,EAASuL,WAAY,CAAEJ,KAAMoE,EAAWnE,OAAQ,KACpFW,EAAON,EAAKK,oBAEVL,EAAK7D,QAEX,MAAOmE,EACEN,QAAMA,EAAKoB,WAClBd,EAAON,EAAKK,oBAENL,EAAK7D,OACb,CAyBFxN,cAAyC4F,EAAgC,IACvE,MAAM,WAAEuL,EAAa,CAAC,KAAMiE,GAASxP,GAC/B,KAAEmL,EAAOc,GAAyBb,OAAAA,GAAWG,EAC7CgE,EAAYpE,GAAQa,GAAsBb,EAAOa,GAEvD,IAAIP,QAAanU,KAAKgU,aAAa,IAAKkE,EAAMjE,WAAY,CAAEJ,KAAMoE,EAAWnE,YAC7E,MAAMqE,EAAU,IAAIhE,EAAK7D,SAEzB,MAAO6D,EAAKK,eAAiB2D,EAAQnO,OAAS6J,EACrCM,QAAMA,EAAKoB,WACV4C,EAAAA,QAAQhE,EAAK7D,SAGnB6D,EAAKK,oBAA8C,IAA7B9L,EAAQuL,YAAYJ,MAC5CuE,QAAQ9M,MAAM,4FAGV,MAAA+M,EAAQ,IAAIzE,GAAYO,EAAMgE,EAAQ9N,MAAM,EAAGwJ,IAG9C,OAAAwE,CAAA,CA4BTvV,aACE4F,EAAyD,IAEzD,MAAM,UAAEuP,EAAYvD,MAAwBwD,GAASxP,EAC/CyP,EAAU,GAEC,gBAAAhE,KAAQnU,KAAKgY,YAAY,IAAKE,EAAMD,cAC3CE,EAAAA,QAAQhE,GAIX,OAAAgE,CAAA,CAyBTrV,eAA0C4F,EAAgC,IACxE,MAAM4H,QAAgBtQ,KAAKsY,QAAQ,IAAK5P,EAASuL,WAAY,CAAEJ,KAAM,KAGrE,OAAQvD,EAAQ,IAA4B,KA4B9CxN,sBAAiD4F,EAAgC,IAC/E,MAAM4H,QAAgBtQ,KAAKsY,QAAQ,IAAK5P,EAASuL,WAAY,CAAEJ,KAAM,KACrE,QAAmB,IAAfvD,EAAQ,GAAwB,UAAI/N,MAAM,qBAG9C,OAAO+N,EAAQ,GAGjBxN,gBAGElB,EAAuD,IACvD,MAAM,UAAE2W,EAAS,gBAAEC,KAAoB9P,GAAY9G,EAC7CiI,EAAQ,IAAI8L,GAChB5B,GAAK,SACLA,GAAK,SACLrL,EACAqL,GAAK,UAGP,OAAOA,GAAK,SAAYhE,eAAelG,EAAO0O,EAAWC,EAA2C,CAQtG/B,MAAMgC,GACG,WAAI9C,GAAsB,GAAA3V,KAAK+V,IAAa,GAAA/V,KAAK8V,IAAQ,CAAEW,MAAOgC,GAAO,GAAAzY,KAAKkW,IAAK,CAQ5FX,SAAS1B,EAAeC,GACf,OAAA9T,KAAKyV,UAAU5B,EAAMC,EAAM,CAQpC0B,aAAa3B,EAAeC,GACnB,OAAA9T,KAAKyV,UAAU5B,EAAMC,EAAM,CAQpC2B,UAAU5B,EAAeC,GAChB,OAAA9T,KAAKgU,aAAa,CAAEC,WAAY,CAAEJ,OAAMC,WAAU,CAQ3D4B,SAAS7B,EAAeC,GACf,OAAA9T,KAAKgU,aAAa,CAAEC,WAAY,CAAEJ,OAAMC,SAAQO,OAAQ,QAAS,CAM1EG,cACS,OAAAxU,KAAKwT,KAAKW,KAAKM,IAAA,GAnenB,IAAMiE,GAAN,GAyeP,SAASzC,GACP1U,EACAyU,GAEI,OAAApB,GAA0BrT,EAAK0S,YAC1B,IAAK+B,EAAQO,UAAM,EAAWpS,YAAQ,GAGxC6R,CACT,CC3aO,SAAS2C,GAAeC,GAC7B,OAAOxU,EAASwU,IAAMnU,EAAUmU,GAA6BlW,GAC/D,CC/FO,SAASmW,GAAyC9X,GACvD,OAAO0D,EAAS1D,EAClB,CAEO,SAAS+X,GAAuC3U,GACrD,OAAOC,EAASD,IAAWsB,OAAO6N,OAAOnP,GAAQQ,OAAO5D,GAAoB,QAAVA,GAA6B,SAAVA,GACvF,CAEO,SAASgY,GAAyC5U,GAChD,OAAAC,EAASD,KAAY2U,GAAiB3U,SAA6B,IAAlBA,EAAOiT,MACjE,CAEO,SAAS4B,GACd7U,GAEI,GAAA0U,GAAmB1U,GACd,OAAE,CAACA,GAAS,OACV,GAAAG,MAAMC,QAAQJ,GACvB,OAAOA,EAAO+Q,KAAK+D,GAASD,GAAgBC,KAC9C,GAAWH,GAAiB3U,GACnB,OAAAA,EACT,GAAW4U,GAAmB5U,GAC5B,MAAO,CAAE,CAACA,EAAOiT,QAASjT,EAAOuT,WAAa,OAExC,UAAInV,MAAM,wBAAwB4B,IAE5C,CFHE2R,GAAAA,IAAAA,QACAC,GAAAA,IAAAA,QACAG,GAAAA,IAAAA,QA8IAgD,GAAAA,IAAAA,QAAAC,GAAyB,SAAC/B,EAAgBrW,GACxC,MAAMqY,EAAa,GAAApZ,KAAK8V,IAAOuD,QAAQ7C,QAAQ8C,MAAK,EAAGzY,UAAWA,IAASuW,KAAS3V,KAGpF,MAAmB,aAAf2X,IAA8B3U,EAAS1D,IAAU2D,EAAc3D,IAC1D,CAAEwY,UAAWxY,GAGH,SAAfqY,GAAyBhV,EAASrD,IAAU0D,EAAS1D,EAAM2B,IACtD3B,EAAM2B,GAGR3B,CACT,E,IG9MF,wE,iYAsuBO,MAAMyY,WACHd,GAURlQ,YAAYE,GAMVC,MACE,KACA,CAAE9H,KAAM6H,EAAQ2H,MAAOgJ,OAAQ3Q,EAAQ+Q,cAAcH,MAAMjJ,GAAUA,EAAMxP,OAAS6H,EAAQ2H,SAC5F,CAAC,GAsGCoD,GAAAA,KAAAA,IAqBAA,GAAAA,KAAAA,IA2BAA,GAAAA,KAAAA,IA0SAA,GAAAA,KAAAA,IAyGAA,GAAAA,KAAAA,IA4MAA,GAAAA,KAAAA,IAwJAA,GAAAA,KAAAA,IAIAA,GAAAA,KAAAA,IAcAA,GAAAA,KAAAA,IA/6BNA,GAAAA,KAAAA,QAAAA,GACAA,GAAAA,KAAAA,QAAAA,GACAA,GAAAA,KAAAA,QAAAA,GACAA,GAAAA,KAAAA,QAAAA,GACAA,GAAAA,KAAAA,QAAAA,GACAA,GAAAA,KAAAA,QAAAA,GAcEC,GAAAA,KAAKoC,GAASpN,EAAQ2H,OACtBqD,GAAAA,KAAKgG,GAAMhR,EAAQiR,IACdjG,GAAAA,KAAAA,GAAShL,EAAQkR,cAAcnD,OACpC/C,GAAAA,KAAKmG,GAAgBnR,EAAQ+Q,cAC7B/F,GAAAA,KAAKoG,IAAiBhX,UACpB,MAAMiX,QAAcrR,EAAQkR,cAAcI,gBAC1C,MAAO,IAAKD,EAAOtO,UAAWsH,KAAgB,IAG1C,MAAAzH,EAAQ5C,EAAQkR,cAActO,OAASzI,EAC7C6Q,GAAAA,KAAKuG,IAASnX,MACZjC,EACAmC,EACA0F,EAA+B,CAAC,IAEzB4C,EAASzK,EAAMmC,EAAI,IACrB0F,EACH,CAACvF,EAAgBG,OAAQyQ,GAAK,SAC9B,CAAC5Q,EAAgBC,MAAO,gBACxB,CAACD,EAAgBE,SAAUA,KAE/B,CA8BFP,aACEuC,EACAC,EACA0N,EACAkH,GAOA,OAAOnG,GAAK,SAALwD,KAAY,eAAUzU,UAC3B,MAAMqX,EAAYC,GAAe9U,EAAG0N,EAAGkH,GAGnC,GAAA5V,MAAMC,QAAQc,GAAI,CACpB,GAAiB,IAAbA,EAAE2E,OAAc,MAAO,GAE3B,MAAMwM,EAAU9R,EAAcY,GAAKA,OAAI,EAChC,UAAAtF,KAAKqa,GAAL,SAAAra,KAA6BqF,EAAGmR,EAAA,CAIzC,GAAI/R,EAASY,IAAMjB,EAASkB,GAAI,CAC9B,GAAU,KAAND,EAAgB,UAAI9C,MAAM,yBAE9B,MAAMiU,EAAU9R,EAAcsO,GAAKA,OAAI,EAChC,UAAAhT,KAAKsa,GAAAA,IAAL/C,KAAyB,KAAAlS,EAAGC,EAA2BkR,EAAS,CAAE+D,YAAY,EAAMJ,aAAU,CAIvG,GAAI/V,EAASiB,IAAMZ,EAASY,EAAE3C,IAAK,CACjC,GAAa,KAAT2C,EAAE3C,GAAiB,UAAIH,MAAM,yBAEjC,MAAMiU,EAAU9R,EAAcY,GAAKA,OAAI,EACvC,OAAOgS,GAAK,YAALC,KAAyB,KAAAlS,EAAE3C,GAAI,IAAK2C,EAAG3C,QAAI,GAAa8T,EAAS,CAAE+D,YAAY,EAAMJ,aAAU,CAIpG,GAAA/V,EAASiB,GAAI,CACf,MAAMmR,EAAU9R,EAAcY,GAAKA,OAAI,EAChC,UAAAtF,KAAKwa,GAAL,SAAAxa,KAA4BqF,EAAGmR,EAAA,CAGlC,UAAIjU,MAAM,sCAAsC,GACxD,CAgGFO,WACEuC,EACAC,GAQA,OAAOyO,GAAK,SAALwD,KAAY,aAAQzU,UACzB,MAAM0T,EAAU9R,EAAcY,GAAKA,EAAI,CAAC,KAGpC,GAAAhB,MAAMC,QAAQc,GAAI,CACpB,GAAiB,IAAbA,EAAE2E,OAAc,MAAO,GAE3B,MAAMyQ,EAAMpV,EAAE6P,KAAK+D,GAASyB,GAAUzB,KAEhC0B,QAAqB3a,KAAK4a,OAAO,CAAEzW,OAAQ,CAAEzB,GAAI,CAAEyT,KAAMlS,EAAQwW,KAAUjE,YAG3EqE,EAAaF,EAAahR,QAAQ,CAAAC,EAAKkR,KAC3ClR,EAAIkR,EAAOpY,IAAMoY,EACVlR,IACN,CAAC,GAEJ,OAAO6Q,EAAIvF,KAAKxS,GAAOmY,EAAWnY,GAAM,KAAO,MAAI,CAI/C,MAAAA,EAAKgY,GAAUrV,GACrB,GAAI3C,EAAI,CACA,MAAAqY,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MAErB,IACI,MAAA8L,QAAiBwD,GAAU,CAC/B7F,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,SAChBmH,SAAUxY,GAEZ8G,YAAa,CAAEgN,cACZuE,IAGCtB,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MAC3B,OAAOob,GAAWrH,GAAK,SAAK0F,EAAc1F,GAAK,SAAQjI,EAAU0K,EAM3D,CANkE,MACjElU,GACP,GAAI8B,EAAS9B,IAAmB,MAAbA,EAAEuG,OACZ,YAGH,MAAAvG,CAAA,CACR,CAGK,cACT,CAuBFQ,kBACEuC,EACAC,GAOA,OAAOyO,GAAK,SAALwD,KAAY,oBAAezU,UAChC,MAAMyC,QAAevF,KAAKqb,KAAKhW,EAAUC,GAErC,GAAAhB,MAAMC,QAAQgB,GAAS,CACzB,MAAM+V,EAAarX,EAChBoB,EACElB,QAAO,CAACoX,EAAOC,IAA4B,OAAlBjW,EAAOiW,KAChCtG,KAAK+D,GAASyB,GAAUzB,MAGzB,GAAAqC,EAAWtR,OAAS,EACtB,MAAM,IAAIzH,MAAM,oCAAoC+Y,EAAWnU,KAAK,SAG/D,OAAA5B,CAAA,CAGT,GAAe,OAAXA,EAAiB,CACb,MAAA7C,EAAKgY,GAAUrV,IAAM,UACrB,UAAI9C,MAAM,kBAAkBG,cAAc,CAG3C,OAAA6C,CAAA,GACT,CA8BFzC,aACEuC,EACAC,EACA0N,EACAkH,GAQA,OAAOnG,GAAK,SAALwD,KAAY,eAAUzU,UAC3B,MAAMqX,EAAYC,GAAe9U,EAAG0N,EAAGkH,GAGnC,GAAA5V,MAAMC,QAAQc,GAAI,CACpB,GAAiB,IAAbA,EAAE2E,OAAc,MAAO,GAEvB3E,EAAE2E,OAAS,KAEboO,QAAQqD,KAAK,0FAGf,MAAMjF,EAAU9R,EAAcY,GAAKA,EAAK,CAAC,KAClC,OAAAnD,QAAQyU,IAAIvR,EAAE6P,KAAK4F,GAAW9a,KAAK0b,OAAOZ,EAAQtE,KAAS,CAIpE,GAAI/R,EAASY,IAAMjB,EAASkB,GAAI,CAC9B,MAAMkR,EAAU9R,EAAcsO,GAAKA,OAAI,EACvC,OAAOsE,GAAAA,KAAKqE,GAAL,SAAA3b,KAAyBqF,EAAGC,EAA2BkR,EAAS,CAAE2D,aAAU,CAIrF,GAAI/V,EAASiB,IAAMZ,EAASY,EAAE3C,IAAK,CACjC,MAAM8T,EAAU9R,EAAcY,GAAKA,OAAI,EACvC,OAAOgS,GAAK,YAALC,KAAyB,KAAAlS,EAAE3C,GAAI,IAAK2C,EAAG3C,QAAI,GAAa8T,EAAS,CAAE2D,aAAU,CAGhF,UAAI5X,MAAM,sCAAsC,GACxD,CA8BFO,oBACEuC,EACAC,EACA0N,EACAkH,GAOA,OAAOnG,GAAK,SAALwD,KAAY,sBAAiBzU,UAClC,MAAMyC,QAAevF,KAAK0b,OAAOrW,EAAUC,EAAU0N,EAAUkH,GAE3D,GAAA5V,MAAMC,QAAQgB,GAAS,CACzB,MAAM+V,EAAarX,EAChBoB,EACElB,QAAO,CAACoX,EAAOC,IAA4B,OAAlBjW,EAAOiW,KAChCtG,KAAK+D,GAASyB,GAAUzB,MAGzB,GAAAqC,EAAWtR,OAAS,EACtB,MAAM,IAAIzH,MAAM,oCAAoC+Y,EAAWnU,KAAK,SAG/D,OAAA5B,CAAA,CAGT,GAAe,OAAXA,EAAiB,CACb,MAAA7C,EAAKgY,GAAUrV,IAAM,UACrB,UAAI9C,MAAM,kBAAkBG,cAAc,CAG3C,OAAA6C,CAAA,GACT,CAiEFzC,qBACEuC,EACAC,EACA0N,EACAkH,GAOA,OAAOnG,GAAK,SAALwD,KAAY,uBAAkBzU,UACnC,MAAMqX,EAAYC,GAAe9U,EAAG0N,EAAGkH,GAGnC,GAAA5V,MAAMC,QAAQc,GAAI,CACpB,GAAiB,IAAbA,EAAE2E,OAAc,MAAO,GAEvB3E,EAAE2E,OAAS,KAEboO,QAAQqD,KAAK,0FAGf,MAAMjF,EAAU9R,EAAcY,GAAKA,EAAK,CAAC,KAClC,OAAAnD,QAAQyU,IAAIvR,EAAE6P,KAAK4F,GAAW9a,KAAK4b,eAAed,EAAetE,KAAS,CAInF,GAAI/R,EAASY,IAAMjB,EAASkB,GAAI,CAC9B,MAAMkR,EAAU9R,EAAcsO,GAAKA,OAAI,EACvC,OAAOsE,GAAAA,KAAKuE,GAAL,SAAA7b,KAAyBqF,EAAGC,EAA2BkR,EAAS,CAAE2D,aAAU,CAIrF,GAAI/V,EAASiB,IAAMZ,EAASY,EAAE3C,IAAK,CACjC,MAAM8T,EAAU9R,EAAcsO,GAAKA,OAAI,EACvC,OAAOsE,GAAK,YAALC,KAAyB,KAAAlS,EAAE3C,GAAI,IAAK2C,EAAG3C,QAAI,GAAa8T,EAAS,CAAE2D,aAAU,CAGhF,UAAI5X,MAAM,8CAA8C,GAChE,CAuDFO,sBACEuC,EACAC,EACA0N,EACAkH,GAOA,OAAOnG,GAAK,SAALwD,KAAY,wBAAmBzU,UACpC,MAAMqX,EAAYC,GAAe9U,EAAG0N,EAAGkH,GAGnC,GAAA5V,MAAMC,QAAQc,GAAI,CACpB,GAAiB,IAAbA,EAAE2E,OAAc,MAAO,GAE3B,MAAMwM,EAAU9R,EAAcY,GAAKA,EAAK,CAAC,KAClC,UAAAtF,KAAKqa,GAAL,SAAAra,KAA6BqF,EAAGmR,EAAA,CAIzC,GAAI/R,EAASY,IAAMjB,EAASkB,GAAI,CAC9B,MAAMkR,EAAU9R,EAAcsO,GAAKA,OAAI,EAChC,UAAAhT,KAAKsa,GAAAA,IAAL/C,KAAyB,KAAAlS,EAAGC,EAA2BkR,EAAS,CAAE+D,YAAY,EAAOJ,aAAU,CAIxG,GAAI/V,EAASiB,IAAMZ,EAASY,EAAE3C,IAAK,CACjC,MAAM8T,EAAU9R,EAAcsO,GAAKA,OAAI,EACvC,OAAOsE,GAAK,YAALC,KAAyB,KAAAlS,EAAE3C,GAAI,IAAK2C,EAAG3C,QAAI,GAAa8T,EAAS,CAAE+D,YAAY,EAAOJ,aAAU,CAGnG,UAAI5X,MAAM,+CAA+C,GACjE,CAyBFO,aACEuC,EACAC,GAQA,OAAOyO,GAAK,SAALwD,KAAY,eAAUzU,UAEvB,GAAAwB,MAAMC,QAAQc,GAChB,OAAiB,IAAbA,EAAE2E,OAAqB,IAEvB3E,EAAE2E,OAAS,KAEboO,QAAQqD,KAAK,0FAGRtZ,QAAQyU,IAAIvR,EAAE6P,KAAKxS,GAAO1C,KAAK8b,OAAOpZ,EAAW4C,OAItD,GAAAb,EAASY,GACJ,UAAArF,KAAK+b,GAAL,SAAA/b,KAAmBqF,EAAGC,GAI/B,GAAIlB,EAASiB,IAAMZ,EAASY,EAAE3C,IAC5B,OAAO4U,GAAK,YAALC,KAAmB,KAAAlS,EAAE3C,GAAI4C,GAG5B,UAAI/C,MAAM,sCAAsC,GACxD,CAyBFO,oBACEuC,EACAC,GAOA,OAAOyO,GAAK,SAALwD,KAAY,sBAAiBzU,UAClC,MAAMyC,QAAevF,KAAK8b,OAAOzW,EAAUC,GAEvC,GAAAhB,MAAMC,QAAQgB,GAAS,CACzB,MAAM+V,EAAarX,EAChBoB,EACElB,QAAO,CAACoX,EAAOC,IAA4B,OAAlBjW,EAAOiW,KAChCtG,KAAK+D,GAASyB,GAAUzB,MAGzB,GAAAqC,EAAWtR,OAAS,EACtB,MAAM,IAAIzH,MAAM,oCAAoC+Y,EAAWnU,KAAK,SAG/D,OAAA5B,CAAA,CACT,GAAsB,OAAXA,EAAiB,CACpB,MAAA7C,EAAKgY,GAAUrV,IAAM,UACrB,UAAI9C,MAAM,kBAAkBG,cAAc,CAG3C,OAAA6C,CAAA,GACT,CA8BFzC,aACE+G,EACAnB,EAMI,CAAC,GAEL,OAAOqL,GAAK,SAALwD,KAAY,eAAUzU,UACrB,MAAAiY,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,OAEnB,QAAEsQ,SAAkBR,GAAY,CACpCrG,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,UAElB3I,KAAM,CACJvB,QACAmS,UAAWtT,EAAQsT,UACnBC,OAAQvT,EAAQuT,OAChBC,UAAWxT,EAAQwT,UACnB/X,OAAQuE,EAAQvE,OAChBgY,SAAUzT,EAAQyT,aAEjBpB,IAGCtB,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MAG3B,OAAOsQ,EAAQ4E,KAAK+D,GAASmC,GAAWrH,GAAK,SAAK0F,EAAc,GAAAzZ,KAAK8V,IAAQmD,EAAM,CAAC,OAAM,GAC5F,CAGFnW,gBACEsZ,EACAjY,GAEA,OAAO4P,GAAK,SAALwD,KAAY,kBAAazU,UACxB,MAAAiY,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MAEnBuF,QAAeyK,GAAe,CAClCvG,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,UAElB3I,KAAM,CAAEgR,OAAMjY,aACX4W,IAGE,OAAAxV,CAAA,GACT,CAGFzC,YAAuC+G,GACrC,OAAOkK,GAAK,SAALwD,KAAY,cAASzU,UAC1B,MAAMuZ,QAAmB/E,GAAK,YAALC,KAA4B,KAAA1N,GACjD,GAAAwS,EAAY,OAAO,IAAI9I,GAAqB1J,EAAOwS,EAAW7I,KAAM6I,EAAW/L,SAE7E,MAAA/O,EAAOsI,EAAMoN,kBAEb8D,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,OACnB,KAAEwT,EAAMlD,QAASgM,SAAkB1M,GAAW,CAClDnG,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,UAElB3I,KAAM,CACJjH,OAAQkP,GAAY9R,EAAK4C,QACzBoS,UAAoB,IAAdhV,EAAKgV,KAAqByC,GAAgBzX,EAAKgV,WAAQ,EAC7DpC,KAAM5S,EAAK0S,WACXuC,QAASjV,EAAKiV,SAAW,CAAC,SAEzBuE,IAGCtB,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MACrBsQ,EAAUgM,EAAQpH,KAAK6C,GAC3BqD,GAAmB,GAAApb,KAAK0Z,IAAKD,EAAc1F,GAAK,SAAQgE,EAAQxW,EAAKiV,SAAW,CAAC,QAInF,aAFMc,GAAK,YAALC,KAAoB,KAAA1N,EAAO2J,EAAMlD,GAEhC,IAAIiD,GAAqB1J,EAAO2J,EAAMlD,EAAQ,GACvD,CAGFxN,qBACE+G,EACA0O,EACAC,GAEA,OAAOzE,GAAK,SAALwD,KAAY,kBAAazU,UACxB,MAAAvB,EAAOsI,EAAMoN,kBAEb8D,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MACnBuF,QAAewK,GAAe,CAClCtG,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,UAElB3I,KAAM,CACJjH,OAAQkP,GAAY9R,EAAK4C,QACzBoS,UAAoB,IAAdhV,EAAKgV,KAAqByC,GAAgBzX,EAAKgV,WAAQ,EAC7DC,QAASjV,EAAKiV,QACdrC,UAAgC,IAA1B5S,EAAK0S,YAAYJ,KAAqB,CAAEA,KAAMtS,EAAK0S,YAAYJ,WAAS,EAC9E0E,YACAC,sBAECuC,IAGE,OAAAxV,CAAA,GACT,EA15BFuQ,GAAAA,IAAAA,QACAgE,GAAAA,IAAAA,QACAJ,GAAAA,IAAAA,QACA6C,GAAAA,IAAAA,QACA1C,GAAAA,IAAAA,QACAI,GAAAA,IAAAA,QAiHMO,GAAAA,IAAAA,QAAAgC,GAAsB,eAAC1B,EAA8BtE,EAAsC,CAAC,MAC1F,MAAAuE,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MAEnB+X,EAAS0E,GAAqB3B,GAE9BhP,QAAiBuD,GAAa,CAClC5F,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,UAElBvK,YAAa,CAAEgN,WACfpL,KAAM2M,KACHgD,IAGCtB,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MAC3B,OAAOob,GAAWrH,GAAK,SAAK0F,EAAc1F,GAAK,SAAQjI,EAAU0K,EACnE,EAEM8D,GAAAA,IAAAA,QAAAoC,GAAmB,eACvBxB,EACAJ,EACAtE,EAAsC,CAAC,MACvC,WAAE+D,EAAYJ,UAAAA,IAER,MAAAY,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MAEnB+X,EAAS0E,GAAqB3B,GAE9BhP,QAAiByD,GAAmB,CACxC9F,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,SAChBmH,YAEF9P,KAAM2M,EACNvO,YAAa,CAAE+Q,aAAY/D,UAAS2D,gBACjCY,IAGCtB,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MAC3B,OAAOob,GAAWrH,GAAK,SAAK0F,EAAc1F,GAAK,SAAQjI,EAAU0K,EACnE,EAEM6D,GAAAA,IAAAA,QAAAsC,GAAuB,eAACL,EAAiC9F,EAAsC,CAAC,MAC9F,MAAAuE,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MAEnBsQ,EAAUgM,EAAQpH,KAAK4F,GAAW2B,GAAqB3B,KAEvDhP,QAAiB6D,GAAuB,CAC5ClG,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,UAElBvK,YAAa,CAAEgN,WACfpL,KAAM,CAAEkF,cACLyK,IAGD,IAAC6B,GAAsB9Q,GACnB,UAAIvJ,MAAM,2DAGZ,MAAAkX,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MAC3B,OAAO8L,EAASwE,SAAS4E,KAAK+D,GAASmC,GAAWrH,GAAK,SAAK0F,EAAc,GAAAzZ,KAAK8V,IAAQmD,EAAMzC,IAC/F,EAmRMmF,GAAAA,IAAAA,QAAAkB,GAAmB,eACvB3B,EACAJ,EACAtE,EAAsC,CAAC,MACvC,UAAE2D,IAEI,MAAAY,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MAEnB+X,EAAS0E,GAAqB3B,GAEhC,IACI,MAAAhP,QAAiB0D,GAAmB,CACxC/F,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,SAChBmH,YAEF1R,YAAa,CAAEgN,UAAS2D,aACxB/O,KAAM2M,KACHgD,IAGCtB,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MAC3B,OAAOob,GAAWrH,GAAK,SAAK0F,EAAc1F,GAAK,SAAQjI,EAAU0K,EAM3D,CANkE,MACjElU,GACP,GAAI8B,EAAS9B,IAAmB,MAAbA,EAAEuG,OACZ,YAGH,MAAAvG,CAAA,CAEV,EAwEMuZ,GAAAA,IAAAA,QAAAiB,GAAmB,eACvB5B,EACAJ,EACAtE,EAAsC,CAAC,MACvC,UAAE2D,IAEI,MAAAY,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MAEnB8L,QAAiB2D,GAAmB,CACxChG,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,SAChBmH,YAEF1R,YAAa,CAAEgN,UAAS2D,aACxB/O,KAAM0P,KACHC,IAGCtB,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MAC3B,OAAOob,GAAWrH,GAAK,SAAK0F,EAAc1F,GAAK,SAAQjI,EAAU0K,EACnE,EAqLMuF,GAAAA,IAAAA,QAAAgB,GAAa,eAAC7B,EAAkB1E,EAAsC,CAAC,MACrE,MAAAuE,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,MAErB,IACI,MAAA8L,QAAiB4D,GAAa,CAClCjG,WAAY,CACVkB,UAAW,gBACXqQ,aAAc,aACdpQ,OAAQ,WACRqQ,UAAWlH,GAAK,SAChBmH,YAEF1R,YAAa,CAAEgN,cACZuE,IAGCtB,QAAqBnC,GAAAA,KAAK6D,GAAL,SAAAnb,MAC3B,OAAOob,GAAWrH,GAAK,SAAK0F,EAAc1F,GAAK,SAAQjI,EAAU0K,EAM3D,CANkE,MACjElU,GACP,GAAI8B,EAAS9B,IAAmB,MAAbA,EAAEuG,OACZ,YAGH,MAAAvG,CAAA,CAEV,EA+HM0a,GAAAA,IAAAA,QAAAC,GAAc,eAACpT,EAAkC2J,EAAuBlD,SACtEyD,GAAAA,KAAKwI,IAAOW,IAAa,YAAAld,KAAK8V,OAAUjM,EAAMrE,QAAS,CAAE2X,KAAM,IAAIC,KAAQ5J,OAAMlD,WACzF,EAEM+M,GAAAA,IAAAA,QAAAC,GAAoC,eACxCzT,GAEA,MAAMrE,EAAM,SAASuO,GAAK,YAAUlK,EAAMrE,QACpCD,QAAewO,GAAK,SAAOhN,IAAyDvB,GAC1F,IAAKD,EAAe,YAEd,MAAEkR,MAAOgC,EAAM,GAAAzY,KAAKuc,IAAOgB,iBAAoB1T,EAAMoN,kBAC3D,GAAIwB,EAAM,EAAU,YAEpB,MAAM+E,EAAajY,EAAO4X,KAAKM,UAAYhF,EAAM2E,KAAKM,MACtD,OAAOF,EAAa,KAAOjY,CAC7B,EAEM4V,GAAAA,IAAAA,QAAAwC,GAAgB,iBACpB,GAAI5J,GAAK,SAAe,OAAOA,GAAK,SAC9B,MAAAgH,QAAmBhH,GAAAA,KAAK+F,IAAL,KAAA9Z,OAEnB,OAAEqZ,SAAiBrM,EAAiB,CACxCvD,WAAY,CAAEkB,UAAW,gBAAiBqQ,aAAc,aAAcpQ,OAAQ,eAC3EmQ,IAIL,OADArH,GAAAA,KAAKmG,GAAgBR,EAAOuE,QACrBvE,EAAOuE,MAChB,EAGF,MAAMnB,GAAwB3B,GACrBrV,OAAOC,QAAQoV,GAAQnR,QAAO,CAACC,GAAMpE,EAAKzE,KAEnC,SAARyE,EAAuBoE,EAGpB,IAAKA,EAAK,CAACpE,GAAMmT,GAAe5X,GAASA,EAAM2B,GAAK3B,IAC1D,CAAC,GAGOqa,GAAa,CACxBzB,EACAF,EACApJ,EACAyK,EACA+C,KAEA,MAAMtY,EAA8B,CAAC,GAC/B,KAAEuY,KAAS5F,GAAS4C,GAAU,CAAC,EAC9BrV,OAAAA,OAAOF,EAAQ2S,GAEtB,MAAM,QAAE1B,GAAYiD,EAAaH,MAAM,EAAEzY,UAAWA,IAASwP,KAAU,CAAC,EACnEmG,GAAiB4B,QAAAA,MAAM,SAAS/H,yBAE1B,UAAA+G,KAAUZ,GAAW,GAAI,CAE9B,IAACuH,GAAcF,EAAiBzG,GAAS,SAEvC,MAAArW,EAAQwE,EAAO6R,EAAOvW,MAE5B,OAAQuW,EAAO3V,MACb,IAAK,WAAY,CACf,MAAM0b,OAAiB,IAAVpc,EAAsB,IAAIqc,KAAKrc,QAAmB,EAE3Doc,GAAQa,MAAMb,EAAKM,WACrBrF,QAAQhP,MAAM,wBAAwBrI,eAAmBqW,EAAOvW,QACvDsc,IACT5X,EAAO6R,EAAOvW,MAAQsc,GAGxB,MAEF,IAAK,OAAQ,CACL,MAAAc,EAAY7G,EAAO8G,MAAM7N,MAE/B,GAAK4N,EAEL,GAAW7Z,EAASrD,GAAQ,CAC1B,MAAMod,EAAsBN,EAAgBlU,QAAQ,CAAAC,EAAKqP,KACnD,GAAAA,IAAS7B,EAAOvW,KACX,UAAI+I,EAAK,KAGlB,GAAIqP,EAAKmF,WAAc,GAAAhH,EAAOvW,SAAU,CACtC,MAAO,IAAKc,GAAQsX,EAAKoF,MAAM,KAC/B,MAAO,IAAIzU,EAAKjI,EAAKwF,KAAK,KAAI,CAGzB,OAAAyC,CAAA,GACN,IAEHrE,EAAO6R,EAAOvW,MAAQua,GAAWzB,EAAIF,EAAcwE,EAAWld,EAAOod,EAAmB,MAExF5Y,EAAO6R,EAAOvW,MAAQ,UAjBduX,QAAAA,MAAwC,kCAAAhB,EAAOvW,QAoBzD,MAEF,QACS0E,EAAAA,EAAO1E,MAAQE,GAAS,MACR,IAAnBqW,EAAOkH,SAA8B,OAAVvd,GACrBqX,QAAAA,MAA6B,uBAAAhB,EAAOvW,gDAE9C,MACJ,CAGK0E,EAAAA,KAAO,SAAUiR,GACtB,OAAOmD,EAAGtJ,GAAOgL,KAAK9V,EAAO,MAAiBiR,EAAO,EAGvDjR,EAAOmW,OAAS,SAAUna,EAAW+D,EAAS0N,GAC5C,MAAMwD,EAAU9R,EAAcY,GAAKA,EAAI,CAAC,KAClC6U,EAAYC,GAAe9U,EAAG0N,GAE7B,OAAA2G,EAAGtJ,GAAOqL,OAAOnW,EAAO,MAAiBhE,EAAMiV,EAAS,CAAE2D,aAAW,EAG9E5U,EAAO6E,QAAU,SAAU7I,EAAW+D,EAAS0N,GAC7C,MAAMwD,EAAU9R,EAAcY,GAAKA,EAAI,CAAC,KAClC6U,EAAYC,GAAe9U,EAAG0N,GAE7B,OAAA2G,EAAGtJ,GAAOkO,gBAAgBhZ,EAAO,MAAiBhE,EAAMiV,EAAS,CAAE2D,aAAW,EAGvF5U,EAAOuW,OAAS,WACd,OAAOnC,EAAGtJ,GAAOyL,OAAOvW,EAAO,MAAe,EAGhDA,EAAOiZ,YAAc,WACZ,OAAAV,CAAA,EAGT,IAAK,MAAMW,IAAQ,CAAC,OAAQ,SAAU,UAAW,SAAU,eACzDhZ,OAAOsR,eAAexR,EAAQkZ,EAAM,CAAEzH,YAAY,IAI7C,OADPvR,OAAOiZ,OAAOnZ,GACPA,CAAA,EAGT,SAASqX,GAAsB7b,GAC7B,OAAOqD,EAASrD,IAAUuD,MAAMC,QAAQxD,EAAMuP,QAChD,CAEA,SAASoK,GAAU3Z,GACjB,OAAI0D,EAAS1D,GAAeA,EACxBqD,EAASrD,IAAU0D,EAAS1D,EAAM2B,IAAY3B,EAAM2B,QAAxD,CAEF,CAEA,SAASqb,GAAcvH,EAAmBY,GAEpC,GAAAZ,EAAQ3K,SAAS,KAAa,SAG9B,GAAgB,SAAhBuL,EAAO3V,KAAiB,CACpB,MAAAkd,EAAcnI,EAAQrS,QAAQ8U,GAASA,EAAKmF,WAAWhH,EAAOvW,QAEpE,OAAO8d,EAAY3U,OAAS,EAIvB,OAAAwM,EAAQ3K,SAASuL,EAAOvW,KACjC,CAEA,SAASuZ,MAAkBtF,GACzB,IAAK,MAAM8J,KAAO9J,EAChB,GAAI1Q,EAASwa,IAAQha,EAASga,EAAIzE,WAChC,OAAOyE,EAAIzE,SAKjB,C,ICvzDA,G,iVAeO,MAAM0E,GAMXrW,YAAYE,EAA8B,IAL1C+K,GAAAA,KAAAA,QAAAA,GAMOC,GAAAA,KAAAA,GAAAA,IAAWoL,KACX,KAAAC,SAAWrW,EAAQsW,KAAO,IAC1B,KAAAzB,gBAAkB7U,EAAQ6U,iBAAmB,GAAK,CAGzDza,eACS,OAAA2C,OAAOwZ,YAAY,GAAAjf,KAAKkf,IAAI,CAGrCpc,UAAa0C,GACX,OAAQuO,GAAK,SAAKhN,IAAIvB,IAAQ,KAGhC1C,UAAa0C,EAAazE,GAIxB,SAHMf,KAAK8b,OAAOtW,GACbuO,GAAAA,KAAAA,IAAKmJ,IAAI1X,EAAKzE,GAEfgT,GAAK,SAAKF,KAAO7T,KAAK+e,SAAU,CAClC,MAAMI,EAAoBpL,GAAK,SAAKtR,OAAO2c,OAAOre,YAC5Cf,KAAK8b,OAAOqD,EAAiB,CACrC,CAGFrc,aAAa0C,GACNuO,GAAAA,KAAAA,IAAK+H,OAAOtW,EAAG,CAGtB1C,cACS,UAAA9C,KAAKkf,IAAKG,OAAM,EAlCzBH,GAAAA,IAAAA,Q,IChBF,M,iVAwBO,MAAMI,WAAiExM,GAI5EtK,YAAYiR,GACJ,QAJRhG,GAAAA,KAAAA,GAA2C,CAAC,GAC5CA,GAAAA,KAAAA,QAAAA,GAKEC,GAAAA,KAAKmG,GAAgBJ,EAAA,CAGvB8F,MAAM3F,GACJ,MAAMD,EAAU,IAAI6F,MAClB,CAAC,EACD,CACEzY,IAAK,CAAC0Y,EAASpP,KACT,IAAC5L,EAAS4L,GAAc,UAAI9N,MAAM,sBAKtC,YAJ4B,IAAxB,GAAAvC,KAAK0f,IAAQrP,KACV0D,GAAAA,KAAAA,IAAQ1D,GAAS,IAAImJ,GAAe,CAAEG,KAAIC,gBAAevJ,QAAOoJ,aAAc1F,GAAK,YAGnFA,GAAAA,KAAK2L,IAAQrP,EAAA,IAMpBsP,EAAa5L,GAAK,UAAemB,KAAK,EAAErU,UAAWA,KAAS,GAClE,IAAK,MAAMwP,KAASsP,EACfhG,EAAAA,GAAS,IAAIH,GAAe,CAAEG,KAAIC,gBAAevJ,QAAOoJ,aAAc1F,GAAK,WAGzE,OAAA4F,CAAA,EA9BT+F,GAAAA,IAAAA,QACA7F,GAAAA,IAAAA,Q,IC1BF,e,iYA0DO,MAAM+F,WAAiE9M,GAG5EtK,YAAoBmR,EAAiCF,GAC7C,QADY,KAAAE,GAAAA,EAsCdlG,GAAAA,KAAAA,IAkBAA,GAAAA,KAAAA,IA1DNA,GAAAA,KAAAA,QAAAA,GAIEC,GAAAA,KAAKmG,GAAgBJ,EAAA,CAGvB8F,OAAM,cAAEvF,IACC,OACLpD,IAAK9T,MAA2C+G,EAAenB,EAA0C,CAAC,KACxG,MAAM4H,QAAgBgH,GAAAA,KAAKuI,GAAL,SAAA7f,KAAa6J,EAAOnB,EAASsR,GAC7CP,QAAqBnC,GAAK,YAALC,KAAsB,KAAAyC,GAE1C,OAAA1J,EAAQ4E,KAAK6C,IAClB,MAAM,MAAE1H,EAAQ,UAAa0H,EAAO+F,KAGpC,MAAO,CAAEzN,QAAO0H,OAAQqD,GAAWpb,KAAK2Z,GAAIF,EAAcpJ,EAAO0H,EAAQ,CAAC,MAAO,GACjF,EAEJ+H,QAAShd,MACP+G,EACAnB,EAA0C,CAAC,KAE3C,MAAM4H,QAAgBgH,GAAAA,KAAKuI,GAAL,SAAA7f,KAAa6J,EAAOnB,EAASsR,GAC7CP,QAAqBnC,GAAK,YAALC,KAAsB,KAAAyC,GAEjD,OAAO1J,EAAQ3G,QAAO,CAACC,EAAKmO,KAC1B,MAAM,MAAE1H,EAAQ,UAAa0H,EAAO+F,KAE9BiC,EAAQnW,EAAIyG,IAAU,GAEtB4I,EAAOmC,GAAWpb,KAAK2Z,GAAIF,EAAcpJ,EAAO0H,EAAQ,CAAC,MAExD,UAAKnO,EAAK,CAACyG,GAAQ,IAAI0P,EAAO9G,GAAO,GAC3C,CAAC,EAAS,EAEjB,EArCFY,GAAAA,IAAAA,QAwCMgG,GAAAA,IAAAA,QAAAG,GAA2C,eAC/CnW,EACAnB,EACAsR,GAEM,MAAAe,QAAmBf,KACnB,OAAE4D,EAAQ5B,UAAAA,EAAS,UAAEE,EAAS,OAAED,GAAWvT,GAAW,CAAC,GAEvD,QAAE4H,SAAkBT,GAAa,CACrCpG,WAAY,CAAEkB,UAAW,gBAAiBqQ,aAAc,aAAcpQ,OAAQ,YAE9EQ,KAAM,CAAEwS,SAAQ/T,QAAOmS,YAAWC,SAAQC,gBACvCnB,IAGE,OAAAzK,CACT,EAEM6K,GAAAA,IAAAA,QAAAwC,GAAgB,eAAC3D,GACrB,GAAIjG,GAAK,SAAe,OAAOA,GAAK,SAC9B,MAAAgH,QAAmBf,KAEnB,OAAEX,SAAiBrM,EAAiB,CACxCvD,WAAY,CAAEkB,UAAW,gBAAiBqQ,aAAc,aAAcpQ,OAAQ,eAC3EmQ,IAIL,OADArH,GAAAA,KAAKmG,GAAgBR,EAAOuE,QACrBvE,EAAOuE,MAChB,EC3HW,MAAAqC,GAA2BC,GACX,oBAAbA,ECQhB,eAAsBC,GAAqBzX,GACzC,MAAM,OAAEvC,EAAM,UAAEG,GAAcX,IAE9B,GAAIQ,EAAQ,CACV,MAAMia,QAAgBC,GAAkBla,EAAQuC,GAC5C,GAAA0X,EAAgB,OAAAja,EAEZiS,QAAAA,KAAK,UAAUjS,mCAAuC,CAG1D,MAAAma,EAAYha,SAAoBU,IAC/B,OAAAuZ,GAAkBD,EAAW5X,EACtC,CAOA5F,eAAeyd,GAAkBD,EAA+B5X,GACxD,MAAA1C,EAAc0C,GAAS1C,aAAewa,KACtC3a,EAAS6C,GAAS7C,QAAUoC,IAElC,IAAKjC,EACH,MAAM,IAAIzD,MACR,iHAEJ,IAAKsD,EACH,MAAM,IAAItD,MACR,yGAGE,MAAC2J,EAAS,CAAGjB,EAAK,CAAGwV,GAAUza,EAAYqY,MAAM,KACjDqC,EAAWlO,GAAwBvH,GACzC,IAAKyV,EAAgB,UAAIne,MAAM,yCAAyCyD,KAClE,gBAAE2E,EAAWC,OAAAA,GAAW8V,GAExB,eAAEha,GAAmBf,KAErB,OAAEQ,SAAiBsH,EAAc,CACrC5H,SACA4E,OAAQzE,EACRsC,UAAWJ,EAAuBQ,GAASJ,WAC3CkC,iBAAkB,GAAG0B,MAAajB,IAClCxB,WAAY,CAAEgX,SAAQ9V,YAAWC,UACjCpB,YAAa,CAAE8W,YAAW5Z,kBAC1B4E,MAAOzI,IAGF,OAAAsD,CACT,CAEArD,eAAeud,GAAkBla,EAAgBuC,GACzC,MAAA1C,EAAc0C,GAAS1C,aAAewa,KACtC3a,EAAS6C,GAAS7C,QAAUoC,IAElC,IAAKjC,EACH,MAAM,IAAIzD,MACR,iHAEJ,IAAKsD,EACH,MAAM,IAAItD,MACR,yGAGE,MAAC2J,EAAS,CAAGjB,EAAK,CAAGiF,GAAYlK,EAAYqY,MAAM,KACnDqC,EAAWlO,GAAwBvH,GACzC,IAAKyV,EAAgB,UAAIne,MAAM,yCAAyCyD,KAClE,gBAAE2E,EAAWC,OAAAA,GAAW8V,EAE1B,IACF,aAAa1T,EAAiB,CAC5BnH,SACA4E,OAAQzE,EACRsC,UAAWJ,EAAuBQ,GAASJ,WAC3CkC,iBAAkB,GAAG0B,MAAajB,IAClCxB,WAAY,CAAEuR,aAAc,GAAG9K,KAAY/J,IAAUwE,YAAWC,UAChEU,MAAOzI,GAIH,CAHL,MACMkC,GACP,GAAIX,EAASW,IAAuB,MAAfA,EAAI8D,OAAuB,YAC1C,MAAA9D,CAAA,CAEV,CAEO,SAASyb,KACV,IACI,kBAAExa,GAAgBL,IACjB,OAAAK,CAEA,CAFA,MACAjB,GACA,OAEX,C,qYC7Ea,MAAA4b,GAAgEC,IA7B7E,sBA8BQ,eAOJpY,YAAYE,EAA6B,CAAC,EAAG+Q,GAwC7ChG,GAAAA,KAAAA,GAsBMA,GAAAA,KAAAA,GAmBAA,GAAAA,KAAAA,GAvFNA,GAAAA,KAAAA,OAAAA,GACAA,GAAAA,KAAAA,OAAAA,GAMQ,MAAAoN,EAAcvJ,GAAK,UAALC,KAAmB,KAAA7O,GACvCgL,GAAAA,KAAKzQ,EAAW4d,GAEhB,MAAMjH,EAAmC,CACvCI,cAAe,IAAM1C,GAAK,UAALC,KAAoB,KAAAsJ,GACzCpK,MAAOoK,EAAYpK,MACnBnL,MAAOuV,EAAYvV,OAGfqO,EAAK,IAAI2F,GAAa7F,GAAc8F,MAAM3F,GAC1CkH,EAAS,IAAIlB,GAAajG,EAAIF,GAAc8F,MAAM3F,GAGxD5Z,KAAK2Z,GAAKA,EACV3Z,KAAK8gB,OAASA,EAEH,UAACtb,EAAKub,KAActb,OAAOC,QAAQkb,GAAW,CAAC,GAAI,CAC5D,QAAkB,IAAdG,EAAyB,SACvB,MAAAxb,EAASwb,EAAUxB,MAAM3F,GAE3BrU,aAAkBpD,QACfoD,EAAOlD,MAAM0e,IAEhB/gB,KAAKwF,GAAOub,CAAAA,IAId/gB,KAAKwF,GAAOD,CACd,CACF,CAGF,kBACQ,MAAAS,EAAc+N,GAAAA,KAAK9Q,GAAS+C,YAC5BG,QAAe4N,GAAK,QAAS5N,SAE5B,OAAEH,cAAaG,SAAO,GA3C/B,cACAlD,EA6CA,4BAAa,SAACyF,GACN,MAAAL,EAAQH,EAAuBQ,GAASL,OACxCrC,EAAc0C,GAAS1C,aAAewa,KACtC3a,EAAS6C,GAAS7C,QAAUoC,IAC5BwO,EAAQ/N,GAAS+N,OAAS,IAAIoI,GAAY,CAAEtB,gBAAiB,IAC7DjS,EAAQ5C,GAAS4C,OAASzI,EAC1BsD,EAASrD,cACO,IAApB4F,GAASvC,aACCmR,GAAAA,KAAK0J,EAAL,QAAAhhB,KAAqB0I,EAAQvC,cAC7Bga,GAAqB,CAAEta,SAAQG,cAAasC,UAAWI,GAASL,QAE5E,IAAKxC,EACG,UAAItD,MAAM,6BAGlB,IAAKyD,EACG,UAAIzD,MAAM,kCAGX,OAAE8F,QAAOrC,cAAaH,SAAQM,SAAQsQ,QAAOnL,QAAOE,SAAUuH,KAAe,EAGhF+G,EAAc,8BAAC,MAAEzR,EAAK,OAAExC,EAAM,YAAEG,EAAaG,OAAAA,EAAM,MAAEmF,EAAOE,SAAAA,IAChE,MAAMyV,QAAoB3J,GAAK,UAALC,KAAqB,KAAApR,GAC/C,IAAK8a,EAAmB,UAAI1e,MAAM,kCAE3B,OACL+F,UAAWD,EACXxC,SACA4E,OAAQ,GAERD,iBAAkB,CAAC7I,EAAMC,KACjB,MAAAsf,EAAYtf,EAAOoZ,cAAgBpZ,EAAOuE,OAC1Cgb,EAAUxf,EAAKyI,QAAQ,oBAA8B,IAAd8W,EAA0B,IAAID,IAAgB,IAC3F,OAAOjb,EAAcmb,CAAA,EAEvB7V,QACAE,WACF,EAGIwV,EAAe,6BAACI,GACpB,GAAIrN,GAAK,QAAS,OAAOA,GAAK,QAC9B,QAAc,IAAVqN,EAA4B,OAE1B,MAAAC,EAAa/c,MAAMC,QAAQ6c,GAAS,IAAIA,GAAS,CAACA,GAElDE,EAAiBxe,SACdmd,GAAwBC,SAAkBA,IAAaA,EAGhE,UAAW,MAAMA,KAAYmB,EAAY,CACjC,MAAAlb,QAAemb,EAAepB,GACpC,GAAI/Z,EAEK,OADPuN,GAAAA,KAAK6N,EAAUpb,GACRA,CACT,CACF,EAxGJ,GAiIW,MAAAqb,WAAmBb,OC5JhC,MAAMc,GAAO,KACPC,GAAQ,MAGP,MAAMC,GAANnZ,cACL,KAAAoZ,QAA+B,CAAC,EAEhCC,IAAIC,GACG,KAAAF,QAAQE,EAAMjhB,MAAQihB,CAAA,CAG7BC,OAAUxgB,GAKR,SAASygB,EAAMC,GACT,GAAA3d,MAAMC,QAAQ0d,GAAa,OAAAA,EAAI/M,IAAI8M,GAEvC,MAAMvgB,SAAcwgB,EACpB,GAAa,cAATxgB,EAA6B,OAAE,CAACggB,IAAO,aAC3C,GAAa,WAAThgB,EAA0B,OAAE,CAACggB,IAAO,SAAU,CAACC,IAAQO,EAAI9c,YAC3D,GAAQ,OAAR8c,GAAyB,WAATxgB,EAA0B,OAAAwgB,EAE9C,MAAMzZ,EAAcyZ,EAAIzZ,YAClB0Z,EAAyB,CAAE,CAACT,IAAOjZ,EAAY3H,MACrD,IAAK,MAAO2E,EAAKzE,KAAU0E,OAAOC,QAAQuc,GACtCC,EAAAA,GAAOF,EAAMjhB,GAKV,OAHHyH,IAAgB4U,OAAQ8E,EAAAA,IAASD,EAAIE,eACrC3Z,IAAgBsW,MAAOoD,EAAAA,IAASzc,OAAOwZ,YAAYgD,IACnDzZ,IAAgB4Z,MAAOF,EAAAA,IAAS,IAAID,IACjCC,CAAA,CAGT,OAAOnW,KAAKC,UAAUgW,EAAMzgB,GAAK,CAGnC8gB,SAAYhW,GACV,OAAON,KAAKuW,MAAMjW,GAAM,CAAC7G,EAAKzE,KAExB,GAAAA,GAA0B,kBAAVA,IAAuBuD,MAAMC,QAAQxD,GAAQ,CAC/D,MAAM,CAAG0gB,IAAOK,EAAA,CAAQJ,IAAQa,KAAQrK,GAASnX,EAC3CyH,EAAcxI,KAAK4hB,QAAQE,GAGjC,GAAItZ,EACF,OAAO/C,OAAO+c,OAAO/c,OAAOgd,OAAOja,EAAYka,WAAYxK,GAE7D,GAAc,SAAV4J,EAAyB,WAAI1E,KAAKmF,GACtC,GAAc,QAAVT,EAAwB,WAAIM,IAAIG,GACpC,GAAc,QAAVT,EAAiB,OAAO,IAAIhD,IAAIrZ,OAAOC,QAAQ6c,IACnD,GAAc,WAAVT,EAAoB,OAAOa,OAAOJ,GAGtC,GAAc,cAAVT,EAA8B,OAC3B,OAAA5J,CAAA,CAEF,OAAAnX,CAAA,GACR,EAIqB,IAAI4gB,GClEvB,MAAMiB,WAAkBrgB,MAG7BiG,YAAYC,EAAiBI,GAC3BF,MAAMF,GACNzI,KAAK6I,OAASA,CAAA,ECDlB,MAAM+U,GAAS,CACb,CACE/c,KAAM,QACN2V,QAAS,CACP,CAAE3V,KAAM,WAAYY,KAAM,UAC1B,CAAEZ,KAAM,QAASY,KAAM,SACvB,CAAEZ,KAAM,WAAYY,KAAM,aAK1BohB,GAAiBlC,KACjBmC,GAAiB,CACrB9c,YACE,uFACFH,OAAQ,yBAKH,MAAMkd,WAAmBF,GAC9Bra,YAAYE,GACVC,MAAM,IAAKma,MAAmBpa,GAAWkV,GAC3C,EAEF,IAAIoF,GAEG,MAAMC,GAAgB,IACvBD,KACJA,GAAW,IAAID,GACRC,G","sources":["webpack://invoice-generator/./src/views/SigninView.vue","webpack://invoice-generator/src/views/SigninView.vue","webpack://invoice-generator/./src/views/SigninView.vue?41cf","webpack://invoice-generator/./src/views/SigninView.vue?2906","webpack://invoice-generator/./src/views/SignupView.vue","webpack://invoice-generator/src/views/SignupView.vue","webpack://invoice-generator/./src/views/SignupView.vue?827a","webpack://invoice-generator/./src/views/SignupView.vue?9d1c","webpack://invoice-generator/./node_modules/@xata.io/client/dist/ lazy strict namespace object","webpack://invoice-generator/../src/schema/tracing.ts","webpack://invoice-generator/../src/util/lang.ts","webpack://invoice-generator/../src/util/environment.ts","webpack://invoice-generator/../src/util/apiKey.ts","webpack://invoice-generator/../src/util/fetch.ts","webpack://invoice-generator/../src/version.ts","webpack://invoice-generator/../src/api/errors.ts","webpack://invoice-generator/../src/api/fetcher.ts","webpack://invoice-generator/../src/api/dataPlaneFetcher.ts","webpack://invoice-generator/../src/api/dataPlaneComponents.ts","webpack://invoice-generator/../src/api/controlPlaneFetcher.ts","webpack://invoice-generator/../src/api/controlPlaneComponents.ts","webpack://invoice-generator/../src/api/components.ts","webpack://invoice-generator/../src/api/providers.ts","webpack://invoice-generator/../src/api/client.ts","webpack://invoice-generator/../src/plugins.ts","webpack://invoice-generator/../src/util/uuid.ts","webpack://invoice-generator/../src/schema/filters.ts","webpack://invoice-generator/../src/schema/pagination.ts","webpack://invoice-generator/../src/schema/query.ts","webpack://invoice-generator/../src/schema/record.ts","webpack://invoice-generator/../src/schema/sorting.ts","webpack://invoice-generator/../src/schema/repository.ts","webpack://invoice-generator/../src/schema/cache.ts","webpack://invoice-generator/../src/schema/index.ts","webpack://invoice-generator/../src/search/index.ts","webpack://invoice-generator/../src/util/branches.ts","webpack://invoice-generator/../src/util/config.ts","webpack://invoice-generator/../src/client.ts","webpack://invoice-generator/../src/serializer/index.ts","webpack://invoice-generator/../src/index.ts","webpack://invoice-generator/./src/xata.js"],"sourcesContent":["var render = function render(){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"bg-lightest-blue vh-100\"},[_c('div',{staticClass:\"pv5 ph2\"},[_c('form',{staticClass:\"ba b--dark-blue bw3 bg-white br2 mw6 w-40-m w-70 w-20-l center pa3 shadow-5\",on:{\"submit\":function($event){$event.preventDefault();return _vm.signIn.apply(null, arguments)}}},[_c('h2',{staticClass:\"ttc tc\"},[_vm._v(\" Sign In \")]),_c('label',{staticClass:\"db mb2 black-70\",attrs:{\"for\":\"email\"}},[_vm._v(\"Email\")]),_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.email),expression:\"email\"}],staticClass:\"db mb3 w-100 br2 ph2 pv3 ba bw1 b--lightest-blue\",attrs:{\"id\":\"email\",\"name\":\"email\",\"type\":\"email\",\"placeholder\":\"example@email.com\"},domProps:{\"value\":(_vm.email)},on:{\"input\":function($event){if($event.target.composing)return;_vm.email=$event.target.value}}}),_c('label',{staticClass:\"db mb2 black-70\",attrs:{\"for\":\"password\"}},[_vm._v(\"Password\")]),_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.password),expression:\"password\"}],staticClass:\"db mb3 w-100 br2 ph2 pv3 ba bw1 b--lightest-blue\",attrs:{\"id\":\"password\",\"name\":\"password\",\"type\":\"password\",\"placeholder\":\"\"},domProps:{\"value\":(_vm.password)},on:{\"input\":function($event){if($event.target.composing)return;_vm.password=$event.target.value}}}),_c('button',{staticClass:\"center db pa3 mb3 tracked bg-dark-blue ba br3 white pointer hover-black hover-bg-lightest-blue bg-animate pointer\",attrs:{\"type\":\"submit\"}},[_vm._v(\" Sign in \")])])])])\n}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","<template>\r\n  <div class=\"bg-lightest-blue vh-100\">\r\n    <div class=\"pv5 ph2\">\r\n      <form class=\"ba b--dark-blue bw3 bg-white br2 mw6 w-40-m w-70 w-20-l center pa3 shadow-5\" @submit.prevent=\"signIn\">\r\n        <h2 class=\"ttc tc\">\r\n          Sign In\r\n        </h2>\r\n\r\n        <label for=\"email\" class=\"db mb2 black-70\">Email</label>\r\n        <input\r\n          id=\"email\"\r\n          v-model=\"email\"\r\n          name=\"email\"\r\n          type=\"email\"\r\n          class=\"db mb3 w-100 br2 ph2 pv3 ba bw1  b--lightest-blue\"\r\n          placeholder=\"example@email.com\"\r\n        >\r\n\r\n        <label for=\"password\" class=\"db mb2 black-70\">Password</label>\r\n        <input\r\n          id=\"password\"\r\n          v-model=\"password\"\r\n          name=\"password\"\r\n          type=\"password\"\r\n          class=\"db mb3 w-100 br2 ph2 pv3 ba bw1  b--lightest-blue\"\r\n          placeholder=\"\"\r\n        >\r\n\r\n        <button type=\"submit\" class=\"center db pa3 mb3 tracked bg-dark-blue ba br3 white pointer hover-black hover-bg-lightest-blue bg-animate pointer\">\r\n          Sign in\r\n        </button>\r\n      </form>\r\n    </div>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nimport { getXataClient } from '@/xata'\r\n\r\nexport default {\r\n  data: () => ({\r\n    email: '',\r\n    password: ''\r\n  }),\r\n  methods: {\r\n    async signIn() {\r\n      const xata = getXataClient()\r\n      const user = await xata.db.users.filter('email', this.email).getFirst()\r\n      if (!this.email || !this.password ){\r\n        this.$notify({type: 'error', text: \"Please fill all empty fields\"})\r\n      } else if (this.email !== user.email || this.password !== user.password){\r\n        this.$notify({type: 'error', text: \"Incorrect credentials\"})\r\n        this.email = '';\r\n        this.password = '';\r\n      } else {\r\n        this.$router.push({path:`/dashboard/${user.username}`, params: user})\r\n        this.$notify({type: 'success', text: \"Login successful!\"})\r\n\r\n      }\r\n    }\r\n  }\r\n}\r\n</script>","import mod from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./SigninView.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./SigninView.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./SigninView.vue?vue&type=template&id=72963592&\"\nimport script from \"./SigninView.vue?vue&type=script&lang=js&\"\nexport * from \"./SigninView.vue?vue&type=script&lang=js&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","var render = function render(){var _vm=this,_c=_vm._self._c;return _c('div',{staticClass:\"bg-lightest-blue vh-100\"},[_c('div',{staticClass:\"pv5 ph2\"},[_c('form',{staticClass:\"ba b--dark-blue bw3 bg-white br2 mw6 w-40-m w-70 w-20-l center pa3 shadow-5\",on:{\"submit\":function($event){$event.preventDefault();return _vm.signUp.apply(null, arguments)}}},[_c('h2',{staticClass:\"ttc tc\"},[_vm._v(\" Sign up \")]),_c('label',{staticClass:\"db mb2 black-70\",attrs:{\"for\":\"name\"}},[_vm._v(\"Name\")]),_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.username),expression:\"username\"}],staticClass:\"db mb3 w-100 br2 ph2 pv3 ba bw1 b--lightest-blue\",attrs:{\"id\":\"name\",\"name\":\"name\",\"type\":\"text\",\"placeholder\":\"John Doe\"},domProps:{\"value\":(_vm.username)},on:{\"input\":function($event){if($event.target.composing)return;_vm.username=$event.target.value}}}),_c('label',{staticClass:\"db mb2 black-70\",attrs:{\"for\":\"email\"}},[_vm._v(\"Email\")]),_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.email),expression:\"email\"}],staticClass:\"db mb3 w-100 br2 ph2 pv3 ba bw1 b--lightest-blue\",attrs:{\"id\":\"email\",\"name\":\"email\",\"type\":\"email\",\"placeholder\":\"example@email.com\"},domProps:{\"value\":(_vm.email)},on:{\"input\":function($event){if($event.target.composing)return;_vm.email=$event.target.value}}}),_c('label',{staticClass:\"db mb2 black-70\",attrs:{\"for\":\"password\"}},[_vm._v(\"Password\")]),_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.password),expression:\"password\"}],staticClass:\"db mb3 w-100 br2 ph2 pv3 ba bw1 b--lightest-blue\",attrs:{\"id\":\"password\",\"name\":\"password\",\"type\":\"password\",\"placeholder\":\"\"},domProps:{\"value\":(_vm.password)},on:{\"input\":function($event){if($event.target.composing)return;_vm.password=$event.target.value}}}),_c('button',{staticClass:\"center db pa3 mb3 tracked bg-dark-blue ba br3 white pointer hover-black hover-bg-lightest-blue bg-animate pointer\",attrs:{\"type\":\"submit\"}},[_vm._v(\" Sign up \")]),_vm._m(0)])])])\n}\nvar staticRenderFns = [function (){var _vm=this,_c=_vm._self._c;return _c('p',[_vm._v(\"Already have an account? \"),_c('a',{staticClass:\"black-70 b\",attrs:{\"href\":\"/signin\"}},[_vm._v(\"Sign in\")])])\n}]\n\nexport { render, staticRenderFns }","<template>\r\n  <div class=\"bg-lightest-blue vh-100\">\r\n    <div class=\"pv5 ph2\">\r\n      <form class=\"ba b--dark-blue bw3 bg-white br2 mw6 w-40-m w-70 w-20-l center pa3 shadow-5\" @submit.prevent=\"signUp\">\r\n        <h2 class=\"ttc tc\">\r\n          Sign up\r\n        </h2>\r\n\r\n        <label for=\"name\" class=\"db mb2 black-70\">Name</label>\r\n        <input\r\n          id=\"name\"\r\n          v-model=\"username\"\r\n          name=\"name\"\r\n          type=\"text\"\r\n          class=\"db mb3 w-100 br2 ph2 pv3 ba bw1 b--lightest-blue\"\r\n          placeholder=\"John Doe\"\r\n        >\r\n\r\n        <label for=\"email\" class=\"db mb2 black-70\">Email</label>\r\n        <input\r\n          id=\"email\"\r\n          v-model=\"email\"\r\n          name=\"email\"\r\n          type=\"email\"\r\n          class=\"db mb3 w-100 br2 ph2 pv3 ba bw1 b--lightest-blue\"\r\n          placeholder=\"example@email.com\"\r\n        >\r\n\r\n        <label for=\"password\" class=\"db mb2 black-70\">Password</label>\r\n        <input\r\n          id=\"password\"\r\n          v-model=\"password\"\r\n          name=\"password\"\r\n          type=\"password\"\r\n          class=\"db mb3 w-100 br2 ph2 pv3 ba bw1 b--lightest-blue\"\r\n          placeholder=\"\"\r\n        >\r\n\r\n        <button type=\"submit\" class=\"center db pa3 mb3 tracked bg-dark-blue ba br3 white pointer hover-black hover-bg-lightest-blue bg-animate pointer\">\r\n          Sign up\r\n        </button>\r\n        <p>Already have an account? <a href=\"/signin\" class=\"black-70 b\">Sign in</a> </p>\r\n      </form>\r\n    </div>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nimport { getXataClient } from '@/xata'\r\n\r\nexport default {\r\n  name: 'signup',\r\n  data: () => ({\r\n    username: '',\r\n    email: '',\r\n    password: '',\r\n  }),\r\n  methods: {\r\n    async signUp() {\r\n      const xata = getXataClient()\r\n      const user = await xata.db.users.filter('username', this.username).getFirst()\r\n      if (!user) {\r\n        await xata.db.users.create({\r\n          username: this.username,\r\n          password: this.password,\r\n          email: this.email\r\n        }).then((res) => {\r\n          this.$router.push({path:`/dashboard/${res.username}`, params: user})\r\n        })\r\n        this.$notify({type: 'success', text: \"Account creation successful!\" })\r\n\r\n      }\r\n    }\r\n  }\r\n}\r\n</script>\r\n","import mod from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./SignupView.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./SignupView.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./SignupView.vue?vue&type=template&id=2af3ecb6&\"\nimport script from \"./SignupView.vue?vue&type=script&lang=js&\"\nexport * from \"./SignupView.vue?vue&type=script&lang=js&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","function webpackEmptyAsyncContext(req) {\n\t// Here Promise.resolve().then() is used instead of new Promise() to prevent\n\t// uncaught exception popping up in devtools\n\treturn Promise.resolve().then(function() {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t});\n}\nwebpackEmptyAsyncContext.keys = function() { return []; };\nwebpackEmptyAsyncContext.resolve = webpackEmptyAsyncContext;\nwebpackEmptyAsyncContext.id = 4674;\nmodule.exports = webpackEmptyAsyncContext;","export type AttributeDictionary = Record<string, string | number | boolean | undefined>;\n\nexport type TraceFunction = <T>(\n  name: string,\n  fn: (options: { setAttributes: (attrs: AttributeDictionary) => void }) => T,\n  options?: AttributeDictionary\n) => Promise<T>;\n\nexport const defaultTrace: TraceFunction = async <T>(\n  _name: string,\n  fn: (options: { setAttributes: (attrs: Record<string, string | number | boolean | undefined>) => void }) => T,\n  _options?: Record<string, any>\n): Promise<T> => {\n  return await fn({\n    setAttributes: () => {\n      return;\n    }\n  });\n};\n\nexport const TraceAttributes = {\n  KIND: 'xata.trace.kind',\n\n  VERSION: 'xata.sdk.version',\n\n  TABLE: 'xata.table',\n\n  HTTP_REQUEST_ID: 'http.request_id',\n  HTTP_STATUS_CODE: 'http.status_code',\n  HTTP_HOST: 'http.host',\n  HTTP_SCHEME: 'http.scheme',\n  HTTP_USER_AGENT: 'http.user_agent',\n  HTTP_METHOD: 'http.method',\n  HTTP_URL: 'http.url',\n  HTTP_ROUTE: 'http.route',\n  HTTP_TARGET: 'http.target'\n};\n","function notEmpty<T>(value: T | null | undefined): value is T {\n  return value !== null && value !== undefined;\n}\n\nexport function compact<T>(arr: Array<T | null | undefined>): T[] {\n  return arr.filter(notEmpty);\n}\n\nexport function compactObject<T>(obj: Record<string, T | null | undefined>): Record<string, T> {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value))) as Record<string, T>;\n}\n\nexport type PartialBy<T, K extends keyof T> = Omit<T, K> & Partial<Pick<T, K>>;\n\nexport function isObject(value: any): value is Record<string, unknown> {\n  return Boolean(value) && typeof value === 'object' && !Array.isArray(value);\n}\n\nexport function isDefined<T>(value: T | null | undefined): value is T {\n  return value !== null && value !== undefined;\n}\n\nexport function isString(value: any): value is string {\n  return isDefined(value) && typeof value === 'string';\n}\n\nexport function isStringArray(value: any): value is string[] {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\n\nexport function isNumber(value: any): value is number {\n  return isDefined(value) && typeof value === 'number';\n}\n\nexport function toBase64(value: string): string {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer; // Avoid \"A Node.js API is used which is not supported in the Edge Runtime\" in Vercel Edge middleware\n    return buf.from(value).toString('base64');\n  }\n}\n\nexport function deepMerge<A extends Record<string, any>, B extends Record<string, any>>(a: A, b: B) {\n  const result: Record<string, any> = { ...a };\n\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n\n  return result as DeepMergeResult<A, B>;\n}\n\ntype DeepMergeResult<A extends Record<string, any>, B extends Record<string, any>> = {\n  [K in keyof A | keyof B]: K extends keyof A\n    ? K extends keyof B\n      ? A[K] extends Record<string, any>\n        ? B[K] extends Record<string, any>\n          ? DeepMergeResult<A[K], B[K]>\n          : B[K]\n        : B[K]\n      : A[K]\n    : K extends keyof B\n    ? B[K]\n    : never;\n};\n","// eslint-disable-next-line @typescript-eslint/triple-slash-reference\n///<reference path=\"../types/global-node.d.ts\"/>\n// eslint-disable-next-line @typescript-eslint/triple-slash-reference\n///<reference path=\"../types/global-variables.d.ts\"/>\n// eslint-disable-next-line @typescript-eslint/triple-slash-reference\n///<reference path=\"../types/global-deno.d.ts\"/>\n\nimport { isObject } from './lang';\n\ninterface Environment {\n  apiKey: string | undefined;\n  databaseURL: string | undefined;\n  branch: string | undefined;\n  envBranch: string | undefined;\n  fallbackBranch: string | undefined;\n}\n\nexport function getEnvironment(): Environment {\n  // Node.js: process.env\n  try {\n    if (isObject(process) && isObject(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        envBranch: process.env.VERCEL_GIT_COMMIT_REF ?? process.env.CF_PAGES_BRANCH ?? process.env.BRANCH,\n        fallbackBranch: process.env.XATA_FALLBACK_BRANCH ?? getGlobalFallbackBranch()\n      };\n    }\n  } catch (err) {\n    // Ignore: Should never happen\n  }\n\n  try {\n    // Deno: Deno.env.get\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get('XATA_API_KEY') ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get('XATA_DATABASE_URL') ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get('XATA_BRANCH') ?? getGlobalBranch(),\n        envBranch: Deno.env.get('VERCEL_GIT_COMMIT_REF') ?? Deno.env.get('CF_PAGES_BRANCH') ?? Deno.env.get('BRANCH'),\n        fallbackBranch: Deno.env.get('XATA_FALLBACK_BRANCH') ?? getGlobalFallbackBranch()\n      };\n    }\n  } catch (err) {\n    // Ignore: Will fail if not using --allow-env\n  }\n\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    envBranch: undefined,\n    fallbackBranch: getGlobalFallbackBranch()\n  };\n}\n\nfunction getGlobalApiKey(): string | undefined {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return undefined;\n  }\n}\n\nfunction getGlobalDatabaseURL(): string | undefined {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return undefined;\n  }\n}\n\nfunction getGlobalBranch(): string | undefined {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return undefined;\n  }\n}\n\nfunction getGlobalFallbackBranch(): string | undefined {\n  try {\n    return XATA_FALLBACK_BRANCH;\n  } catch (err) {\n    return undefined;\n  }\n}\n\nexport async function getGitBranch(): Promise<string | undefined> {\n  const cmd = ['git', 'branch', '--show-current'];\n  const fullCmd = cmd.join(' ');\n\n  // Avoid \"Detected a Node builtin module import while Node compatibility is disabled\" in CloudFlare Workers\n  const nodeModule = ['child', 'process'].join('_');\n\n  const execOptions = { encoding: 'utf-8', stdio: ['ignore', 'pipe', 'ignore'] };\n\n  // Node.js: child_process.execSync\n  try {\n    // CJS\n    if (typeof require === 'function') {\n      // eslint-disable-next-line @typescript-eslint/no-var-requires\n      return require(nodeModule).execSync(fullCmd, execOptions).trim();\n    }\n\n    // ESM\n    const { execSync } = await import(nodeModule);\n    return execSync(fullCmd, execOptions).toString().trim();\n  } catch (err) {\n    // Ignore\n  }\n\n  // Deno: Deno.run\n  try {\n    if (isObject(Deno)) {\n      const process = Deno.run({ cmd, stdout: 'piped', stderr: 'null' });\n      return new TextDecoder().decode(await process.output()).trim();\n    }\n  } catch (err) {\n    // Ignore: Will fail if not using --allow-run\n  }\n}\n","import { getEnvironment } from './environment';\n\nexport function getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return undefined;\n  }\n}\n","import { FetchImpl } from '../api/fetcher';\n\nexport function getFetchImplementation(userFetch?: FetchImpl) {\n  const globalFetch = typeof fetch !== 'undefined' ? fetch : undefined;\n  const fetchImpl = userFetch ?? globalFetch;\n  if (!fetchImpl) {\n    /** @todo add a link after docs exist */\n    throw new Error(\n      `Couldn't find \\`fetch\\`. Install a fetch implementation such as \\`node-fetch\\` and pass it explicitly.`\n    );\n  }\n  return fetchImpl;\n}\n","export const VERSION = '0.19.1';","import { Responses } from '.';\nimport { isObject, isString } from '../util/lang';\n\n// Polyfill for TypeScript < 4.6\nclass ErrorWithCause extends Error {\n  cause?: Error;\n\n  constructor(message?: string, options?: { cause?: Error }) {\n    // @ts-ignore - Options didn't exist before 4.6\n    super(message, options);\n  }\n}\n\nexport class FetcherError extends ErrorWithCause {\n  public status: number | string;\n  public requestId: string | undefined;\n  public errors: Responses.BulkError['errors'] | undefined;\n\n  constructor(status: number, data?: unknown, requestId?: string) {\n    super(getMessage(data));\n\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : undefined;\n    this.requestId = requestId;\n\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = (data as ErrorWithCause).cause;\n    }\n  }\n\n  toString() {\n    const error = super.toString();\n\n    return `[${this.status}] (${this.requestId ?? 'Unknown'}): ${error}`;\n  }\n}\n\nexport type PossibleErrors =\n  | Responses.BadRequestError\n  | Responses.AuthError\n  | Responses.SimpleError\n  | Responses.BulkError;\n\nfunction isBulkError(error: any): error is Responses.BulkError {\n  return isObject(error) && Array.isArray(error.errors);\n}\n\nfunction isErrorWithMessage(\n  error: any\n): error is Responses.BadRequestError | Responses.SimpleError | Responses.AuthError {\n  return isObject(error) && isString(error.message);\n}\n\nfunction getMessage(data?: unknown): string {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return 'Bulk operation failed';\n  } else {\n    return 'Unexpected error';\n  }\n}\n","import { TraceAttributes, TraceFunction } from '../schema/tracing';\nimport { isString } from '../util/lang';\nimport { VERSION } from '../version';\nimport { FetcherError, PossibleErrors } from './errors';\n\nconst resolveUrl = (\n  url: string,\n  queryParams: Record<string, any> = {},\n  pathParams: Partial<Record<string, string | number>> = {}\n) => {\n  // Remove nulls and undefineds from query params\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === undefined || value === null) return acc;\n    return { ...acc, [key]: value };\n  }, {} as Record<string, any>);\n\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : '';\n\n  // We need to encode the path params because they can contain special characters\n  // Special case, `:` does not need to be encoded as we use it as a separator\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? '')).replace('%3A', ':') };\n  }, {} as Record<string, string>);\n\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\n\n// Typed only the subset of the spec we actually use (to be able to build a simple mock)\nexport type FetchImpl = (\n  url: string,\n  init?: { body?: string; headers?: Record<string, string>; method?: string; signal?: any }\n) => Promise<{\n  ok: boolean;\n  status: number;\n  url: string;\n  json(): Promise<any>;\n  headers?: {\n    get(name: string): string | null;\n  };\n}>;\n\nexport type WorkspaceApiUrlBuilder = (path: string, pathParams: Partial<Record<string, string | number>>) => string;\n\nexport type FetcherExtraProps = {\n  endpoint: 'controlPlane' | 'dataPlane';\n  apiUrl: string;\n  workspacesApiUrl: string | WorkspaceApiUrlBuilder;\n  fetchImpl: FetchImpl;\n  apiKey: string;\n  trace: TraceFunction;\n  signal?: AbortSignal;\n  clientID?: string;\n  sessionID?: string;\n};\n\nexport type ErrorWrapper<TError> = TError | { status: 'unknown'; payload: string };\n\nexport type FetcherOptions<TBody, THeaders, TQueryParams, TPathParams> = {\n  url: string;\n  method: string;\n  body?: TBody;\n  headers?: THeaders;\n  queryParams?: TQueryParams;\n  pathParams?: TPathParams;\n} & FetcherExtraProps;\n\nfunction buildBaseUrl({\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}: {\n  endpoint: 'controlPlane' | 'dataPlane';\n  path: string;\n  workspacesApiUrl: string | WorkspaceApiUrlBuilder;\n  apiUrl: string;\n  pathParams?: Partial<Record<string, string | number>>;\n}): string {\n  if (endpoint === 'dataPlane') {\n    const url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n\n    const urlWithWorkspace = isString(pathParams.workspace)\n      ? url.replace('{workspaceId}', String(pathParams.workspace))\n      : url;\n\n    return isString(pathParams.region)\n      ? urlWithWorkspace.replace('{region}', String(pathParams.region))\n      : urlWithWorkspace;\n  }\n\n  return `${apiUrl}${path}`;\n}\n\n// The host header is needed by Node.js on localhost.\n// It is ignored by fetch() in the frontend\nfunction hostHeader(url: string): { Host?: string } {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n\n  return groups?.host ? { Host: groups.host } : {};\n}\n\nexport async function fetch<\n  TData,\n  TError extends ErrorWrapper<{ status: unknown; payload: PossibleErrors }>,\n  TBody extends Record<string, unknown> | undefined | null,\n  THeaders extends Record<string, unknown>,\n  TQueryParams extends Record<string, unknown>,\n  TPathParams extends Partial<Record<string, string | number>>\n>({\n  url: path,\n  method,\n  body,\n  headers,\n  pathParams,\n  queryParams,\n  fetchImpl,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID\n}: FetcherOptions<TBody, THeaders, TQueryParams, TPathParams> & FetcherExtraProps): Promise<TData> {\n  return trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n\n      // Node.js on localhost won't resolve localhost subdomains unless mapped in /etc/hosts\n      // So, instead, we use localhost without subdomains, but will add a Host header\n      const url = fullUrl.includes('localhost') ? fullUrl.replace(/^[^.]+\\./, 'http://') : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n\n      const response = await fetchImpl(url, {\n        method: method.toUpperCase(),\n        body: body ? JSON.stringify(body) : undefined,\n        headers: {\n          'Content-Type': 'application/json',\n          'User-Agent': `Xata client-ts/${VERSION}`,\n          'X-Xata-Client-ID': clientID ?? '',\n          'X-Xata-Session-ID': sessionID ?? '',\n          ...headers,\n          ...hostHeader(fullUrl),\n          Authorization: `Bearer ${apiKey}`\n        },\n        signal\n      });\n\n      // No content\n      if (response.status === 204) {\n        return {} as unknown as TData;\n      }\n\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get('x-request-id') ?? undefined;\n      setAttributes({\n        [TraceAttributes.KIND]: 'http',\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(':', '')\n      });\n\n      try {\n        const jsonResponse = await response.json();\n\n        if (response.ok) {\n          return jsonResponse;\n        }\n\n        throw new FetcherError(response.status, jsonResponse as TError['payload'], requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\n\nfunction parseUrl(url: string): { host?: string; protocol?: string } {\n  try {\n    const { host, protocol } = new URL(url);\n\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n","import { TraceFunction } from '../schema/tracing';\nimport { PossibleErrors } from './errors';\nimport { fetch, FetchImpl, WorkspaceApiUrlBuilder } from './fetcher';\n\nexport type DataPlaneFetcherExtraProps = {\n  apiUrl: string;\n  workspacesApiUrl: string | WorkspaceApiUrlBuilder;\n  fetchImpl: FetchImpl;\n  apiKey: string;\n  trace: TraceFunction;\n  signal?: AbortSignal;\n  clientID?: string;\n  sessionID?: string;\n};\n\nexport type ErrorWrapper<TError> = TError | { status: 'unknown'; payload: string };\n\nexport type DataPlaneFetcherOptions<TBody, THeaders, TQueryParams, TPathParams> = {\n  url: string;\n  method: string;\n  body?: TBody;\n  headers?: THeaders;\n  queryParams?: TQueryParams;\n  pathParams?: TPathParams;\n  signal?: AbortSignal;\n} & DataPlaneFetcherExtraProps;\n\nexport const dataPlaneFetch = async <\n  TData,\n  TError extends ErrorWrapper<{ status: unknown; payload: PossibleErrors }>,\n  TBody extends Record<string, unknown> | undefined | null,\n  THeaders extends Record<string, unknown>,\n  TQueryParams extends Record<string, unknown>,\n  TPathParams extends Partial<Record<string, string | number>>\n>(\n  options: DataPlaneFetcherOptions<TBody, THeaders, TQueryParams, TPathParams>\n): Promise<TData> =>\n  fetch<TData, TError, TBody, THeaders, TQueryParams, TPathParams>({ ...options, endpoint: 'dataPlane' });\n","/**\n * Generated by @openapi-codegen\n *\n * @version 1.0\n */\nimport type * as Fetcher from './dataPlaneFetcher';\nimport { dataPlaneFetch, DataPlaneFetcherExtraProps } from './dataPlaneFetcher';\nimport type * as Schemas from './dataPlaneSchemas';\nimport type * as Responses from './dataPlaneResponses';\n\nexport type DEPRECATEDgetDatabaseListPathParams = {\n  workspace: string;\n  region: string;\n};\n\nexport type DEPRECATEDgetDatabaseListError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type DEPRECATEDgetDatabaseListVariables = {\n  pathParams: DEPRECATEDgetDatabaseListPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * List all databases available in your Workspace.\n */\nexport const dEPRECATEDgetDatabaseList = (variables: DEPRECATEDgetDatabaseListVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Schemas.DEPRECATEDListDatabasesResponse,\n    DEPRECATEDgetDatabaseListError,\n    undefined,\n    {},\n    {},\n    DEPRECATEDgetDatabaseListPathParams\n  >({ url: '/dbs', method: 'get', ...variables, signal });\n\nexport type GetBranchListPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetBranchListError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetBranchListVariables = {\n  pathParams: GetBranchListPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * List all available Branches\n */\nexport const getBranchList = (variables: GetBranchListVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Schemas.ListBranchesResponse, GetBranchListError, undefined, {}, {}, GetBranchListPathParams>({\n    url: '/dbs/{dbName}',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type DEPRECATEDcreateDatabasePathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type DEPRECATEDcreateDatabaseError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type DEPRECATEDcreateDatabaseResponse = {\n  /**\n   * @minLength 1\n   */\n  databaseName: string;\n  branchName?: string;\n  status: Schemas.MigrationStatus;\n};\n\nexport type DEPRECATEDcreateDatabaseRequestBody = {\n  /**\n   * @minLength 1\n   */\n  branchName?: string;\n  ui?: {\n    color?: string;\n  };\n  metadata?: Schemas.BranchMetadata;\n};\n\nexport type DEPRECATEDcreateDatabaseVariables = {\n  body?: DEPRECATEDcreateDatabaseRequestBody;\n  pathParams: DEPRECATEDcreateDatabasePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Create Database with identifier name\n */\nexport const dEPRECATEDcreateDatabase = (variables: DEPRECATEDcreateDatabaseVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    DEPRECATEDcreateDatabaseResponse,\n    DEPRECATEDcreateDatabaseError,\n    DEPRECATEDcreateDatabaseRequestBody,\n    {},\n    {},\n    DEPRECATEDcreateDatabasePathParams\n  >({ url: '/dbs/{dbName}', method: 'put', ...variables, signal });\n\nexport type DEPRECATEDdeleteDatabasePathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type DEPRECATEDdeleteDatabaseError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DEPRECATEDdeleteDatabaseResponse = {\n  status: Schemas.MigrationStatus;\n};\n\nexport type DEPRECATEDdeleteDatabaseVariables = {\n  pathParams: DEPRECATEDdeleteDatabasePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Delete a database and all of its branches and tables permanently.\n */\nexport const dEPRECATEDdeleteDatabase = (variables: DEPRECATEDdeleteDatabaseVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    DEPRECATEDdeleteDatabaseResponse,\n    DEPRECATEDdeleteDatabaseError,\n    undefined,\n    {},\n    {},\n    DEPRECATEDdeleteDatabasePathParams\n  >({ url: '/dbs/{dbName}', method: 'delete', ...variables, signal });\n\nexport type DEPRECATEDgetDatabaseMetadataPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type DEPRECATEDgetDatabaseMetadataError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DEPRECATEDgetDatabaseMetadataVariables = {\n  pathParams: DEPRECATEDgetDatabaseMetadataPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Retrieve metadata of the given database\n */\nexport const dEPRECATEDgetDatabaseMetadata = (\n  variables: DEPRECATEDgetDatabaseMetadataVariables,\n  signal?: AbortSignal\n) =>\n  dataPlaneFetch<\n    Schemas.DEPRECATEDDatabaseMetadata,\n    DEPRECATEDgetDatabaseMetadataError,\n    undefined,\n    {},\n    {},\n    DEPRECATEDgetDatabaseMetadataPathParams\n  >({ url: '/dbs/{dbName}/metadata', method: 'get', ...variables, signal });\n\nexport type DEPRECATEDupdateDatabaseMetadataPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type DEPRECATEDupdateDatabaseMetadataError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DEPRECATEDupdateDatabaseMetadataRequestBody = {\n  ui?: {\n    /**\n     * @minLength 1\n     */\n    color?: string;\n  };\n};\n\nexport type DEPRECATEDupdateDatabaseMetadataVariables = {\n  body?: DEPRECATEDupdateDatabaseMetadataRequestBody;\n  pathParams: DEPRECATEDupdateDatabaseMetadataPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Update the color of the selected database\n */\nexport const dEPRECATEDupdateDatabaseMetadata = (\n  variables: DEPRECATEDupdateDatabaseMetadataVariables,\n  signal?: AbortSignal\n) =>\n  dataPlaneFetch<\n    Schemas.DEPRECATEDDatabaseMetadata,\n    DEPRECATEDupdateDatabaseMetadataError,\n    DEPRECATEDupdateDatabaseMetadataRequestBody,\n    {},\n    {},\n    DEPRECATEDupdateDatabaseMetadataPathParams\n  >({ url: '/dbs/{dbName}/metadata', method: 'patch', ...variables, signal });\n\nexport type GetBranchDetailsPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetBranchDetailsError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetBranchDetailsVariables = {\n  pathParams: GetBranchDetailsPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const getBranchDetails = (variables: GetBranchDetailsVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Schemas.DBBranch, GetBranchDetailsError, undefined, {}, {}, GetBranchDetailsPathParams>({\n    url: '/db/{dbBranchName}',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type CreateBranchPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type CreateBranchQueryParams = {\n  /**\n   * Name of source branch to branch the new schema from\n   */\n  from?: string;\n};\n\nexport type CreateBranchError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CreateBranchResponse = {\n  /**\n   * @minLength 1\n   */\n  databaseName: string;\n  branchName: string;\n  status: Schemas.MigrationStatus;\n};\n\nexport type CreateBranchRequestBody = {\n  /**\n   * Select the branch to fork from. Defaults to 'main'\n   */\n  from?: string;\n  metadata?: Schemas.BranchMetadata;\n};\n\nexport type CreateBranchVariables = {\n  body?: CreateBranchRequestBody;\n  pathParams: CreateBranchPathParams;\n  queryParams?: CreateBranchQueryParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const createBranch = (variables: CreateBranchVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    CreateBranchResponse,\n    CreateBranchError,\n    CreateBranchRequestBody,\n    {},\n    CreateBranchQueryParams,\n    CreateBranchPathParams\n  >({ url: '/db/{dbBranchName}', method: 'put', ...variables, signal });\n\nexport type DeleteBranchPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type DeleteBranchError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DeleteBranchResponse = {\n  status: Schemas.MigrationStatus;\n};\n\nexport type DeleteBranchVariables = {\n  pathParams: DeleteBranchPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Delete the branch in the database and all its resources\n */\nexport const deleteBranch = (variables: DeleteBranchVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<DeleteBranchResponse, DeleteBranchError, undefined, {}, {}, DeleteBranchPathParams>({\n    url: '/db/{dbBranchName}',\n    method: 'delete',\n    ...variables,\n    signal\n  });\n\nexport type UpdateBranchMetadataPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type UpdateBranchMetadataError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateBranchMetadataVariables = {\n  body?: Schemas.BranchMetadata;\n  pathParams: UpdateBranchMetadataPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Update the branch metadata\n */\nexport const updateBranchMetadata = (variables: UpdateBranchMetadataVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<undefined, UpdateBranchMetadataError, Schemas.BranchMetadata, {}, {}, UpdateBranchMetadataPathParams>({\n    url: '/db/{dbBranchName}/metadata',\n    method: 'put',\n    ...variables,\n    signal\n  });\n\nexport type GetBranchMetadataPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetBranchMetadataError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetBranchMetadataVariables = {\n  pathParams: GetBranchMetadataPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const getBranchMetadata = (variables: GetBranchMetadataVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Schemas.BranchMetadata, GetBranchMetadataError, undefined, {}, {}, GetBranchMetadataPathParams>({\n    url: '/db/{dbBranchName}/metadata',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type GetBranchStatsPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetBranchStatsError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetBranchStatsResponse = {\n  timestamp: string;\n  interval: string;\n  resolution: string;\n  numberOfRecords?: Schemas.MetricsDatapoint[];\n  writesOverTime?: Schemas.MetricsDatapoint[];\n  readsOverTime?: Schemas.MetricsDatapoint[];\n  readLatency?: Schemas.MetricsLatency;\n  writeLatency?: Schemas.MetricsLatency;\n  warning?: string;\n};\n\nexport type GetBranchStatsVariables = {\n  pathParams: GetBranchStatsPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Get branch usage metrics.\n */\nexport const getBranchStats = (variables: GetBranchStatsVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<GetBranchStatsResponse, GetBranchStatsError, undefined, {}, {}, GetBranchStatsPathParams>({\n    url: '/db/{dbBranchName}/stats',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type GetGitBranchesMappingPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetGitBranchesMappingError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type GetGitBranchesMappingVariables = {\n  pathParams: GetGitBranchesMappingPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Lists all the git branches in the mapping, and their associated Xata branches.\n *\n * Example response:\n *\n * ```json\n * {\n *   \"mappings\": [\n *       {\n *         \"gitBranch\": \"main\",\n *         \"xataBranch\": \"main\"\n *       },\n *       {\n *         \"gitBranch\": \"gitBranch1\",\n *         \"xataBranch\": \"xataBranch1\"\n *       }\n *       {\n *         \"gitBranch\": \"xataBranch2\",\n *         \"xataBranch\": \"xataBranch2\"\n *       }\n *   ]\n * }\n * ```\n */\nexport const getGitBranchesMapping = (variables: GetGitBranchesMappingVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Schemas.ListGitBranchesResponse,\n    GetGitBranchesMappingError,\n    undefined,\n    {},\n    {},\n    GetGitBranchesMappingPathParams\n  >({ url: '/dbs/{dbName}/gitBranches', method: 'get', ...variables, signal });\n\nexport type AddGitBranchesEntryPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type AddGitBranchesEntryError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type AddGitBranchesEntryResponse = {\n  /**\n   * Warning message\n   */\n  warning?: string;\n};\n\nexport type AddGitBranchesEntryRequestBody = {\n  /**\n   * The name of the Git branch.\n   */\n  gitBranch: string;\n  /**\n   * The name of the Xata branch.\n   */\n  xataBranch: Schemas.BranchName;\n};\n\nexport type AddGitBranchesEntryVariables = {\n  body: AddGitBranchesEntryRequestBody;\n  pathParams: AddGitBranchesEntryPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Adds an entry to the mapping of git branches to Xata branches. The git branch and the Xata branch must be present in the body of the request. If the Xata branch doesn't exist, a 400 error is returned.\n *\n * If the git branch is already present in the mapping, the old entry is overwritten, and a warning message is included in the response. If the git branch is added and didn't exist before, the response code is 204. If the git branch existed and it was overwritten, the response code is 201.\n *\n * Example request:\n *\n * ```json\n * // POST https://tutorial-ng7s8c.xata.sh/dbs/demo/gitBranches\n * {\n *   \"gitBranch\": \"fix/bug123\",\n *   \"xataBranch\": \"fix_bug\"\n * }\n * ```\n */\nexport const addGitBranchesEntry = (variables: AddGitBranchesEntryVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    AddGitBranchesEntryResponse,\n    AddGitBranchesEntryError,\n    AddGitBranchesEntryRequestBody,\n    {},\n    {},\n    AddGitBranchesEntryPathParams\n  >({ url: '/dbs/{dbName}/gitBranches', method: 'post', ...variables, signal });\n\nexport type RemoveGitBranchesEntryPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type RemoveGitBranchesEntryQueryParams = {\n  /**\n   * The Git Branch to remove from the mapping\n   */\n  gitBranch: string;\n};\n\nexport type RemoveGitBranchesEntryError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type RemoveGitBranchesEntryVariables = {\n  pathParams: RemoveGitBranchesEntryPathParams;\n  queryParams: RemoveGitBranchesEntryQueryParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Removes an entry from the mapping of git branches to Xata branches. The name of the git branch must be passed as a query parameter. If the git branch is not found, the endpoint returns a 404 status code.\n *\n * Example request:\n *\n * ```json\n * // DELETE https://tutorial-ng7s8c.xata.sh/dbs/demo/gitBranches?gitBranch=fix%2Fbug123\n * ```\n */\nexport const removeGitBranchesEntry = (variables: RemoveGitBranchesEntryVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    undefined,\n    RemoveGitBranchesEntryError,\n    undefined,\n    {},\n    RemoveGitBranchesEntryQueryParams,\n    RemoveGitBranchesEntryPathParams\n  >({ url: '/dbs/{dbName}/gitBranches', method: 'delete', ...variables, signal });\n\nexport type ResolveBranchPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type ResolveBranchQueryParams = {\n  /**\n   * The Git Branch\n   */\n  gitBranch?: string;\n  /**\n   * Default branch to fallback to\n   */\n  fallbackBranch?: string;\n};\n\nexport type ResolveBranchError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type ResolveBranchResponse = {\n  branch: string;\n  reason: {\n    code: 'FOUND_IN_MAPPING' | 'BRANCH_EXISTS' | 'FALLBACK_BRANCH' | 'DEFAULT_BRANCH';\n    message: string;\n  };\n};\n\nexport type ResolveBranchVariables = {\n  pathParams: ResolveBranchPathParams;\n  queryParams?: ResolveBranchQueryParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * In order to resolve the database branch, the following algorithm is used:\n * * if the `gitBranch` was provided and is found in the [git branches mapping](/api-reference/dbs/db_name/gitBranches), the associated Xata branch is returned\n * * else, if a Xata branch with the exact same name as `gitBranch` exists, return it\n * * else, if `fallbackBranch` is provided and a branch with that name exists, return it\n * * else, return the default branch of the DB (`main` or the first branch)\n *\n * Example call:\n *\n * ```json\n * // GET https://tutorial-ng7s8c.xata.sh/dbs/demo/dbs/demo/resolveBranch?gitBranch=test&fallbackBranch=tsg\n * ```\n *\n * Example response:\n *\n * ```json\n * {\n *   \"branch\": \"main\",\n *   \"reason\": {\n *     \"code\": \"DEFAULT_BRANCH\",\n *     \"message\": \"Default branch for this database (main)\"\n *   }\n * }\n * ```\n */\nexport const resolveBranch = (variables: ResolveBranchVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    ResolveBranchResponse,\n    ResolveBranchError,\n    undefined,\n    {},\n    ResolveBranchQueryParams,\n    ResolveBranchPathParams\n  >({ url: '/dbs/{dbName}/resolveBranch', method: 'get', ...variables, signal });\n\nexport type GetBranchMigrationHistoryPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetBranchMigrationHistoryError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetBranchMigrationHistoryResponse = {\n  startedFrom?: Schemas.StartedFromMetadata;\n  migrations?: Schemas.BranchMigration[];\n};\n\nexport type GetBranchMigrationHistoryRequestBody = {\n  limit?: number;\n  startFrom?: string;\n};\n\nexport type GetBranchMigrationHistoryVariables = {\n  body?: GetBranchMigrationHistoryRequestBody;\n  pathParams: GetBranchMigrationHistoryPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const getBranchMigrationHistory = (variables: GetBranchMigrationHistoryVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    GetBranchMigrationHistoryResponse,\n    GetBranchMigrationHistoryError,\n    GetBranchMigrationHistoryRequestBody,\n    {},\n    {},\n    GetBranchMigrationHistoryPathParams\n  >({ url: '/db/{dbBranchName}/migrations', method: 'get', ...variables, signal });\n\nexport type GetBranchMigrationPlanPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetBranchMigrationPlanError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetBranchMigrationPlanVariables = {\n  body: Schemas.Schema;\n  pathParams: GetBranchMigrationPlanPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Compute a migration plan from a target schema the branch should be migrated too.\n */\nexport const getBranchMigrationPlan = (variables: GetBranchMigrationPlanVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.BranchMigrationPlan,\n    GetBranchMigrationPlanError,\n    Schemas.Schema,\n    {},\n    {},\n    GetBranchMigrationPlanPathParams\n  >({ url: '/db/{dbBranchName}/migrations/plan', method: 'post', ...variables, signal });\n\nexport type ExecuteBranchMigrationPlanPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type ExecuteBranchMigrationPlanError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type ExecuteBranchMigrationPlanRequestBody = {\n  version: number;\n  migration: Schemas.BranchMigration;\n};\n\nexport type ExecuteBranchMigrationPlanVariables = {\n  body: ExecuteBranchMigrationPlanRequestBody;\n  pathParams: ExecuteBranchMigrationPlanPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Apply a migration plan to the branch\n */\nexport const executeBranchMigrationPlan = (variables: ExecuteBranchMigrationPlanVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaUpdateResponse,\n    ExecuteBranchMigrationPlanError,\n    ExecuteBranchMigrationPlanRequestBody,\n    {},\n    {},\n    ExecuteBranchMigrationPlanPathParams\n  >({ url: '/db/{dbBranchName}/migrations/execute', method: 'post', ...variables, signal });\n\nexport type QueryMigrationRequestsPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type QueryMigrationRequestsError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type QueryMigrationRequestsResponse = {\n  migrationRequests: Schemas.MigrationRequest[];\n  meta: Schemas.RecordsMetadata;\n};\n\nexport type QueryMigrationRequestsRequestBody = {\n  filter?: Schemas.FilterExpression;\n  sort?: Schemas.SortExpression;\n  page?: Schemas.PageConfig;\n  columns?: Schemas.ColumnsProjection;\n};\n\nexport type QueryMigrationRequestsVariables = {\n  body?: QueryMigrationRequestsRequestBody;\n  pathParams: QueryMigrationRequestsPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const queryMigrationRequests = (variables: QueryMigrationRequestsVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    QueryMigrationRequestsResponse,\n    QueryMigrationRequestsError,\n    QueryMigrationRequestsRequestBody,\n    {},\n    {},\n    QueryMigrationRequestsPathParams\n  >({ url: '/dbs/{dbName}/migrations/query', method: 'post', ...variables, signal });\n\nexport type CreateMigrationRequestPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  workspace: string;\n  region: string;\n};\n\nexport type CreateMigrationRequestError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CreateMigrationRequestResponse = {\n  number: number;\n};\n\nexport type CreateMigrationRequestRequestBody = {\n  /**\n   * The source branch.\n   */\n  source: string;\n  /**\n   * The target branch.\n   */\n  target: string;\n  /**\n   * The title.\n   */\n  title: string;\n  /**\n   * Optional migration request description.\n   */\n  body?: string;\n};\n\nexport type CreateMigrationRequestVariables = {\n  body: CreateMigrationRequestRequestBody;\n  pathParams: CreateMigrationRequestPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const createMigrationRequest = (variables: CreateMigrationRequestVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    CreateMigrationRequestResponse,\n    CreateMigrationRequestError,\n    CreateMigrationRequestRequestBody,\n    {},\n    {},\n    CreateMigrationRequestPathParams\n  >({ url: '/dbs/{dbName}/migrations', method: 'post', ...variables, signal });\n\nexport type GetMigrationRequestPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  /**\n   * The migration request number.\n   */\n  mrNumber: Schemas.MigrationRequestNumber;\n  workspace: string;\n  region: string;\n};\n\nexport type GetMigrationRequestError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetMigrationRequestVariables = {\n  pathParams: GetMigrationRequestPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const getMigrationRequest = (variables: GetMigrationRequestVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Schemas.MigrationRequest, GetMigrationRequestError, undefined, {}, {}, GetMigrationRequestPathParams>({\n    url: '/dbs/{dbName}/migrations/{mrNumber}',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type UpdateMigrationRequestPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  /**\n   * The migration request number.\n   */\n  mrNumber: Schemas.MigrationRequestNumber;\n  workspace: string;\n  region: string;\n};\n\nexport type UpdateMigrationRequestError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateMigrationRequestRequestBody = {\n  /**\n   * New migration request title.\n   */\n  title?: string;\n  /**\n   * New migration request description.\n   */\n  body?: string;\n  /**\n   * Change the migration request status.\n   */\n  status?: 'open' | 'closed';\n};\n\nexport type UpdateMigrationRequestVariables = {\n  body?: UpdateMigrationRequestRequestBody;\n  pathParams: UpdateMigrationRequestPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const updateMigrationRequest = (variables: UpdateMigrationRequestVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    undefined,\n    UpdateMigrationRequestError,\n    UpdateMigrationRequestRequestBody,\n    {},\n    {},\n    UpdateMigrationRequestPathParams\n  >({ url: '/dbs/{dbName}/migrations/{mrNumber}', method: 'patch', ...variables, signal });\n\nexport type ListMigrationRequestsCommitsPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  /**\n   * The migration request number.\n   */\n  mrNumber: Schemas.MigrationRequestNumber;\n  workspace: string;\n  region: string;\n};\n\nexport type ListMigrationRequestsCommitsError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type ListMigrationRequestsCommitsResponse = {\n  meta: {\n    /**\n     * last record id\n     */\n    cursor: string;\n    /**\n     * true if more records can be fetch\n     */\n    more: boolean;\n  };\n  logs: Schemas.Commit[];\n};\n\nexport type ListMigrationRequestsCommitsRequestBody = {\n  page?: {\n    /**\n     * Query the next page that follow the cursor.\n     */\n    after?: string;\n    /**\n     * Query the previous page before the cursor.\n     */\n    before?: string;\n    /**\n     * Set page size. If the size is missing it is read from the cursor. If no cursor is given xata will choose the default page size.\n     *\n     * @default 20\n     */\n    size?: number;\n  };\n};\n\nexport type ListMigrationRequestsCommitsVariables = {\n  body?: ListMigrationRequestsCommitsRequestBody;\n  pathParams: ListMigrationRequestsCommitsPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const listMigrationRequestsCommits = (variables: ListMigrationRequestsCommitsVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    ListMigrationRequestsCommitsResponse,\n    ListMigrationRequestsCommitsError,\n    ListMigrationRequestsCommitsRequestBody,\n    {},\n    {},\n    ListMigrationRequestsCommitsPathParams\n  >({ url: '/dbs/{dbName}/migrations/{mrNumber}/commits', method: 'post', ...variables, signal });\n\nexport type CompareMigrationRequestPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  /**\n   * The migration request number.\n   */\n  mrNumber: Schemas.MigrationRequestNumber;\n  workspace: string;\n  region: string;\n};\n\nexport type CompareMigrationRequestError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CompareMigrationRequestVariables = {\n  pathParams: CompareMigrationRequestPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const compareMigrationRequest = (variables: CompareMigrationRequestVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaCompareResponse,\n    CompareMigrationRequestError,\n    undefined,\n    {},\n    {},\n    CompareMigrationRequestPathParams\n  >({ url: '/dbs/{dbName}/migrations/{mrNumber}/compare', method: 'post', ...variables, signal });\n\nexport type GetMigrationRequestIsMergedPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  /**\n   * The migration request number.\n   */\n  mrNumber: Schemas.MigrationRequestNumber;\n  workspace: string;\n  region: string;\n};\n\nexport type GetMigrationRequestIsMergedError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetMigrationRequestIsMergedResponse = {\n  merged?: boolean;\n};\n\nexport type GetMigrationRequestIsMergedVariables = {\n  pathParams: GetMigrationRequestIsMergedPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const getMigrationRequestIsMerged = (variables: GetMigrationRequestIsMergedVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    GetMigrationRequestIsMergedResponse,\n    GetMigrationRequestIsMergedError,\n    undefined,\n    {},\n    {},\n    GetMigrationRequestIsMergedPathParams\n  >({ url: '/dbs/{dbName}/migrations/{mrNumber}/merge', method: 'get', ...variables, signal });\n\nexport type MergeMigrationRequestPathParams = {\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n  /**\n   * The migration request number.\n   */\n  mrNumber: Schemas.MigrationRequestNumber;\n  workspace: string;\n  region: string;\n};\n\nexport type MergeMigrationRequestError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type MergeMigrationRequestVariables = {\n  pathParams: MergeMigrationRequestPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const mergeMigrationRequest = (variables: MergeMigrationRequestVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Schemas.Commit, MergeMigrationRequestError, undefined, {}, {}, MergeMigrationRequestPathParams>({\n    url: '/dbs/{dbName}/migrations/{mrNumber}/merge',\n    method: 'post',\n    ...variables,\n    signal\n  });\n\nexport type GetBranchSchemaHistoryPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetBranchSchemaHistoryError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetBranchSchemaHistoryResponse = {\n  meta: {\n    /**\n     * last record id\n     */\n    cursor: string;\n    /**\n     * true if more records can be fetch\n     */\n    more: boolean;\n  };\n  logs: Schemas.Commit[];\n};\n\nexport type GetBranchSchemaHistoryRequestBody = {\n  page?: {\n    /**\n     * Query the next page that follow the cursor.\n     */\n    after?: string;\n    /**\n     * Query the previous page before the cursor.\n     */\n    before?: string;\n    /**\n     * Set page size. If the size is missing it is read from the cursor. If no cursor is given xata will choose the default page size.\n     *\n     * @default 20\n     */\n    size?: number;\n  };\n};\n\nexport type GetBranchSchemaHistoryVariables = {\n  body?: GetBranchSchemaHistoryRequestBody;\n  pathParams: GetBranchSchemaHistoryPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const getBranchSchemaHistory = (variables: GetBranchSchemaHistoryVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    GetBranchSchemaHistoryResponse,\n    GetBranchSchemaHistoryError,\n    GetBranchSchemaHistoryRequestBody,\n    {},\n    {},\n    GetBranchSchemaHistoryPathParams\n  >({ url: '/db/{dbBranchName}/schema/history', method: 'post', ...variables, signal });\n\nexport type CompareBranchWithUserSchemaPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type CompareBranchWithUserSchemaError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CompareBranchWithUserSchemaRequestBody = {\n  schema: Schemas.Schema;\n};\n\nexport type CompareBranchWithUserSchemaVariables = {\n  body: CompareBranchWithUserSchemaRequestBody;\n  pathParams: CompareBranchWithUserSchemaPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const compareBranchWithUserSchema = (variables: CompareBranchWithUserSchemaVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaCompareResponse,\n    CompareBranchWithUserSchemaError,\n    CompareBranchWithUserSchemaRequestBody,\n    {},\n    {},\n    CompareBranchWithUserSchemaPathParams\n  >({ url: '/db/{dbBranchName}/schema/compare', method: 'post', ...variables, signal });\n\nexport type CompareBranchSchemasPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Database Name\n   */\n  branchName: Schemas.BranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type CompareBranchSchemasError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CompareBranchSchemasVariables = {\n  body?: Record<string, any>;\n  pathParams: CompareBranchSchemasPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const compareBranchSchemas = (variables: CompareBranchSchemasVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaCompareResponse,\n    CompareBranchSchemasError,\n    Record<string, any>,\n    {},\n    {},\n    CompareBranchSchemasPathParams\n  >({ url: '/db/{dbBranchName}/schema/compare/{branchName}', method: 'post', ...variables, signal });\n\nexport type UpdateBranchSchemaPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type UpdateBranchSchemaError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateBranchSchemaVariables = {\n  body: Schemas.Migration;\n  pathParams: UpdateBranchSchemaPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const updateBranchSchema = (variables: UpdateBranchSchemaVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaUpdateResponse,\n    UpdateBranchSchemaError,\n    Schemas.Migration,\n    {},\n    {},\n    UpdateBranchSchemaPathParams\n  >({ url: '/db/{dbBranchName}/schema/update', method: 'post', ...variables, signal });\n\nexport type PreviewBranchSchemaEditPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type PreviewBranchSchemaEditError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type PreviewBranchSchemaEditResponse = {\n  original: Schemas.Schema;\n  updated: Schemas.Schema;\n};\n\nexport type PreviewBranchSchemaEditRequestBody = {\n  edits?: Schemas.SchemaEditScript;\n};\n\nexport type PreviewBranchSchemaEditVariables = {\n  body?: PreviewBranchSchemaEditRequestBody;\n  pathParams: PreviewBranchSchemaEditPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const previewBranchSchemaEdit = (variables: PreviewBranchSchemaEditVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    PreviewBranchSchemaEditResponse,\n    PreviewBranchSchemaEditError,\n    PreviewBranchSchemaEditRequestBody,\n    {},\n    {},\n    PreviewBranchSchemaEditPathParams\n  >({ url: '/db/{dbBranchName}/schema/preview', method: 'post', ...variables, signal });\n\nexport type ApplyBranchSchemaEditPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type ApplyBranchSchemaEditError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type ApplyBranchSchemaEditRequestBody = {\n  edits: Schemas.SchemaEditScript;\n};\n\nexport type ApplyBranchSchemaEditVariables = {\n  body: ApplyBranchSchemaEditRequestBody;\n  pathParams: ApplyBranchSchemaEditPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const applyBranchSchemaEdit = (variables: ApplyBranchSchemaEditVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaUpdateResponse,\n    ApplyBranchSchemaEditError,\n    ApplyBranchSchemaEditRequestBody,\n    {},\n    {},\n    ApplyBranchSchemaEditPathParams\n  >({ url: '/db/{dbBranchName}/schema/apply', method: 'post', ...variables, signal });\n\nexport type CreateTablePathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type CreateTableError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 422;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CreateTableResponse = {\n  branchName: string;\n  /**\n   * @minLength 1\n   */\n  tableName: string;\n  status: Schemas.MigrationStatus;\n};\n\nexport type CreateTableVariables = {\n  pathParams: CreateTablePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Creates a new table with the given name. Returns 422 if a table with the same name already exists.\n */\nexport const createTable = (variables: CreateTableVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<CreateTableResponse, CreateTableError, undefined, {}, {}, CreateTablePathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}',\n    method: 'put',\n    ...variables,\n    signal\n  });\n\nexport type DeleteTablePathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type DeleteTableError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type DeleteTableResponse = {\n  status: Schemas.MigrationStatus;\n};\n\nexport type DeleteTableVariables = {\n  pathParams: DeleteTablePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Deletes the table with the given name.\n */\nexport const deleteTable = (variables: DeleteTableVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<DeleteTableResponse, DeleteTableError, undefined, {}, {}, DeleteTablePathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}',\n    method: 'delete',\n    ...variables,\n    signal\n  });\n\nexport type UpdateTablePathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type UpdateTableError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateTableRequestBody = {\n  /**\n   * @minLength 1\n   */\n  name: string;\n};\n\nexport type UpdateTableVariables = {\n  body: UpdateTableRequestBody;\n  pathParams: UpdateTablePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Update table. Currently there is only one update operation supported: renaming the table by providing a new name.\n *\n * In the example below, we rename a table from users to people:\n *\n * ```json\n * // PATCH /db/test:main/tables/users\n *\n * {\n *   \"name\": \"people\"\n * }\n * ```\n */\nexport const updateTable = (variables: UpdateTableVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaUpdateResponse,\n    UpdateTableError,\n    UpdateTableRequestBody,\n    {},\n    {},\n    UpdateTablePathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}', method: 'patch', ...variables, signal });\n\nexport type GetTableSchemaPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetTableSchemaError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetTableSchemaResponse = {\n  columns: Schemas.Column[];\n};\n\nexport type GetTableSchemaVariables = {\n  pathParams: GetTableSchemaPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const getTableSchema = (variables: GetTableSchemaVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<GetTableSchemaResponse, GetTableSchemaError, undefined, {}, {}, GetTableSchemaPathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}/schema',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type SetTableSchemaPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type SetTableSchemaError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 409;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type SetTableSchemaRequestBody = {\n  columns: Schemas.Column[];\n};\n\nexport type SetTableSchemaVariables = {\n  body: SetTableSchemaRequestBody;\n  pathParams: SetTableSchemaPathParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const setTableSchema = (variables: SetTableSchemaVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaUpdateResponse,\n    SetTableSchemaError,\n    SetTableSchemaRequestBody,\n    {},\n    {},\n    SetTableSchemaPathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/schema', method: 'put', ...variables, signal });\n\nexport type GetTableColumnsPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetTableColumnsError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetTableColumnsResponse = {\n  columns: Schemas.Column[];\n};\n\nexport type GetTableColumnsVariables = {\n  pathParams: GetTableColumnsPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Retrieves the list of table columns and their definition. This endpoint returns the column list with object columns being reported with their\n * full dot-separated path (flattened).\n */\nexport const getTableColumns = (variables: GetTableColumnsVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<GetTableColumnsResponse, GetTableColumnsError, undefined, {}, {}, GetTableColumnsPathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}/columns',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type AddTableColumnPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type AddTableColumnError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type AddTableColumnVariables = {\n  body: Schemas.Column;\n  pathParams: AddTableColumnPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Adds a new column to the table. The body of the request should contain the column definition. In the column definition, the 'name' field should\n * contain the full path separated by dots. If the parent objects do not exists, they will be automatically created. For example,\n * passing `\"name\": \"address.city\"` will auto-create the `address` object if it doesn't exist.\n */\nexport const addTableColumn = (variables: AddTableColumnVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Responses.SchemaUpdateResponse, AddTableColumnError, Schemas.Column, {}, {}, AddTableColumnPathParams>(\n    { url: '/db/{dbBranchName}/tables/{tableName}/columns', method: 'post', ...variables, signal }\n  );\n\nexport type GetColumnPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  /**\n   * The Column name\n   */\n  columnName: Schemas.ColumnName;\n  workspace: string;\n  region: string;\n};\n\nexport type GetColumnError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetColumnVariables = {\n  pathParams: GetColumnPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Get the definition of a single column. To refer to sub-objects, the column name can contain dots. For example `address.country`.\n */\nexport const getColumn = (variables: GetColumnVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Schemas.Column, GetColumnError, undefined, {}, {}, GetColumnPathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}/columns/{columnName}',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type UpdateColumnPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  /**\n   * The Column name\n   */\n  columnName: Schemas.ColumnName;\n  workspace: string;\n  region: string;\n};\n\nexport type UpdateColumnError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateColumnRequestBody = {\n  /**\n   * @minLength 1\n   */\n  name: string;\n};\n\nexport type UpdateColumnVariables = {\n  body: UpdateColumnRequestBody;\n  pathParams: UpdateColumnPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Update column with partial data. Can be used for renaming the column by providing a new \"name\" field. To refer to sub-objects, the column name can contain dots. For example `address.country`.\n */\nexport const updateColumn = (variables: UpdateColumnVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SchemaUpdateResponse,\n    UpdateColumnError,\n    UpdateColumnRequestBody,\n    {},\n    {},\n    UpdateColumnPathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/columns/{columnName}', method: 'patch', ...variables, signal });\n\nexport type DeleteColumnPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  /**\n   * The Column name\n   */\n  columnName: Schemas.ColumnName;\n  workspace: string;\n  region: string;\n};\n\nexport type DeleteColumnError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DeleteColumnVariables = {\n  pathParams: DeleteColumnPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Deletes the specified column. To refer to sub-objects, the column name can contain dots. For example `address.country`.\n */\nexport const deleteColumn = (variables: DeleteColumnVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Responses.SchemaUpdateResponse, DeleteColumnError, undefined, {}, {}, DeleteColumnPathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}/columns/{columnName}',\n    method: 'delete',\n    ...variables,\n    signal\n  });\n\nexport type InsertRecordPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type InsertRecordQueryParams = {\n  /**\n   * Column filters\n   */\n  columns?: Schemas.ColumnsProjection;\n};\n\nexport type InsertRecordError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type InsertRecordVariables = {\n  body?: Record<string, any>;\n  pathParams: InsertRecordPathParams;\n  queryParams?: InsertRecordQueryParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Insert a new Record into the Table\n */\nexport const insertRecord = (variables: InsertRecordVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.RecordUpdateResponse,\n    InsertRecordError,\n    Record<string, any>,\n    {},\n    InsertRecordQueryParams,\n    InsertRecordPathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/data', method: 'post', ...variables, signal });\n\nexport type GetRecordPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  /**\n   * The Record name\n   */\n  recordId: Schemas.RecordID;\n  workspace: string;\n  region: string;\n};\n\nexport type GetRecordQueryParams = {\n  /**\n   * Column filters\n   */\n  columns?: Schemas.ColumnsProjection;\n};\n\nexport type GetRecordError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetRecordVariables = {\n  pathParams: GetRecordPathParams;\n  queryParams?: GetRecordQueryParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Retrieve record by ID\n */\nexport const getRecord = (variables: GetRecordVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Responses.RecordResponse, GetRecordError, undefined, {}, GetRecordQueryParams, GetRecordPathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}/data/{recordId}',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type InsertRecordWithIDPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  /**\n   * The Record name\n   */\n  recordId: Schemas.RecordID;\n  workspace: string;\n  region: string;\n};\n\nexport type InsertRecordWithIDQueryParams = {\n  /**\n   * Column filters\n   */\n  columns?: Schemas.ColumnsProjection;\n  createOnly?: boolean;\n  ifVersion?: number;\n};\n\nexport type InsertRecordWithIDError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 422;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type InsertRecordWithIDVariables = {\n  body?: Record<string, any>;\n  pathParams: InsertRecordWithIDPathParams;\n  queryParams?: InsertRecordWithIDQueryParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * By default, IDs are auto-generated when data is insterted into Xata. Sending a request to this endpoint allows us to insert a record with a pre-existing ID, bypassing the default automatic ID generation.\n */\nexport const insertRecordWithID = (variables: InsertRecordWithIDVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.RecordUpdateResponse,\n    InsertRecordWithIDError,\n    Record<string, any>,\n    {},\n    InsertRecordWithIDQueryParams,\n    InsertRecordWithIDPathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/data/{recordId}', method: 'put', ...variables, signal });\n\nexport type UpdateRecordWithIDPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  /**\n   * The Record name\n   */\n  recordId: Schemas.RecordID;\n  workspace: string;\n  region: string;\n};\n\nexport type UpdateRecordWithIDQueryParams = {\n  /**\n   * Column filters\n   */\n  columns?: Schemas.ColumnsProjection;\n  ifVersion?: number;\n};\n\nexport type UpdateRecordWithIDError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 422;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateRecordWithIDVariables = {\n  body?: Record<string, any>;\n  pathParams: UpdateRecordWithIDPathParams;\n  queryParams?: UpdateRecordWithIDQueryParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const updateRecordWithID = (variables: UpdateRecordWithIDVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.RecordUpdateResponse,\n    UpdateRecordWithIDError,\n    Record<string, any>,\n    {},\n    UpdateRecordWithIDQueryParams,\n    UpdateRecordWithIDPathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/data/{recordId}', method: 'patch', ...variables, signal });\n\nexport type UpsertRecordWithIDPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  /**\n   * The Record name\n   */\n  recordId: Schemas.RecordID;\n  workspace: string;\n  region: string;\n};\n\nexport type UpsertRecordWithIDQueryParams = {\n  /**\n   * Column filters\n   */\n  columns?: Schemas.ColumnsProjection;\n  ifVersion?: number;\n};\n\nexport type UpsertRecordWithIDError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 422;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpsertRecordWithIDVariables = {\n  body?: Record<string, any>;\n  pathParams: UpsertRecordWithIDPathParams;\n  queryParams?: UpsertRecordWithIDQueryParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const upsertRecordWithID = (variables: UpsertRecordWithIDVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.RecordUpdateResponse,\n    UpsertRecordWithIDError,\n    Record<string, any>,\n    {},\n    UpsertRecordWithIDQueryParams,\n    UpsertRecordWithIDPathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/data/{recordId}', method: 'post', ...variables, signal });\n\nexport type DeleteRecordPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  /**\n   * The Record name\n   */\n  recordId: Schemas.RecordID;\n  workspace: string;\n  region: string;\n};\n\nexport type DeleteRecordQueryParams = {\n  /**\n   * Column filters\n   */\n  columns?: Schemas.ColumnsProjection;\n};\n\nexport type DeleteRecordError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DeleteRecordVariables = {\n  pathParams: DeleteRecordPathParams;\n  queryParams?: DeleteRecordQueryParams;\n} & DataPlaneFetcherExtraProps;\n\nexport const deleteRecord = (variables: DeleteRecordVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.RecordResponse,\n    DeleteRecordError,\n    undefined,\n    {},\n    DeleteRecordQueryParams,\n    DeleteRecordPathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/data/{recordId}', method: 'delete', ...variables, signal });\n\nexport type BulkInsertTableRecordsPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type BulkInsertTableRecordsQueryParams = {\n  /**\n   * Column filters\n   */\n  columns?: Schemas.ColumnsProjection;\n};\n\nexport type BulkInsertTableRecordsError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BulkError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 422;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type BulkInsertTableRecordsRequestBody = {\n  records: Record<string, any>[];\n};\n\nexport type BulkInsertTableRecordsVariables = {\n  body: BulkInsertTableRecordsRequestBody;\n  pathParams: BulkInsertTableRecordsPathParams;\n  queryParams?: BulkInsertTableRecordsQueryParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Bulk insert records\n */\nexport const bulkInsertTableRecords = (variables: BulkInsertTableRecordsVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.BulkInsertResponse,\n    BulkInsertTableRecordsError,\n    BulkInsertTableRecordsRequestBody,\n    {},\n    BulkInsertTableRecordsQueryParams,\n    BulkInsertTableRecordsPathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/bulk', method: 'post', ...variables, signal });\n\nexport type QueryTablePathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type QueryTableError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type QueryTableRequestBody = {\n  filter?: Schemas.FilterExpression;\n  sort?: Schemas.SortExpression;\n  page?: Schemas.PageConfig;\n  columns?: Schemas.ColumnsProjection;\n};\n\nexport type QueryTableVariables = {\n  body?: QueryTableRequestBody;\n  pathParams: QueryTablePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * The Query Table API can be used to retrieve all records in a table.\n * The API support filtering, sorting, selecting a subset of columns, and pagination.\n *\n * The overall structure of the request looks like this:\n *\n * ```json\n * // POST /db/<dbname>:<branch>/tables/<table>/query\n * {\n *   \"columns\": [...],\n *   \"filter\": {\n *     \"$all\": [...],\n *     \"$any\": [...]\n *     ...\n *   },\n *   \"sort\": {\n *     \"multiple\": [...]\n *     ...\n *   },\n *   \"page\": {\n *     ...\n *   }\n * }\n * ```\n *\n * ### Column selection\n *\n * If the `columns` array is not specified, all columns are included. For link\n * fields, only the ID column of the linked records is included in the response.\n *\n * If the `columns` array is specified, only the selected and internal\n * columns `id` and `xata` are included. The `*` wildcard can be used to\n * select all columns.\n *\n * For objects and link fields, if the column name of the object is specified, we\n * include all of its sub-keys. If only some sub-keys are specified (via dotted\n * notation, e.g. `\"settings.plan\"` ), then only those sub-keys from the object\n * are included.\n *\n * By the way of example, assuming two tables like this:\n *\n * ```json {\"truncate\": true}\n * {\n *   \"formatVersion\": \"1.0\",\n *   \"tables\": [\n *     {\n *       \"name\": \"teams\",\n *       \"columns\": [\n *         {\n *           \"name\": \"name\",\n *           \"type\": \"string\"\n *         },\n *         {\n *           \"name\": \"owner\",\n *           \"type\": \"link\",\n *           \"link\": {\n *             \"table\": \"users\"\n *           }\n *         },\n *         {\n *           \"name\": \"foundedDate\",\n *           \"type\": \"datetime\"\n *         },\n *       ]\n *     },\n *     {\n *       \"name\": \"users\",\n *       \"columns\": [\n *         {\n *           \"name\": \"email\",\n *           \"type\": \"email\"\n *         },\n *         {\n *           \"name\": \"full_name\",\n *           \"type\": \"string\"\n *         },\n *         {\n *           \"name\": \"address\",\n *           \"type\": \"object\",\n *           \"columns\": [\n *             {\n *               \"name\": \"street\",\n *               \"type\": \"string\"\n *             },\n *             {\n *               \"name\": \"number\",\n *               \"type\": \"int\"\n *             },\n *             {\n *               \"name\": \"zipcode\",\n *               \"type\": \"int\"\n *             }\n *           ]\n *         },\n *         {\n *           \"name\": \"team\",\n *           \"type\": \"link\",\n *           \"link\": {\n *             \"table\": \"teams\"\n *           }\n *         }\n *       ]\n *     }\n *   ]\n * }\n * ```\n *\n * A query like this:\n *\n * ```json\n * POST /db/<dbname>:<branch>/tables/<table>/query\n * {\n *   \"columns\": [\n *     \"name\",\n *     \"address.*\"\n *   ]\n * }\n * ```\n *\n * returns objects like:\n *\n * ```json\n * {\n *   \"name\": \"Kilian\",\n *   \"address\": {\n *     \"street\": \"New street\",\n *     \"number\": 41,\n *     \"zipcode\": 10407\n *   }\n * }\n * ```\n *\n * while a query like this:\n *\n * ```json\n * POST /db/<dbname>:<branch>/tables/<table>/query\n * {\n *   \"columns\": [\n *     \"name\",\n *     \"address.street\"\n *   ]\n * }\n * ```\n *\n * returns objects like:\n *\n * ```json\n * {\n *   \"id\": \"id1\"\n *   \"xata\": {\n *     \"version\": 0\n *   }\n *   \"name\": \"Kilian\",\n *   \"address\": {\n *     \"street\": \"New street\"\n *   }\n * }\n * ```\n *\n * If you want to return all columns from the main table and selected columns from the linked table, you can do it like this:\n *\n * ```json\n * {\n *   \"columns\": [\"*\", \"team.name\"]\n * }\n * ```\n *\n * The `\"*\"` in the above means all columns, including columns of objects. This returns data like:\n *\n * ```json\n * {\n *   \"id\": \"id1\"\n *   \"xata\": {\n *     \"version\": 0\n *   }\n *   \"name\": \"Kilian\",\n *   \"email\": \"kilian@gmail.com\",\n *   \"address\": {\n *     \"street\": \"New street\",\n *     \"number\": 41,\n *     \"zipcode\": 10407\n *   },\n *   \"team\": {\n *     \"id\": \"XX\",\n *     \"xata\": {\n *       \"version\": 0\n *     },\n *     \"name\": \"first team\"\n *   }\n * }\n * ```\n *\n * If you want all columns of the linked table, you can do:\n *\n * ```json\n * {\n *   \"columns\": [\"*\", \"team.*\"]\n * }\n * ```\n *\n * This returns, for example:\n *\n * ```json\n * {\n *   \"id\": \"id1\"\n *   \"xata\": {\n *     \"version\": 0\n *   }\n *   \"name\": \"Kilian\",\n *   \"email\": \"kilian@gmail.com\",\n *   \"address\": {\n *     \"street\": \"New street\",\n *     \"number\": 41,\n *     \"zipcode\": 10407\n *   },\n *   \"team\": {\n *     \"id\": \"XX\",\n *     \"xata\": {\n *       \"version\": 0\n *     },\n *     \"name\": \"first team\",\n *     \"code\": \"A1\",\n *     \"foundedDate\": \"2020-03-04T10:43:54.32Z\"\n *   }\n * }\n * ```\n *\n * ### Filtering\n *\n * There are two types of operators:\n *\n * - Operators that work on a single column: `$is`, `$contains`, `$pattern`,\n *   `$includes`, `$gt`, etc.\n * - Control operators that combine multiple conditions: `$any`, `$all`, `$not` ,\n *   `$none`, etc.\n *\n * All operators start with an `$` to differentiate them from column names\n * (which are not allowed to start with a dollar sign).\n *\n * #### Exact matching and control operators\n *\n * Filter by one column:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<column_name>\": \"value\"\n *   }\n * }\n * ```\n *\n * This is equivalent to using the `$is` operator:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<column_name>\": {\n *       \"$is\": \"value\"\n *     }\n *   }\n * }\n * ```\n *\n * For example:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"name\": \"r2\"\n *   }\n * }\n * ```\n *\n * Or:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"name\": {\n *       \"$is\": \"r2\"\n *     }\n *   }\n * }\n * ```\n *\n * For objects, both dots and nested versions work:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"settings.plan\": \"free\"\n *   }\n * }\n * ```\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"settings\": {\n *       \"plan\": \"free\"\n *     }\n *   }\n * }\n * ```\n *\n * If you want to OR together multiple values, you can use the `$any` operator with an array of values:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"settings.plan\": { \"$any\": [\"free\", \"paid\"] }\n *   }\n * }\n * ```\n *\n * If you specify multiple columns in the same filter, they are logically AND'ed together:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"settings.dark\": true,\n *     \"settings.plan\": \"free\"\n *   }\n * }\n * ```\n *\n * The above matches if both conditions are met.\n *\n * To be more explicit about it, you can use `$all` or `$any`:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"$any\": {\n *       \"settings.dark\": true,\n *       \"settings.plan\": \"free\"\n *     }\n *   }\n * }\n * ```\n *\n * The `$all` and `$any` operators can also receive an array of objects, which allows for repeating column names:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"$any\": [\n *       {\n *         \"name\": \"r1\"\n *       },\n *       {\n *         \"name\": \"r2\"\n *       }\n *     ]\n *   }\n * }\n * ```\n *\n * You can check for a value being not-null with `$exists`:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"$exists\": \"settings\"\n *   }\n * }\n * ```\n *\n * This can be combined with `$all` or `$any` :\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"$all\": [\n *       {\n *         \"$exists\": \"settings\"\n *       },\n *       {\n *         \"$exists\": \"name\"\n *       }\n *     ]\n *   }\n * }\n * ```\n *\n * Or you can use the inverse operator `$notExists`:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"$notExists\": \"settings\"\n *   }\n * }\n * ```\n *\n * #### Partial match\n *\n * `$contains` is the simplest operator for partial matching. We should generally\n * discourage overusing `$contains` because it typically can't make use of\n * indices.\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<column_name>\": {\n *       \"$contains\": \"value\"\n *     }\n *   }\n * }\n * ```\n *\n * Wildcards are supported via the `$pattern` operator:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<column_name>\": {\n *       \"$pattern\": \"v*alu?\"\n *     }\n *   }\n * }\n * ```\n *\n * The `$pattern` operator accepts two wildcard characters:\n * * `*` matches zero or more characters\n * * `?` matches exactly one character\n *\n * If you want to match a string that contains a wildcard character, you can escape them using a backslash (`\\`). You can escape a backslash by usign another backslash.\n *\n * We could also have `$endsWith` and `$startsWith` operators:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<column_name>\": {\n *       \"$endsWith\": \".gz\"\n *     },\n *     \"<column_name>\": {\n *       \"$startsWith\": \"tmp-\"\n *     }\n *   }\n * }\n * ```\n *\n * #### Numeric or datetime ranges\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<column_name>\": {\n *       \"$ge\": 0,\n *       \"$lt\": 100\n *     }\n *   }\n * }\n * ```\n * Date ranges support the same operators, with the date using the format defined in\n * [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339):\n * ```json\n * {\n *   \"filter\": {\n *     \"<column_name>\": {\n *       \"$gt\": \"2019-10-12T07:20:50.52Z\",\n *       \"$lt\": \"2021-10-12T07:20:50.52Z\"\n *     }\n *   }\n * }\n * ```\n * The supported operators are `$gt`, `$lt`, `$ge`, `$le`.\n *\n * #### Negations\n *\n * A general `$not` operator can inverse any operation.\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"$not\": {\n *       \"<column_name1>\": \"value1\",\n *       \"<column_name2>\": \"value1\"\n *     }\n *   }\n * }\n * ```\n *\n * Note: in the above the two condition are AND together, so this does (NOT ( ...\n * AND ...))\n *\n * Or more complex:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"$not\": {\n *       \"$any\": [\n *         {\n *           \"<column_name1>\": \"value1\"\n *         },\n *         {\n *           \"$all\": [\n *             {\n *               \"<column_name2>\": \"value2\"\n *             },\n *             {\n *               \"<column_name3>\": \"value3\"\n *             }\n *           ]\n *         }\n *       ]\n *     }\n *   }\n * }\n * ```\n *\n * The `$not: { $any: {}}` can be shorted using the `$none` operator:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"$none\": {\n *       \"<column_name1>\": \"value1\",\n *       \"<column_name2>\": \"value1\"\n *     }\n *   }\n * }\n * ```\n *\n * In addition, you can use operators like `$isNot` or `$notExists` to simplify expressions:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<column_name>\": {\n *       \"$isNot\": \"2019-10-12T07:20:50.52Z\"\n *     }\n *   }\n * }\n * ```\n *\n * #### Working with arrays\n *\n * To test that an array contains a value, use `$includes`.\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<array_name>\": {\n *       \"$includes\": \"value\"\n *     }\n *   }\n * }\n * ```\n *\n * The `$includes` operator accepts a custom predicate that will check if any\n * array values matches the predicate. For example a complex predicate can include\n * the `$all` , `$contains` and `$endsWith` operators:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"<array name>\": {\n *       \"$includes\": {\n *         \"$all\": [\n *           { \"$contains\": \"label\" },\n *           { \"$not\": { \"$endsWith\": \"-debug\" } }\n *         ]\n *       }\n *     }\n *   }\n * }\n * ```\n *\n * The `$includes` all operator succeeds if any column in the array matches the\n * predicate. The `$includesAll` operator succeeds if all array items match the\n * predicate. The `$includesNone` operator succeeds if no array item matches the\n * predicate. The `$includes` operator is a synonym for the `$includesAny`\n * operator.\n *\n * Here is an example of using the `$includesAll` operator:\n *\n * ```json\n * {\n *   \"filter\": {\n *     \"settings.labels\": {\n *       \"$includesAll\": [{ \"$contains\": \"label\" }]\n *     }\n *   }\n * }\n * ```\n *\n * The above matches if all label values contain the string \"labels\".\n *\n * ### Sorting\n *\n * Sorting by one element:\n *\n * ```json\n * POST /db/demo:main/tables/table/query\n * {\n *   \"sort\": {\n *     \"index\": \"asc\"\n *   }\n * }\n * ```\n *\n * or descendently:\n *\n * ```json\n * POST /db/demo:main/tables/table/query\n * {\n *   \"sort\": {\n *     \"index\": \"desc\"\n *   }\n * }\n * ```\n *\n * Sorting by multiple fields:\n *\n * ```json\n * POST /db/demo:main/tables/table/query\n * {\n *   \"sort\": [\n *     {\n *       \"index\": \"desc\"\n *     },\n *     {\n *       \"createdAt\": \"desc\"\n *     }\n *   ]\n * }\n * ```\n *\n * ### Pagination\n *\n * We offer cursor pagination and offset pagination. For queries that are expected to return more than 1000 records,\n * cursor pagination is needed in order to retrieve all of their results. The offset pagination method is limited to 1000 records.\n *\n * Example of size + offset pagination:\n *\n * ```json\n * POST /db/demo:main/tables/table/query\n * {\n *   \"page\": {\n *     \"size\": 100,\n *     \"offset\": 200\n *   }\n * }\n * ```\n *\n * The `page.size` parameter represents the maximum number of records returned by this query. It has a default value of 20 and a maximum value of 200.\n * The `page.offset` parameter represents the number of matching records to skip. It has a default value of 0 and a maximum value of 800.\n *\n * Example of cursor pagination:\n *\n * ```json\n * POST /db/demo:main/tables/table/query\n * {\n *   \"page\": {\n *     \"after\":\"fMoxCsIwFIDh3WP8c4amDai5hO5SJCRNfaVSeC9b6d1FD\"\n *   }\n * }\n * ```\n *\n * In the above example, the value of the `page.after` parameter is the cursor returned by the previous query. A sample response is shown below:\n *\n * ```json\n * {\n *   \"meta\": {\n *     \"page\": {\n *       \"cursor\": \"fMoxCsIwFIDh3WP8c4amDai5hO5SJCRNfaVSeC9b6d1FD\",\n *       \"more\": true\n *     }\n *   },\n *   \"records\": [...]\n * }\n * ```\n *\n * The `page` object might contain the follow keys, in addition to `size` and `offset` that were introduced before:\n *\n * - `after`: Return the next page 'after' the current cursor\n * - `before`: Return the previous page 'before' the current cursor.\n * - `first`: Return the first page in the table from a cursor.\n * - `last`: Return the last N records in the table from a cursor, where N is the `page.size` parameter.\n *\n * The request will fail if an invalid cursor value is given to `page.before`,\n * `page.after`, `page.first` , or `page.last`. No other cursor setting can be\n * used if `page.first` or `page.last` is set in a query.\n *\n * If both `page.before` and `page.after` parameters are present we treat the\n * request as a range query. The range query will return all entries after\n * `page.after`, but before `page.before`, up to `page.size` or the maximum\n * page size. This query requires both cursors to use the same filters and sort\n * settings, plus we require `page.after < page.before`. The range query returns\n * a new cursor. If the range encompass multiple pages the next page in the range\n * can be queried by update `page.after` to the returned cursor while keeping the\n * `page.before` cursor from the first range query.\n *\n * The `filter` , `columns`, `sort` , and `page.size` configuration will be\n * encoded with the cursor. The pagination request will be invalid if\n * `filter` or `sort` is set. The columns returned and page size can be changed\n * anytime by passing the `columns` or `page.size` settings to the next query.\n *\n * **Special cursors:**\n *\n * - `page.after=end`: Result points past the last entry. The list of records\n *   returned is empty, but `page.meta.cursor` will include a cursor that can be\n *   used to \"tail\" the table from the end waiting for new data to be inserted.\n * - `page.before=end`: This cursor returns the last page.\n * - `page.first=<cursor>`: Go to first page. This is equivalent to querying the\n *   first page without a cursor but `filter` and `sort` . Yet the `page.first`\n *   cursor can be convenient at times as user code does not need to remember the\n *   filter, sort, columns or page size configuration. All these information are\n *   read from the cursor.\n * - `page.last=<cursor>`: Go to the end of the table. This is equivalent to querying the\n *   last page with `page.before=end`, `filter`, and `sort` . Yet the\n *   `page.last` cursor can be more convenient at times as user code does not\n *   need to remember the filter, sort, columns or page size configuration. All\n *   these information are read from the cursor.\n *\n * When using special cursors like `page.after=\"end\"` or `page.before=\"end\"`, we\n * still allow `filter` and `sort` to be set.\n *\n * Example of getting the last page:\n *\n * ```json\n * POST /db/demo:main/tables/table/query\n * {\n *   \"page\": {\n *     \"size\": 10,\n *     \"before\": \"end\"\n *   }\n * }\n * ```\n */\nexport const queryTable = (variables: QueryTableVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Responses.QueryResponse, QueryTableError, QueryTableRequestBody, {}, {}, QueryTablePathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}/query',\n    method: 'post',\n    ...variables,\n    signal\n  });\n\nexport type SearchBranchPathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  workspace: string;\n  region: string;\n};\n\nexport type SearchBranchError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type SearchBranchRequestBody = {\n  /**\n   * An array with the tables in which to search. By default, all tables are included. Optionally, filters can be included that apply to each table.\n   */\n  tables?: (\n    | string\n    | {\n        /**\n         * The name of the table.\n         */\n        table: string;\n        filter?: Schemas.FilterExpression;\n        target?: Schemas.TargetExpression;\n        boosters?: Schemas.BoosterExpression[];\n      }\n  )[];\n  /**\n   * The query string.\n   *\n   * @minLength 1\n   */\n  query: string;\n  fuzziness?: Schemas.FuzzinessExpression;\n  prefix?: Schemas.PrefixExpression;\n  highlight?: Schemas.HighlightExpression;\n};\n\nexport type SearchBranchVariables = {\n  body: SearchBranchRequestBody;\n  pathParams: SearchBranchPathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Run a free text search operation across the database branch.\n */\nexport const searchBranch = (variables: SearchBranchVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Responses.SearchResponse, SearchBranchError, SearchBranchRequestBody, {}, {}, SearchBranchPathParams>({\n    url: '/db/{dbBranchName}/search',\n    method: 'post',\n    ...variables,\n    signal\n  });\n\nexport type SearchTablePathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type SearchTableError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type SearchTableRequestBody = {\n  /**\n   * The query string.\n   *\n   * @minLength 1\n   */\n  query: string;\n  fuzziness?: Schemas.FuzzinessExpression;\n  target?: Schemas.TargetExpression;\n  prefix?: Schemas.PrefixExpression;\n  filter?: Schemas.FilterExpression;\n  highlight?: Schemas.HighlightExpression;\n  boosters?: Schemas.BoosterExpression[];\n};\n\nexport type SearchTableVariables = {\n  body: SearchTableRequestBody;\n  pathParams: SearchTablePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * Run a free text search operation in a particular table.\n *\n * The endpoint accepts a `query` parameter that is used for the free text search and a set of structured filters (via the `filter` parameter) that are applied before the search. The `filter` parameter uses the same syntax as the [query endpoint](/api-reference/db/db_branch_name/tables/table_name/) with the following exceptions:\n * * filters `$contains`, `$startsWith`, `$endsWith` don't work on columns of type `text`\n * * filtering on columns of type `multiple` is currently unsupported\n */\nexport const searchTable = (variables: SearchTableVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<Responses.SearchResponse, SearchTableError, SearchTableRequestBody, {}, {}, SearchTablePathParams>({\n    url: '/db/{dbBranchName}/tables/{tableName}/search',\n    method: 'post',\n    ...variables,\n    signal\n  });\n\nexport type SummarizeTablePathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type SummarizeTableError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type SummarizeTableRequestBody = {\n  filter?: Schemas.FilterExpression;\n  columns?: Schemas.ColumnsProjection;\n  summaries?: Schemas.SummaryExpressionList;\n  sort?: Schemas.SortExpression;\n  summariesFilter?: Schemas.FilterExpression;\n  page?: {\n    /**\n     * The number of records returned by summarize. If the amount of data you have exceeds this, or you have\n     * more complex reporting requirements, we recommend that you use the aggregate endpoint instead.\n     *\n     * @default 20\n     * @maximum 1000\n     * @minimum 1\n     */\n    size?: number;\n  };\n};\n\nexport type SummarizeTableVariables = {\n  body?: SummarizeTableRequestBody;\n  pathParams: SummarizeTablePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * This endpoint allows you to (optionally) define groups, and then to run\n * calculations on the values in each group. This is most helpful when\n * you'd like to understand the data you have in your database.\n *\n * A group is a combination of unique values. If you create a group for\n * `sold_by`, `product_name`, we will return one row for every combination\n * of `sold_by` and `product_name` you have in your database. When you\n * want to calculate statistics, you define these groups and ask Xata to\n * calculate data on each group.\n *\n * **Some questions you can ask of your data:**\n *\n * How many records do I have in this table?\n * - Set `columns: []` as we we want data from the entire table, so we ask\n * for no groups.\n * - Set `summaries: {\"total\": {\"count\": \"*\"}}` in order to see the count\n * of all records. We use `count: *` here we'd like to know the total\n * amount of rows; ignoring whether they are `null` or not.\n *\n * What are the top total sales for each product in July 2022 and sold\n * more than 10 units?\n * - Set `filter: {soldAt: {\n *   \"$ge\": \"2022-07-01T00:00:00.000Z\",\n *   \"$lt\": \"2022-08-01T00:00:00.000Z\"}\n * }`\n * in order to limit the result set to sales recorded in July 2022.\n * - Set `columns: [product_name]` as we'd like to run calculations on\n * each unique product name in our table. Setting `columns` like this will\n * produce one row per unique product name.\n * - Set `summaries: {\"total_sales\": {\"count\": \"product_name\"}}` as we'd\n * like to create a field called \"total_sales\" for each group. This field\n * will count all rows in each group with non-null product names.\n * - Set `sort: [{\"total_sales\": \"desc\"}]` in order to bring the rows with\n * the highest total_sales field to the top.\n * - Set `summariesFilter: {\"total_sales\": {\"$ge\": 10}}` to only send back data\n * with greater than or equal to 10 units.\n *\n * `columns`: tells Xata how to create each group. If you add `product_id`\n * we will create a new group for every unique `product_id`.\n *\n * `summaries`: tells Xata which calculations to run on each group.\n *\n * `sort`: tells Xata in which order you'd like to see results. You may\n * sort by fields specified in `columns` as well as the summary names\n * defined in `summaries`.\n *\n * note: Sorting on summarized values can be slower on very large tables;\n * this will impact your rate limit significantly more than other queries.\n * Try use `filter` [coming soon] to reduce the amount of data being\n * processed in order to reduce impact on your limits.\n *\n * `summariesFilter`: tells Xata how to filter the results of a summary.\n * It has the same syntax as `filter`, however, by using `summariesFilter`\n * you may also filter on the results of a query.\n *\n * note: This is a much slower to use than `filter`. We recommend using\n * `filter` wherever possible and `summariesFilter` when it's not\n * possible to use `filter`.\n *\n * `page.size`: tells Xata how many records to return. If unspecified, Xata\n * will return the default size.\n */\nexport const summarizeTable = (variables: SummarizeTableVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.SummarizeResponse,\n    SummarizeTableError,\n    SummarizeTableRequestBody,\n    {},\n    {},\n    SummarizeTablePathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/summarize', method: 'post', ...variables, signal });\n\nexport type AggregateTablePathParams = {\n  /**\n   * The DBBranchName matches the pattern `{db_name}:{branch_name}`.\n   */\n  dbBranchName: Schemas.DBBranchName;\n  /**\n   * The Table name\n   */\n  tableName: Schemas.TableName;\n  workspace: string;\n  region: string;\n};\n\nexport type AggregateTableError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type AggregateTableRequestBody = {\n  filter?: Schemas.FilterExpression;\n  aggs?: Schemas.AggExpressionMap;\n};\n\nexport type AggregateTableVariables = {\n  body?: AggregateTableRequestBody;\n  pathParams: AggregateTablePathParams;\n} & DataPlaneFetcherExtraProps;\n\n/**\n * This endpoint allows you to run aggragations (analytics) on the data from one table.\n * While the summary endpoint is served from a transactional store and the results are strongly\n * consistent, the aggregate endpoint is served from our columnar store and the results are\n * only eventually consistent. On the other hand, the aggregate endpoint uses a\n * store that is more appropiate for analytics, makes use of approximative algorithms\n * (e.g for cardinality), and is generally faster and can do more complex aggregations.\n */\nexport const aggregateTable = (variables: AggregateTableVariables, signal?: AbortSignal) =>\n  dataPlaneFetch<\n    Responses.AggResponse,\n    AggregateTableError,\n    AggregateTableRequestBody,\n    {},\n    {},\n    AggregateTablePathParams\n  >({ url: '/db/{dbBranchName}/tables/{tableName}/aggregate', method: 'post', ...variables, signal });\n\nexport const operationsByTag = {\n  database: {\n    dEPRECATEDgetDatabaseList,\n    dEPRECATEDcreateDatabase,\n    dEPRECATEDdeleteDatabase,\n    dEPRECATEDgetDatabaseMetadata,\n    dEPRECATEDupdateDatabaseMetadata\n  },\n  branch: {\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  searchAndFilter: { queryTable, searchBranch, searchTable, summarizeTable, aggregateTable }\n};\n","import { TraceFunction } from '../schema/tracing';\nimport { PossibleErrors } from './errors';\nimport { fetch, FetchImpl, WorkspaceApiUrlBuilder } from './fetcher';\n\nexport type ControlPlaneFetcherExtraProps = {\n  apiUrl: string;\n  workspacesApiUrl: string | WorkspaceApiUrlBuilder;\n  fetchImpl: FetchImpl;\n  apiKey: string;\n  trace: TraceFunction;\n  signal?: AbortSignal;\n  clientID?: string;\n  sessionID?: string;\n};\n\nexport type ErrorWrapper<TError> = TError | { status: 'unknown'; payload: string };\n\nexport type ControlPlaneFetcherOptions<TBody, THeaders, TQueryParams, TPathParams> = {\n  url: string;\n  method: string;\n  body?: TBody;\n  headers?: THeaders;\n  queryParams?: TQueryParams;\n  pathParams?: TPathParams;\n  signal?: AbortSignal;\n} & ControlPlaneFetcherExtraProps;\n\nexport const controlPlaneFetch = async <\n  TData,\n  TError extends ErrorWrapper<{ status: unknown; payload: PossibleErrors }>,\n  TBody extends Record<string, unknown> | undefined | null,\n  THeaders extends Record<string, unknown>,\n  TQueryParams extends Record<string, unknown>,\n  TPathParams extends Partial<Record<string, string | number>>\n>(\n  options: ControlPlaneFetcherOptions<TBody, THeaders, TQueryParams, TPathParams>\n): Promise<TData> =>\n  fetch<TData, TError, TBody, THeaders, TQueryParams, TPathParams>({ ...options, endpoint: 'controlPlane' });\n","/**\n * Generated by @openapi-codegen\n *\n * @version 1.0\n */\nimport type * as Fetcher from './controlPlaneFetcher';\nimport { controlPlaneFetch, ControlPlaneFetcherExtraProps } from './controlPlaneFetcher';\nimport type * as Schemas from './controlPlaneSchemas';\nimport type * as Responses from './controlPlaneResponses';\n\nexport type GetUserError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetUserVariables = ControlPlaneFetcherExtraProps;\n\n/**\n * Return details of the user making the request\n */\nexport const getUser = (variables: GetUserVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<Schemas.UserWithID, GetUserError, undefined, {}, {}, {}>({\n    url: '/user',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type UpdateUserError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateUserVariables = {\n  body: Schemas.User;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Update user info\n */\nexport const updateUser = (variables: UpdateUserVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<Schemas.UserWithID, UpdateUserError, Schemas.User, {}, {}, {}>({\n    url: '/user',\n    method: 'put',\n    ...variables,\n    signal\n  });\n\nexport type DeleteUserError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DeleteUserVariables = ControlPlaneFetcherExtraProps;\n\n/**\n * Delete the user making the request\n */\nexport const deleteUser = (variables: DeleteUserVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<undefined, DeleteUserError, undefined, {}, {}, {}>({\n    url: '/user',\n    method: 'delete',\n    ...variables,\n    signal\n  });\n\nexport type GetUserAPIKeysError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetUserAPIKeysResponse = {\n  keys: {\n    name: string;\n    createdAt: Schemas.DateTime;\n  }[];\n};\n\nexport type GetUserAPIKeysVariables = ControlPlaneFetcherExtraProps;\n\n/**\n * Retrieve a list of existing user API keys\n */\nexport const getUserAPIKeys = (variables: GetUserAPIKeysVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<GetUserAPIKeysResponse, GetUserAPIKeysError, undefined, {}, {}, {}>({\n    url: '/user/keys',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type CreateUserAPIKeyPathParams = {\n  /**\n   * API Key name\n   */\n  keyName: Schemas.APIKeyName;\n};\n\nexport type CreateUserAPIKeyError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CreateUserAPIKeyResponse = {\n  name: string;\n  key: string;\n  createdAt: Schemas.DateTime;\n};\n\nexport type CreateUserAPIKeyVariables = {\n  pathParams: CreateUserAPIKeyPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Create and return new API key\n */\nexport const createUserAPIKey = (variables: CreateUserAPIKeyVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<CreateUserAPIKeyResponse, CreateUserAPIKeyError, undefined, {}, {}, CreateUserAPIKeyPathParams>({\n    url: '/user/keys/{keyName}',\n    method: 'post',\n    ...variables,\n    signal\n  });\n\nexport type DeleteUserAPIKeyPathParams = {\n  /**\n   * API Key name\n   */\n  keyName: Schemas.APIKeyName;\n};\n\nexport type DeleteUserAPIKeyError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DeleteUserAPIKeyVariables = {\n  pathParams: DeleteUserAPIKeyPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Delete an existing API key\n */\nexport const deleteUserAPIKey = (variables: DeleteUserAPIKeyVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<undefined, DeleteUserAPIKeyError, undefined, {}, {}, DeleteUserAPIKeyPathParams>({\n    url: '/user/keys/{keyName}',\n    method: 'delete',\n    ...variables,\n    signal\n  });\n\nexport type GetWorkspacesListError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetWorkspacesListResponse = {\n  workspaces: {\n    id: Schemas.WorkspaceID;\n    name: string;\n    slug: string;\n    role: Schemas.Role;\n  }[];\n};\n\nexport type GetWorkspacesListVariables = ControlPlaneFetcherExtraProps;\n\n/**\n * Retrieve the list of workspaces the user belongs to\n */\nexport const getWorkspacesList = (variables: GetWorkspacesListVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<GetWorkspacesListResponse, GetWorkspacesListError, undefined, {}, {}, {}>({\n    url: '/workspaces',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type CreateWorkspaceError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CreateWorkspaceVariables = {\n  body: Schemas.WorkspaceMeta;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Creates a new workspace with the user requesting it as its single owner.\n */\nexport const createWorkspace = (variables: CreateWorkspaceVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<Schemas.Workspace, CreateWorkspaceError, Schemas.WorkspaceMeta, {}, {}, {}>({\n    url: '/workspaces',\n    method: 'post',\n    ...variables,\n    signal\n  });\n\nexport type GetWorkspacePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n};\n\nexport type GetWorkspaceError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetWorkspaceVariables = {\n  pathParams: GetWorkspacePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Retrieve workspace info from a workspace ID\n */\nexport const getWorkspace = (variables: GetWorkspaceVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<Schemas.Workspace, GetWorkspaceError, undefined, {}, {}, GetWorkspacePathParams>({\n    url: '/workspaces/{workspaceId}',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type UpdateWorkspacePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n};\n\nexport type UpdateWorkspaceError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateWorkspaceVariables = {\n  body: Schemas.WorkspaceMeta;\n  pathParams: UpdateWorkspacePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Update workspace info\n */\nexport const updateWorkspace = (variables: UpdateWorkspaceVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<Schemas.Workspace, UpdateWorkspaceError, Schemas.WorkspaceMeta, {}, {}, UpdateWorkspacePathParams>({\n    url: '/workspaces/{workspaceId}',\n    method: 'put',\n    ...variables,\n    signal\n  });\n\nexport type DeleteWorkspacePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n};\n\nexport type DeleteWorkspaceError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DeleteWorkspaceVariables = {\n  pathParams: DeleteWorkspacePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Delete the workspace with the provided ID\n */\nexport const deleteWorkspace = (variables: DeleteWorkspaceVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<undefined, DeleteWorkspaceError, undefined, {}, {}, DeleteWorkspacePathParams>({\n    url: '/workspaces/{workspaceId}',\n    method: 'delete',\n    ...variables,\n    signal\n  });\n\nexport type GetWorkspaceMembersListPathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n};\n\nexport type GetWorkspaceMembersListError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetWorkspaceMembersListVariables = {\n  pathParams: GetWorkspaceMembersListPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Retrieve the list of members of the given workspace\n */\nexport const getWorkspaceMembersList = (variables: GetWorkspaceMembersListVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    Schemas.WorkspaceMembers,\n    GetWorkspaceMembersListError,\n    undefined,\n    {},\n    {},\n    GetWorkspaceMembersListPathParams\n  >({ url: '/workspaces/{workspaceId}/members', method: 'get', ...variables, signal });\n\nexport type UpdateWorkspaceMemberRolePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * UserID\n   */\n  userId: Schemas.UserID;\n};\n\nexport type UpdateWorkspaceMemberRoleError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateWorkspaceMemberRoleRequestBody = {\n  role: Schemas.Role;\n};\n\nexport type UpdateWorkspaceMemberRoleVariables = {\n  body: UpdateWorkspaceMemberRoleRequestBody;\n  pathParams: UpdateWorkspaceMemberRolePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Update a workspace member role. Workspaces must always have at least one owner, so this operation will fail if trying to remove owner role from the last owner in the workspace.\n */\nexport const updateWorkspaceMemberRole = (variables: UpdateWorkspaceMemberRoleVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    undefined,\n    UpdateWorkspaceMemberRoleError,\n    UpdateWorkspaceMemberRoleRequestBody,\n    {},\n    {},\n    UpdateWorkspaceMemberRolePathParams\n  >({ url: '/workspaces/{workspaceId}/members/{userId}', method: 'put', ...variables, signal });\n\nexport type RemoveWorkspaceMemberPathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * UserID\n   */\n  userId: Schemas.UserID;\n};\n\nexport type RemoveWorkspaceMemberError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type RemoveWorkspaceMemberVariables = {\n  pathParams: RemoveWorkspaceMemberPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Remove the member from the workspace\n */\nexport const removeWorkspaceMember = (variables: RemoveWorkspaceMemberVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<undefined, RemoveWorkspaceMemberError, undefined, {}, {}, RemoveWorkspaceMemberPathParams>({\n    url: '/workspaces/{workspaceId}/members/{userId}',\n    method: 'delete',\n    ...variables,\n    signal\n  });\n\nexport type InviteWorkspaceMemberPathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n};\n\nexport type InviteWorkspaceMemberError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 409;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type InviteWorkspaceMemberRequestBody = {\n  /**\n   * @format email\n   */\n  email: string;\n  role: Schemas.Role;\n};\n\nexport type InviteWorkspaceMemberVariables = {\n  body: InviteWorkspaceMemberRequestBody;\n  pathParams: InviteWorkspaceMemberPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Invite some user to join the workspace with the given role\n */\nexport const inviteWorkspaceMember = (variables: InviteWorkspaceMemberVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    Schemas.WorkspaceInvite,\n    InviteWorkspaceMemberError,\n    InviteWorkspaceMemberRequestBody,\n    {},\n    {},\n    InviteWorkspaceMemberPathParams\n  >({ url: '/workspaces/{workspaceId}/invites', method: 'post', ...variables, signal });\n\nexport type UpdateWorkspaceMemberInvitePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * Invite identifier\n   */\n  inviteId: Schemas.InviteID;\n};\n\nexport type UpdateWorkspaceMemberInviteError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n  | {\n      status: 422;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateWorkspaceMemberInviteRequestBody = {\n  role: Schemas.Role;\n};\n\nexport type UpdateWorkspaceMemberInviteVariables = {\n  body: UpdateWorkspaceMemberInviteRequestBody;\n  pathParams: UpdateWorkspaceMemberInvitePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * This operation provides a way to update an existing invite. Updates are performed in-place; they do not change the invite link, the expiry time, nor do they re-notify the recipient of the invite.\n */\nexport const updateWorkspaceMemberInvite = (variables: UpdateWorkspaceMemberInviteVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    Schemas.WorkspaceInvite,\n    UpdateWorkspaceMemberInviteError,\n    UpdateWorkspaceMemberInviteRequestBody,\n    {},\n    {},\n    UpdateWorkspaceMemberInvitePathParams\n  >({ url: '/workspaces/{workspaceId}/invites/{inviteId}', method: 'patch', ...variables, signal });\n\nexport type CancelWorkspaceMemberInvitePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * Invite identifier\n   */\n  inviteId: Schemas.InviteID;\n};\n\nexport type CancelWorkspaceMemberInviteError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type CancelWorkspaceMemberInviteVariables = {\n  pathParams: CancelWorkspaceMemberInvitePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * This operation provides a way to cancel invites by deleting them. Already accepted invites cannot be deleted.\n */\nexport const cancelWorkspaceMemberInvite = (variables: CancelWorkspaceMemberInviteVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    undefined,\n    CancelWorkspaceMemberInviteError,\n    undefined,\n    {},\n    {},\n    CancelWorkspaceMemberInvitePathParams\n  >({ url: '/workspaces/{workspaceId}/invites/{inviteId}', method: 'delete', ...variables, signal });\n\nexport type AcceptWorkspaceMemberInvitePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * Invite Key (secret) for the invited user\n   */\n  inviteKey: Schemas.InviteKey;\n};\n\nexport type AcceptWorkspaceMemberInviteError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type AcceptWorkspaceMemberInviteVariables = {\n  pathParams: AcceptWorkspaceMemberInvitePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Accept the invitation to join a workspace. If the operation succeeds the user will be a member of the workspace\n */\nexport const acceptWorkspaceMemberInvite = (variables: AcceptWorkspaceMemberInviteVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    undefined,\n    AcceptWorkspaceMemberInviteError,\n    undefined,\n    {},\n    {},\n    AcceptWorkspaceMemberInvitePathParams\n  >({ url: '/workspaces/{workspaceId}/invites/{inviteKey}/accept', method: 'post', ...variables, signal });\n\nexport type ResendWorkspaceMemberInvitePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * Invite identifier\n   */\n  inviteId: Schemas.InviteID;\n};\n\nexport type ResendWorkspaceMemberInviteError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type ResendWorkspaceMemberInviteVariables = {\n  pathParams: ResendWorkspaceMemberInvitePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * This operation provides a way to resend an Invite notification. Invite notifications can only be sent for Invites not yet accepted.\n */\nexport const resendWorkspaceMemberInvite = (variables: ResendWorkspaceMemberInviteVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    undefined,\n    ResendWorkspaceMemberInviteError,\n    undefined,\n    {},\n    {},\n    ResendWorkspaceMemberInvitePathParams\n  >({ url: '/workspaces/{workspaceId}/invites/{inviteId}/resend', method: 'post', ...variables, signal });\n\nexport type GetDatabaseListPathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n};\n\nexport type GetDatabaseListError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type GetDatabaseListVariables = {\n  pathParams: GetDatabaseListPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * List all databases available in your Workspace.\n */\nexport const getDatabaseList = (variables: GetDatabaseListVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<Schemas.ListDatabasesResponse, GetDatabaseListError, undefined, {}, {}, GetDatabaseListPathParams>({\n    url: '/workspaces/{workspaceId}/dbs',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport type CreateDatabasePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n};\n\nexport type CreateDatabaseError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type CreateDatabaseResponse = {\n  /**\n   * @minLength 1\n   */\n  databaseName: string;\n  branchName?: string;\n  status: Schemas.MigrationStatus;\n};\n\nexport type CreateDatabaseRequestBody = {\n  /**\n   * @minLength 1\n   */\n  branchName?: string;\n  /**\n   * @minLength 1\n   */\n  region: string;\n  ui?: {\n    color?: string;\n  };\n  metadata?: Schemas.BranchMetadata;\n};\n\nexport type CreateDatabaseVariables = {\n  body: CreateDatabaseRequestBody;\n  pathParams: CreateDatabasePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Create Database with identifier name\n */\nexport const createDatabase = (variables: CreateDatabaseVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    CreateDatabaseResponse,\n    CreateDatabaseError,\n    CreateDatabaseRequestBody,\n    {},\n    {},\n    CreateDatabasePathParams\n  >({ url: '/workspaces/{workspaceId}/dbs/{dbName}', method: 'put', ...variables, signal });\n\nexport type DeleteDatabasePathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n};\n\nexport type DeleteDatabaseError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type DeleteDatabaseResponse = {\n  status: Schemas.MigrationStatus;\n};\n\nexport type DeleteDatabaseVariables = {\n  pathParams: DeleteDatabasePathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Delete a database and all of its branches and tables permanently.\n */\nexport const deleteDatabase = (variables: DeleteDatabaseVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<DeleteDatabaseResponse, DeleteDatabaseError, undefined, {}, {}, DeleteDatabasePathParams>({\n    url: '/workspaces/{workspaceId}/dbs/{dbName}',\n    method: 'delete',\n    ...variables,\n    signal\n  });\n\nexport type GetDatabaseMetadataPathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n};\n\nexport type GetDatabaseMetadataError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type GetDatabaseMetadataVariables = {\n  pathParams: GetDatabaseMetadataPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Retrieve metadata of the given database\n */\nexport const getDatabaseMetadata = (variables: GetDatabaseMetadataVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    Schemas.DatabaseMetadata,\n    GetDatabaseMetadataError,\n    undefined,\n    {},\n    {},\n    GetDatabaseMetadataPathParams\n  >({ url: '/workspaces/{workspaceId}/dbs/{dbName}', method: 'get', ...variables, signal });\n\nexport type UpdateDatabaseMetadataPathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n  /**\n   * The Database Name\n   */\n  dbName: Schemas.DBName;\n};\n\nexport type UpdateDatabaseMetadataError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n  | {\n      status: 404;\n      payload: Responses.SimpleError;\n    }\n>;\n\nexport type UpdateDatabaseMetadataRequestBody = {\n  ui?: {\n    /**\n     * @minLength 1\n     */\n    color?: string;\n  };\n};\n\nexport type UpdateDatabaseMetadataVariables = {\n  body?: UpdateDatabaseMetadataRequestBody;\n  pathParams: UpdateDatabaseMetadataPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * Update the color of the selected database\n */\nexport const updateDatabaseMetadata = (variables: UpdateDatabaseMetadataVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<\n    Schemas.DatabaseMetadata,\n    UpdateDatabaseMetadataError,\n    UpdateDatabaseMetadataRequestBody,\n    {},\n    {},\n    UpdateDatabaseMetadataPathParams\n  >({ url: '/workspaces/{workspaceId}/dbs/{dbName}', method: 'patch', ...variables, signal });\n\nexport type ListRegionsPathParams = {\n  /**\n   * Workspace ID\n   */\n  workspaceId: Schemas.WorkspaceID;\n};\n\nexport type ListRegionsError = Fetcher.ErrorWrapper<\n  | {\n      status: 400;\n      payload: Responses.BadRequestError;\n    }\n  | {\n      status: 401;\n      payload: Responses.AuthError;\n    }\n>;\n\nexport type ListRegionsVariables = {\n  pathParams: ListRegionsPathParams;\n} & ControlPlaneFetcherExtraProps;\n\n/**\n * List regions available to create a database on\n */\nexport const listRegions = (variables: ListRegionsVariables, signal?: AbortSignal) =>\n  controlPlaneFetch<Schemas.ListRegionsResponse, ListRegionsError, undefined, {}, {}, ListRegionsPathParams>({\n    url: '/workspaces/{workspaceId}/regions',\n    method: 'get',\n    ...variables,\n    signal\n  });\n\nexport const operationsByTag = {\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    listRegions\n  }\n};\n","export * from './dataPlaneComponents';\nexport * from './controlPlaneComponents';\n\nimport { operationsByTag as dataPlaneOperations } from './dataPlaneComponents';\nimport { operationsByTag as controlPlaneOperations } from './controlPlaneComponents';\n\nimport { deepMerge } from '../util/lang';\n\nexport const operationsByTag = deepMerge(dataPlaneOperations, controlPlaneOperations);\n","import { isObject, isString } from '../util/lang';\n\ntype HostAliases = 'production' | 'staging';\ntype ProviderBuilder = { main: string; workspaces: string };\nexport type HostProvider = HostAliases | ProviderBuilder;\n\nexport function getHostUrl(provider: HostProvider, type: keyof ProviderBuilder): string {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n\n  throw new Error('Invalid API provider');\n}\n\nconst providers: Record<HostAliases, ProviderBuilder> = {\n  production: {\n    main: 'https://api.xata.io',\n    workspaces: 'https://{workspaceId}.{region}.xata.sh'\n  },\n  staging: {\n    main: 'https://staging.xatabase.co',\n    workspaces: 'https://{workspaceId}.staging.{region}.xatabase.co'\n  }\n};\n\nexport function isHostProviderAlias(alias: HostProvider | string): alias is HostAliases {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\n\nexport function isHostProviderBuilder(builder: HostProvider): builder is ProviderBuilder {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\n\nexport function parseProviderString(provider = 'production'): HostProvider | null {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n\n  const [main, workspaces] = provider.split(',');\n  if (!main || !workspaces) return null;\n  return { main, workspaces };\n}\n\nexport function parseWorkspacesUrlParts(url: string): { workspace: string; region: string } | null {\n  if (!isString(url)) return null;\n\n  const regex = /(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))?\\.xata\\.sh.*/;\n  const regexStaging = /(?:https:\\/\\/)?([^.]+)\\.staging(?:\\.([^.]+))?\\.xatabase\\.co.*/;\n\n  const match = url.match(regex) || url.match(regexStaging);\n  if (!match) return null;\n\n  // Region is optional for now, so we default to 'EU'\n  return { workspace: match[1], region: match[2] ?? 'eu-west-1' };\n}\n","import { defaultTrace, TraceFunction } from '../schema/tracing';\nimport { getAPIKey } from '../util/apiKey';\nimport { getFetchImplementation } from '../util/fetch';\nimport type * as Components from './components';\nimport type * as Types from './components';\nimport { operationsByTag } from './components';\nimport type { FetcherExtraProps, FetchImpl } from './fetcher';\nimport { getHostUrl, HostProvider } from './providers';\nimport type * as Responses from './responses';\nimport type * as Schemas from './schemas';\n\nexport type ApiExtraProps = Omit<FetcherExtraProps, 'endpoint'>;\n\nexport interface XataApiClientOptions {\n  fetch?: FetchImpl;\n  apiKey?: string;\n  host?: HostProvider;\n  trace?: TraceFunction;\n}\n\nexport class XataApiClient {\n  #extraProps: ApiExtraProps;\n  #namespaces: Partial<{\n    user: UserApi;\n    authentication: AuthenticationApi;\n    workspaces: WorkspaceApi;\n    invites: InvitesApi;\n    database: DatabaseApi;\n    branches: BranchApi;\n    migrations: MigrationsApi;\n    migrationRequests: MigrationRequestsApi;\n    tables: TableApi;\n    records: RecordsApi;\n    searchAndFilter: SearchAndFilterApi;\n  }> = {};\n\n  constructor(options: XataApiClientOptions = {}) {\n    const provider = options.host ?? 'production';\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n\n    if (!apiKey) {\n      throw new Error('Could not resolve a valid apiKey');\n    }\n\n    this.#extraProps = {\n      apiUrl: getHostUrl(provider, 'main'),\n      workspacesApiUrl: getHostUrl(provider, 'workspaces'),\n      fetchImpl: getFetchImplementation(options.fetch),\n      apiKey,\n      trace\n    };\n  }\n\n  public get user() {\n    if (!this.#namespaces.user) this.#namespaces.user = new UserApi(this.#extraProps);\n    return this.#namespaces.user;\n  }\n\n  public get authentication() {\n    if (!this.#namespaces.authentication) this.#namespaces.authentication = new AuthenticationApi(this.#extraProps);\n    return this.#namespaces.authentication;\n  }\n\n  public get workspaces() {\n    if (!this.#namespaces.workspaces) this.#namespaces.workspaces = new WorkspaceApi(this.#extraProps);\n    return this.#namespaces.workspaces;\n  }\n\n  public get invites() {\n    if (!this.#namespaces.invites) this.#namespaces.invites = new InvitesApi(this.#extraProps);\n    return this.#namespaces.invites;\n  }\n\n  public get database() {\n    if (!this.#namespaces.database) this.#namespaces.database = new DatabaseApi(this.#extraProps);\n    return this.#namespaces.database;\n  }\n\n  public get branches() {\n    if (!this.#namespaces.branches) this.#namespaces.branches = new BranchApi(this.#extraProps);\n    return this.#namespaces.branches;\n  }\n\n  public get migrations() {\n    if (!this.#namespaces.migrations) this.#namespaces.migrations = new MigrationsApi(this.#extraProps);\n    return this.#namespaces.migrations;\n  }\n\n  public get migrationRequests() {\n    if (!this.#namespaces.migrationRequests)\n      this.#namespaces.migrationRequests = new MigrationRequestsApi(this.#extraProps);\n    return this.#namespaces.migrationRequests;\n  }\n\n  public get tables() {\n    if (!this.#namespaces.tables) this.#namespaces.tables = new TableApi(this.#extraProps);\n    return this.#namespaces.tables;\n  }\n\n  public get records() {\n    if (!this.#namespaces.records) this.#namespaces.records = new RecordsApi(this.#extraProps);\n    return this.#namespaces.records;\n  }\n\n  public get searchAndFilter() {\n    if (!this.#namespaces.searchAndFilter) this.#namespaces.searchAndFilter = new SearchAndFilterApi(this.#extraProps);\n    return this.#namespaces.searchAndFilter;\n  }\n}\n\nclass UserApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public getUser(): Promise<Schemas.UserWithID> {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n\n  public updateUser({ user }: { user: Schemas.User }): Promise<Schemas.UserWithID> {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n\n  public deleteUser(): Promise<void> {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\n\nclass AuthenticationApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public getUserAPIKeys(): Promise<Types.GetUserAPIKeysResponse> {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n\n  public createUserAPIKey({ name }: { name: Schemas.APIKeyName }): Promise<Types.CreateUserAPIKeyResponse> {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n\n  public deleteUserAPIKey({ name }: { name: Schemas.APIKeyName }): Promise<void> {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\n\nclass WorkspaceApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public getWorkspacesList(): Promise<Types.GetWorkspacesListResponse> {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n\n  public createWorkspace({ data }: { data: Schemas.WorkspaceMeta }): Promise<Schemas.Workspace> {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n\n  public getWorkspace({ workspace }: { workspace: Schemas.WorkspaceID }): Promise<Schemas.Workspace> {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n\n  public updateWorkspace({\n    workspace,\n    update\n  }: {\n    workspace: Schemas.WorkspaceID;\n    update: Schemas.WorkspaceMeta;\n  }): Promise<Schemas.Workspace> {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n\n  public deleteWorkspace({ workspace }: { workspace: Schemas.WorkspaceID }): Promise<void> {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n\n  public getWorkspaceMembersList({ workspace }: { workspace: Schemas.WorkspaceID }): Promise<Schemas.WorkspaceMembers> {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n\n  public updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }: {\n    workspace: Schemas.WorkspaceID;\n    user: Schemas.UserID;\n    role: Schemas.Role;\n  }): Promise<void> {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n\n  public removeWorkspaceMember({\n    workspace,\n    user\n  }: {\n    workspace: Schemas.WorkspaceID;\n    user: Schemas.UserID;\n  }): Promise<void> {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\n\nclass InvitesApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }: {\n    workspace: Schemas.WorkspaceID;\n    email: string;\n    role: Schemas.Role;\n  }): Promise<Schemas.WorkspaceInvite> {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n\n  public updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }: {\n    workspace: Schemas.WorkspaceID;\n    invite: Schemas.InviteID;\n    role: Schemas.Role;\n  }): Promise<Schemas.WorkspaceInvite> {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n\n  public cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }: {\n    workspace: Schemas.WorkspaceID;\n    invite: Schemas.InviteID;\n  }): Promise<void> {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n\n  public acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }: {\n    workspace: Schemas.WorkspaceID;\n    key: Schemas.InviteKey;\n  }): Promise<void> {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n\n  public resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }: {\n    workspace: Schemas.WorkspaceID;\n    invite: Schemas.InviteID;\n  }): Promise<void> {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\n\nclass BranchApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public getBranchList({\n    workspace,\n    region,\n    database\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n  }): Promise<Schemas.ListBranchesResponse> {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n\n  public getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n  }): Promise<Schemas.DBBranch> {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n\n  public createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    from?: string;\n    metadata?: Schemas.BranchMetadata;\n  }): Promise<Types.CreateBranchResponse> {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n\n  public deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n  }): Promise<Components.DeleteBranchResponse> {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n\n  public updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    metadata: Schemas.BranchMetadata;\n  }): Promise<void> {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n\n  public getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n  }): Promise<Schemas.BranchMetadata> {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n\n  public getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n  }): Promise<Types.GetBranchStatsResponse> {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n\n  public getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n  }): Promise<Schemas.ListGitBranchesResponse> {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n\n  public addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    gitBranch: string;\n    xataBranch: Schemas.BranchName;\n  }): Promise<Types.AddGitBranchesEntryResponse> {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n\n  public removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    gitBranch: string;\n  }): Promise<void> {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n\n  public resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    gitBranch?: string;\n    fallbackBranch?: string;\n  }): Promise<Types.ResolveBranchResponse> {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\n\nclass TableApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n  }): Promise<Types.CreateTableResponse> {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n\n  public deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n  }): Promise<Components.DeleteTableResponse> {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n\n  public updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    update: Types.UpdateTableRequestBody;\n  }): Promise<Responses.SchemaUpdateResponse> {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n\n  public getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n  }): Promise<Types.GetTableSchemaResponse> {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n\n  public setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    schema: Types.SetTableSchemaRequestBody;\n  }): Promise<Responses.SchemaUpdateResponse> {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n\n  public getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n  }): Promise<Types.GetTableColumnsResponse> {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n\n  public addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    column: Schemas.Column;\n  }): Promise<Responses.SchemaUpdateResponse> {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n\n  public getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    column: Schemas.ColumnName;\n  }): Promise<Schemas.Column> {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n\n  public updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    column: Schemas.ColumnName;\n    update: Types.UpdateColumnRequestBody;\n  }): Promise<Responses.SchemaUpdateResponse> {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n\n  public deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    column: Schemas.ColumnName;\n  }): Promise<Responses.SchemaUpdateResponse> {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\n\nclass RecordsApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    record: Record<string, any>;\n    columns?: Schemas.ColumnsProjection;\n  }): Promise<Responses.RecordUpdateResponse> {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n\n  public getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    id: Schemas.RecordID;\n    columns?: Schemas.ColumnsProjection;\n  }): Promise<Schemas.XataRecord> {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n\n  public insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    id: Schemas.RecordID;\n    record: Record<string, any>;\n    columns?: Schemas.ColumnsProjection;\n    createOnly?: boolean;\n    ifVersion?: number;\n  }): Promise<Responses.RecordUpdateResponse> {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n\n  public updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    id: Schemas.RecordID;\n    record: Record<string, any>;\n    columns?: Schemas.ColumnsProjection;\n    ifVersion?: number;\n  }): Promise<Responses.RecordUpdateResponse> {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n\n  public upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    id: Schemas.RecordID;\n    record: Record<string, any>;\n    columns?: Schemas.ColumnsProjection;\n    ifVersion?: number;\n  }): Promise<Responses.RecordUpdateResponse> {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n\n  public deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    id: Schemas.RecordID;\n    columns?: Schemas.ColumnsProjection;\n  }): Promise<Responses.RecordUpdateResponse> {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n\n  public bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    records: Record<string, any>[];\n    columns?: Schemas.ColumnsProjection;\n  }): Promise<Responses.BulkInsertResponse> {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n}\n\nclass SearchAndFilterApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    filter?: Schemas.FilterExpression;\n    sort?: Schemas.SortExpression;\n    page?: Schemas.PageConfig;\n    columns?: Schemas.ColumnsProjection;\n  }): Promise<Responses.QueryResponse> {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n\n  public searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    query: string;\n    fuzziness?: Schemas.FuzzinessExpression;\n    target?: Schemas.TargetExpression;\n    prefix?: Schemas.PrefixExpression;\n    filter?: Schemas.FilterExpression;\n    highlight?: Schemas.HighlightExpression;\n    boosters?: Schemas.BoosterExpression[];\n  }): Promise<Responses.SearchResponse> {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n\n  public searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    tables?: (\n      | string\n      | {\n          table: string;\n          filter?: Schemas.FilterExpression;\n          target?: Schemas.TargetExpression;\n          boosters?: Schemas.BoosterExpression[];\n        }\n    )[];\n    query: string;\n    fuzziness?: Schemas.FuzzinessExpression;\n    prefix?: Schemas.PrefixExpression;\n    highlight?: Schemas.HighlightExpression;\n  }): Promise<Responses.SearchResponse> {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n\n  public summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    filter?: Schemas.FilterExpression;\n    columns?: Schemas.ColumnsProjection;\n    summaries?: Schemas.SummaryExpressionList;\n    sort?: Schemas.SortExpression;\n    summariesFilter?: Schemas.FilterExpression;\n    page?: { size?: number };\n  }): Promise<Responses.SummarizeResponse> {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page },\n      ...this.extraProps\n    });\n  }\n\n  public aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    table: Schemas.TableName;\n    filter?: Schemas.FilterExpression;\n    aggs?: Schemas.AggExpressionMap;\n  }): Promise<Responses.AggResponse> {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\n\nclass MigrationRequestsApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    filter?: Schemas.FilterExpression;\n    sort?: Schemas.SortExpression;\n    page?: Schemas.PageConfig;\n    columns?: Schemas.ColumnsProjection;\n  }): Promise<Components.QueryMigrationRequestsResponse> {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n\n  public createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    migration: Components.CreateMigrationRequestRequestBody;\n  }): Promise<Components.CreateMigrationRequestResponse> {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n\n  public getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    migrationRequest: Schemas.MigrationRequestNumber;\n  }): Promise<Schemas.MigrationRequest> {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n\n  public updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    migrationRequest: Schemas.MigrationRequestNumber;\n    update: Components.UpdateMigrationRequestRequestBody;\n  }): Promise<void> {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n\n  public listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    migrationRequest: Schemas.MigrationRequestNumber;\n    page?: { after?: string; before?: string; size?: number };\n  }): Promise<Components.ListMigrationRequestsCommitsResponse> {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n\n  public compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    migrationRequest: Schemas.MigrationRequestNumber;\n  }): Promise<Responses.SchemaCompareResponse> {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n\n  public getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    migrationRequest: Schemas.MigrationRequestNumber;\n  }): Promise<Components.GetMigrationRequestIsMergedResponse> {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n\n  public mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    migrationRequest: Schemas.MigrationRequestNumber;\n  }): Promise<Schemas.Commit> {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\n\nclass MigrationsApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    limit?: number;\n    startFrom?: string;\n  }): Promise<Types.GetBranchMigrationHistoryResponse> {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n\n  public getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    schema: Schemas.Schema;\n  }): Promise<Responses.BranchMigrationPlan> {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n\n  public executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    plan: Types.ExecuteBranchMigrationPlanRequestBody;\n  }): Promise<Responses.SchemaUpdateResponse> {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n\n  public getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    page?: { after?: string; before?: string; size?: number };\n  }): Promise<Types.GetBranchSchemaHistoryResponse> {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n\n  public compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    schema: Schemas.Schema;\n  }): Promise<Responses.SchemaCompareResponse> {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema },\n      ...this.extraProps\n    });\n  }\n\n  public compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    schema\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    compare: Schemas.BranchName;\n    schema: Schemas.Schema;\n  }): Promise<Responses.SchemaCompareResponse> {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { schema },\n      ...this.extraProps\n    });\n  }\n\n  public updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    migration: Schemas.Migration;\n  }): Promise<Responses.SchemaUpdateResponse> {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n\n  public previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    data: { edits?: Schemas.SchemaEditScript };\n  }): Promise<Components.PreviewBranchSchemaEditResponse> {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n\n  public applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }: {\n    workspace: Schemas.WorkspaceID;\n    region: string;\n    database: Schemas.DBName;\n    branch: Schemas.BranchName;\n    edits: Schemas.SchemaEditScript;\n  }): Promise<Responses.SchemaUpdateResponse> {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(private extraProps: ApiExtraProps) {}\n\n  public getDatabaseList({ workspace }: { workspace: Schemas.WorkspaceID }): Promise<Schemas.ListDatabasesResponse> {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n\n  public createDatabase({\n    workspace,\n    database,\n    data\n  }: {\n    workspace: Schemas.WorkspaceID;\n    database: Schemas.DBName;\n    data: Components.CreateDatabaseRequestBody;\n  }): Promise<Components.CreateDatabaseResponse> {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      ...this.extraProps\n    });\n  }\n\n  public deleteDatabase({\n    workspace,\n    database\n  }: {\n    workspace: Schemas.WorkspaceID;\n    database: Schemas.DBName;\n  }): Promise<Components.DeleteDatabaseResponse> {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n\n  public getDatabaseMetadata({\n    workspace,\n    database\n  }: {\n    workspace: Schemas.WorkspaceID;\n    database: Schemas.DBName;\n  }): Promise<Schemas.DatabaseMetadata> {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n\n  public updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }: {\n    workspace: Schemas.WorkspaceID;\n    database: Schemas.DBName;\n    metadata: Schemas.DatabaseMetadata;\n  }): Promise<Schemas.DatabaseMetadata> {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n\n  public listRegions({ workspace }: { workspace: Schemas.WorkspaceID }): Promise<Schemas.ListRegionsResponse> {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n","import { ApiExtraProps } from './api';\nimport { CacheImpl } from './schema/cache';\nimport { TraceFunction } from './schema/tracing';\n\nexport abstract class XataPlugin {\n  abstract build(options: XataPluginOptions): unknown | Promise<unknown>;\n}\n\nexport type XataPluginOptions = {\n  getFetchProps: () => Promise<ApiExtraProps>;\n  cache: CacheImpl;\n  trace?: TraceFunction;\n};\n","export function generateUUID() {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n    const r = (Math.random() * 16) | 0,\n      v = c == 'x' ? r : (r & 0x3) | 0x8;\n    return v.toString(16);\n  });\n}\n","import { FilterExpression } from '../api/schemas';\nimport { SingleOrArray } from '../util/types';\nimport { ColumnsByValue, ValueAtColumn } from './selection';\n\n/**\n * PropertyMatchFilter\n * Example:\n{\n  \"filter\": {\n    \"name\": \"value\",\n    \"name\": {\n       \"$is\":  \"value\",\n       \"$any\": [ \"value1\", \"value2\" ],\n    },\n    \"settings.plan\": {\"$any\": [\"free\", \"paid\"]},\n    \"settings.plan\": \"free\",\n    \"settings\": {\n      \"plan\": \"free\"\n    },\n  }\n}\n*/\ntype PropertyAccessFilter<Record> = {\n  [key in ColumnsByValue<Record, any>]?:\n    | NestedApiFilter<ValueAtColumn<Record, key>>\n    | PropertyFilter<ValueAtColumn<Record, key>>;\n};\n\nexport type PropertyFilter<T> = T | { $is: T } | { $isNot: T } | { $any: T[] } | { $none: T[] } | ValueTypeFilters<T>;\n\ntype IncludesFilter<T> =\n  | PropertyFilter<T>\n  | {\n      [key in '$all' | '$none' | '$any']?: IncludesFilter<T> | Array<IncludesFilter<T> | { $not: IncludesFilter<T> }>;\n    };\n\nexport type StringTypeFilter = { [key in '$contains' | '$pattern' | '$startsWith' | '$endsWith']?: string };\nexport type ComparableType = number | Date;\nexport type ComparableTypeFilter<T extends ComparableType> = { [key in '$gt' | '$lt' | '$ge' | '$le']?: T };\nexport type ArrayFilter<T> =\n  | {\n      [key in '$includes']?: SingleOrArray<PropertyFilter<T> | ValueTypeFilters<T>> | IncludesFilter<T>;\n    }\n  | {\n      [key in '$includesAll' | '$includesNone' | '$includesAny']?:\n        | T\n        | Array<PropertyFilter<T> | { $not: PropertyFilter<T> }>;\n    };\n\ntype ValueTypeFilters<T> = T | T extends string\n  ? StringTypeFilter\n  : T extends number\n  ? ComparableTypeFilter<number>\n  : T extends Date\n  ? ComparableTypeFilter<Date>\n  : T extends Array<infer T>\n  ? ArrayFilter<T>\n  : never;\n\n/**\n * AggregatorFilter\n * Example:\n{\n  \"filter\": {\n      \"$any\": {\n        \"settings.dark\": true,\n        \"settings.plan\": \"free\"\n      }\n  },\n}\n{\n  \"filter\": {\n    \"$any\": [\n      {\n        \"name\": \"r1\",\n      },\n      {\n        \"name\": \"r2\",\n      },\n    ],\n}\n*/\ntype AggregatorFilter<T> = {\n  [key in '$all' | '$any' | '$not' | '$none']?: SingleOrArray<Filter<T>>;\n};\n\n/**\n * Existance filter\n * Example: { filter: { $exists: \"settings\" } }\n */\nexport type ExistanceFilter<Record> = {\n  [key in '$exists' | '$notExists']?: ColumnsByValue<Record, any>;\n};\n\ntype BaseApiFilter<Record> = PropertyAccessFilter<Record> | AggregatorFilter<Record> | ExistanceFilter<Record>;\n\n/**\n * Nested filter\n * Injects the Api filters on nested properties\n * Example: { filter: { settings: { plan: { $any: ['free', 'trial'] } } } }\n */\ntype NestedApiFilter<T> = {\n  [key in keyof T]?: T[key] extends Record<string, any> ? SingleOrArray<Filter<T[key]>> : PropertyFilter<T[key]>;\n};\n\nexport type Filter<T> = T extends Record<string, any>\n  ? T extends (infer ArrayType)[] // Arrays have a special filter\n    ? ArrayType | ArrayType[] | ArrayFilter<ArrayType> | ArrayFilter<ArrayType[]>\n    : T extends Date // Date extends object but we treat it as a primitive\n    ? PropertyFilter<T>\n    : BaseApiFilter<T> | NestedApiFilter<T>\n  : PropertyFilter<T>;\n\nexport function cleanFilter(filter?: FilterExpression) {\n  if (!filter) return undefined;\n\n  const values = Object.values(filter)\n    .filter(Boolean)\n    .filter((value) => (Array.isArray(value) ? value.length > 0 : true));\n\n  return values.length > 0 ? filter : undefined;\n}\n","import { isDefined, isObject } from '../util/lang';\nimport { Query } from './query';\nimport { XataRecord } from './record';\n\nexport type PaginationQueryMeta = { page: { cursor: string; more: boolean } };\n\nexport interface Paginable<Record extends XataRecord, Result extends XataRecord = Record> {\n  meta: PaginationQueryMeta;\n  records: RecordArray<Result>;\n\n  nextPage(size?: number, offset?: number): Promise<Page<Record, Result>>;\n  previousPage(size?: number, offset?: number): Promise<Page<Record, Result>>;\n  firstPage(size?: number, offset?: number): Promise<Page<Record, Result>>;\n  lastPage(size?: number, offset?: number): Promise<Page<Record, Result>>;\n\n  hasNextPage(): boolean;\n}\n\n/**\n * A Page contains a set of results from a query plus metadata about the retrieved\n * set of values such as the cursor, required to retrieve additional records.\n */\nexport class Page<Record extends XataRecord, Result extends XataRecord = Record> implements Paginable<Record, Result> {\n  #query: Query<Record, Result>;\n  /**\n   * Page metadata, required to retrieve additional records.\n   */\n  readonly meta: PaginationQueryMeta;\n  /**\n   * The set of results for this page.\n   */\n  readonly records: RecordArray<Result>;\n\n  constructor(query: Query<Record, Result>, meta: PaginationQueryMeta, records: Result[] = []) {\n    this.#query = query;\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size?: number, offset?: number): Promise<Page<Record, Result>> {\n    return this.#query.getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size?: number, offset?: number): Promise<Page<Record, Result>> {\n    return this.#query.getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n\n  /**\n   * Retrieves the first page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The first page or results.\n   */\n  async firstPage(size?: number, offset?: number): Promise<Page<Record, Result>> {\n    return this.#query.getPaginated({ pagination: { size, offset, first: this.meta.page.cursor } });\n  }\n\n  /**\n   * Retrieves the last page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The last page or results.\n   */\n  async lastPage(size?: number, offset?: number): Promise<Page<Record, Result>> {\n    return this.#query.getPaginated({ pagination: { size, offset, last: this.meta.page.cursor } });\n  }\n\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage(): boolean {\n    return this.meta.page.more;\n  }\n}\n\nexport type CursorNavigationOptions = { first?: string } | { last?: string } | { after?: string; before?: string };\nexport type OffsetNavigationOptions = { size?: number; offset?: number };\n\nexport const PAGINATION_MAX_SIZE = 200;\nexport const PAGINATION_DEFAULT_SIZE = 20;\nexport const PAGINATION_MAX_OFFSET = 800;\nexport const PAGINATION_DEFAULT_OFFSET = 0;\n\nexport function isCursorPaginationOptions(\n  options: Record<string, unknown> | undefined | null\n): options is CursorNavigationOptions {\n  return (\n    isDefined(options) &&\n    (isDefined(options.first) || isDefined(options.last) || isDefined(options.after) || isDefined(options.before))\n  );\n}\n\nexport class RecordArray<Result extends XataRecord> extends Array<Result> {\n  #page: Paginable<Result, Result>;\n\n  constructor(page: Paginable<any, Result>, overrideRecords?: Result[]);\n  constructor(...args: any[]) {\n    super(...RecordArray.parseConstructorParams(...args));\n\n    // In the case of serialization/deserialization, the page might be lost\n    this.#page = isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: '', more: false } }, records: [] };\n  }\n\n  static parseConstructorParams(...args: any[]) {\n    // new <T>(arrayLength: number): T[]\n    if (args.length === 1 && typeof args[0] === 'number') {\n      return new Array(args[0]);\n    }\n\n    // new RecordArray<T>(page: Page, overrideRecords: Array | undefined): T[>]\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n\n    // <T>(...items: T[]): T[]\n    return new Array(...args);\n  }\n\n  toArray(): Result[] {\n    return new Array(...this);\n  }\n\n  map<U>(callbackfn: (value: Result, index: number, array: Result[]) => U, thisArg?: any): U[] {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size?: number, offset?: number): Promise<RecordArray<Result>> {\n    const newPage = await this.#page.nextPage(size, offset);\n    return new RecordArray(newPage);\n  }\n\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size?: number, offset?: number): Promise<RecordArray<Result>> {\n    const newPage = await this.#page.previousPage(size, offset);\n    return new RecordArray(newPage);\n  }\n\n  /**\n   * Retrieve first page of records\n   *\n   * @returns A new array of objects\n   */\n  async firstPage(size?: number, offset?: number): Promise<RecordArray<Result>> {\n    const newPage = await this.#page.firstPage(size, offset);\n    return new RecordArray(newPage);\n  }\n\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new array of objects\n   */\n  async lastPage(size?: number, offset?: number): Promise<RecordArray<Result>> {\n    const newPage = await this.#page.lastPage(size, offset);\n    return new RecordArray(newPage);\n  }\n\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage(): boolean {\n    return this.#page.meta.page.more;\n  }\n}\n","import { Schemas } from '../api';\nimport { FilterExpression } from '../api/schemas';\nimport { compact, isDefined, isObject, isString, isStringArray, toBase64 } from '../util/lang';\nimport { Dictionary, OmitBy, RequiredBy, SingleOrArray } from '../util/types';\nimport { Filter } from './filters';\nimport {\n  CursorNavigationOptions,\n  isCursorPaginationOptions,\n  OffsetNavigationOptions,\n  Page,\n  Paginable,\n  PaginationQueryMeta,\n  PAGINATION_DEFAULT_SIZE,\n  PAGINATION_MAX_SIZE,\n  RecordArray\n} from './pagination';\nimport { XataRecord } from './record';\nimport { RestRepository } from './repository';\nimport { ColumnsByValue, SelectableColumn, SelectedPick, ValueAtColumn } from './selection';\nimport { SortDirection, SortFilter } from './sorting';\nimport { SummarizeExpression, SummarizeParams, SummarizeResult } from './summarize';\n\ntype BaseOptions<T extends XataRecord> = {\n  columns?: SelectableColumn<T>[];\n  cache?: number;\n};\n\ntype CursorQueryOptions = {\n  pagination?: CursorNavigationOptions & OffsetNavigationOptions;\n  filter?: never;\n  // Fix for TS 4.7 not inferring `never` for `sort`\n  sort?: never | unknown;\n};\n\ntype OffsetQueryOptions<T extends XataRecord> = {\n  pagination?: OffsetNavigationOptions;\n  filter?: FilterExpression;\n  sort?: SingleOrArray<SortFilter<T>>;\n};\n\nexport type QueryOptions<T extends XataRecord> = BaseOptions<T> & (CursorQueryOptions | OffsetQueryOptions<T>);\n\n/**\n * Query objects contain the information of all filters, sorting, etc. to be included in the database query.\n *\n * Query objects are immutable. Any method that adds more constraints or options to the query will return\n * a new Query object containing the both the previous and the new constraints and options.\n */\nexport class Query<Record extends XataRecord, Result extends XataRecord = Record> implements Paginable<Record, Result> {\n  #table: { name: string; schema?: Schemas.Table };\n  #repository: RestRepository<Record>;\n  #data: QueryOptions<Record> = { filter: {} };\n\n  // Implements pagination\n  readonly meta: PaginationQueryMeta = { page: { cursor: 'start', more: true } };\n  readonly records: RecordArray<Result> = new RecordArray<Result>(this, []);\n\n  constructor(\n    repository: RestRepository<Record> | null,\n    table: { name: string; schema?: Schemas.Table },\n    data: Partial<QueryOptions<Record>>,\n    rawParent?: Partial<QueryOptions<Record>>\n  ) {\n    this.#table = table;\n\n    if (repository) {\n      this.#repository = repository;\n    } else {\n      this.#repository = this as any;\n    }\n\n    // Clean parent query options if new query is cursor based\n    const parent = cleanParent(data, rawParent);\n\n    this.#data.filter = data.filter ?? parent?.filter ?? {};\n    this.#data.filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    this.#data.filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    this.#data.filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    this.#data.filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    this.#data.sort = data.sort ?? parent?.sort;\n    this.#data.columns = data.columns ?? parent?.columns;\n    this.#data.pagination = data.pagination ?? parent?.pagination;\n    this.#data.cache = data.cache ?? parent?.cache;\n\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n\n    Object.defineProperty(this, 'table', { enumerable: false });\n    Object.defineProperty(this, 'repository', { enumerable: false });\n  }\n\n  getQueryOptions(): QueryOptions<Record> {\n    return this.#data;\n  }\n\n  key(): string {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = this.#data;\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries: Query<Record, any>[]): Query<Record, Result> {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new Query<Record, Result>(this.#repository, this.#table, { filter: { $any } }, this.#data);\n  }\n\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries: Query<Record, any>[]): Query<Record, Result> {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new Query<Record, Result>(this.#repository, this.#table, { filter: { $all } }, this.#data);\n  }\n\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries: Query<Record, any>[]): Query<Record, Result> {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new Query<Record, Result>(this.#repository, this.#table, { filter: { $not } }, this.#data);\n  }\n\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries: Query<Record, any>[]): Query<Record, Result> {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new Query<Record, Result>(this.#repository, this.#table, { filter: { $none } }, this.#data);\n  }\n\n  /**\n   * Builds a new query object adding one or more constraints. Examples:\n   *\n   * ```\n   * query.filter(\"columnName\", columnValue)\n   * query.filter(\"columnName\", operator(columnValue)) // Use gt, gte, lt, lte, startsWith,...\n   * ```\n   *\n   * @param column The name of the column to filter.\n   * @param value The value to filter.\n   * @returns A new Query object.\n   */\n  filter<F extends SelectableColumn<Record>>(\n    column: F,\n    value: Filter<NonNullable<ValueAtColumn<Record, F>>>\n  ): Query<Record, Result>;\n\n  /**\n   * Builds a new query object adding one or more constraints. Examples:\n   *\n   * ```\n   * query.filter({ \"columnName\": columnValue })\n   * query.filter({\n   *   \"columnName\": operator(columnValue) // Use gt, gte, lt, lte, startsWith,...\n   * })\n   * ```\n   *\n   * @param filters A filter object\n   * @returns A new Query object.\n   */\n  filter(filters?: Filter<Record>): Query<Record, Result>;\n\n  filter(a: any, b?: any): Query<Record, Result> {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: this.#cleanFilterConstraint(column, constraint) as any\n      }));\n      const $all = compact([this.#data.filter?.$all].flat().concat(constraints));\n\n      return new Query<Record, Result>(this.#repository, this.#table, { filter: { $all } }, this.#data);\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: this.#cleanFilterConstraint(a, b) }] : undefined;\n      const $all = compact([this.#data.filter?.$all].flat().concat(constraints));\n\n      return new Query<Record, Result>(this.#repository, this.#table, { filter: { $all } }, this.#data);\n    }\n  }\n\n  #cleanFilterConstraint<T>(column: string, value: T) {\n    const columnType = this.#table.schema?.columns.find(({ name }) => name === column)?.type;\n\n    // TODO: Fix when we support more array types than string\n    if (columnType === 'multiple' && (isString(value) || isStringArray(value))) {\n      return { $includes: value };\n    }\n\n    if (columnType === 'link' && isObject(value) && isString(value.id)) {\n      return value.id;\n    }\n\n    return value;\n  }\n\n  /**\n   * Builds a new query with a new sort option.\n   * @param column The column name.\n   * @param direction The direction. Either ascending or descending.\n   * @returns A new Query object.\n   */\n  sort<F extends ColumnsByValue<Record, any>>(column: F, direction: SortDirection = 'asc'): Query<Record, Result> {\n    const originalSort = [this.#data.sort ?? []].flat() as SortFilter<Record, any>[];\n    const sort = [...originalSort, { column, direction }];\n    return new Query<Record, Result>(this.#repository, this.#table, { sort }, this.#data);\n  }\n\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select<K extends SelectableColumn<Record>>(columns: K[]) {\n    return new Query<Record, SelectedPick<Record, typeof columns>>(\n      this.#repository,\n      this.#table,\n      { columns },\n      this.#data\n    );\n  }\n\n  /**\n   * Get paginated results\n   *\n   * @returns A page of results\n   */\n  getPaginated(): Promise<Page<Record, Result>>;\n\n  /**\n   * Get paginated results\n   *\n   * @param options Pagination options\n   * @returns A page of results\n   */\n  getPaginated(options: OmitBy<QueryOptions<Record>, 'columns'>): Promise<Page<Record, Result>>;\n\n  /**\n   * Get paginated results\n   *\n   * @param options Pagination options\n   * @returns A page of results\n   */\n  getPaginated<Options extends RequiredBy<QueryOptions<Record>, 'columns'>>(\n    options: Options\n  ): Promise<Page<Record, SelectedPick<Record, typeof options['columns']>>>;\n\n  getPaginated<Result extends XataRecord>(options: QueryOptions<Record> = {}): Promise<Page<Record, Result>> {\n    const query = new Query<Record, Result>(this.#repository, this.#table, options, this.#data);\n    return this.#repository.query(query);\n  }\n\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator](): AsyncIterableIterator<Result> {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n\n  /**\n   * Build an iterator of results\n   *\n   * @returns Async generator of results array\n   */\n  getIterator(): AsyncGenerator<Result[]>;\n\n  /**\n   * Build an iterator of results\n   *\n   * @param options Pagination options with batchSize\n   * @returns Async generator of results array\n   */\n  getIterator(\n    options: OmitBy<QueryOptions<Record>, 'columns' | 'pagination'> & { batchSize?: number }\n  ): AsyncGenerator<Result[]>;\n\n  /**\n   * Build an iterator of results\n   *\n   * @param options Pagination options with batchSize\n   * @returns Async generator of results array\n   */\n  getIterator<\n    Options extends RequiredBy<OmitBy<QueryOptions<Record>, 'pagination'>, 'columns'> & { batchSize?: number }\n  >(options: Options): AsyncGenerator<SelectedPick<Record, typeof options['columns']>[]>;\n\n  async *getIterator<Result extends XataRecord>(\n    options: QueryOptions<Record> & { batchSize?: number } = {}\n  ): AsyncGenerator<Result[]> {\n    const { batchSize = 1 } = options;\n\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n\n    yield page.records as unknown as Result[];\n\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n\n      yield page.records as unknown as Result[];\n    }\n  }\n\n  /**\n   * Performs the query in the database and returns a set of results.\n   * @returns An array of records from the database.\n   */\n  getMany(): Promise<RecordArray<Result>>;\n\n  /**\n   * Performs the query in the database and returns a set of results.\n   * @param options Additional options to be used when performing the query.\n   * @returns An array of records from the database.\n   */\n  getMany<Options extends RequiredBy<QueryOptions<Record>, 'columns'>>(\n    options: Options\n  ): Promise<RecordArray<SelectedPick<Record, typeof options['columns']>>>;\n\n  /**\n   * Performs the query in the database and returns a set of results.\n   * @param options Additional options to be used when performing the query.\n   * @returns An array of records from the database.\n   */\n  getMany(options: OmitBy<QueryOptions<Record>, 'columns'>): Promise<RecordArray<Result>>;\n\n  async getMany<Result extends XataRecord>(options: QueryOptions<Record> = {}): Promise<RecordArray<Result>> {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n\n    if (page.hasNextPage() && options.pagination?.size === undefined) {\n      console.trace('Calling getMany does not return all results. Paginate to get all results or call getAll.');\n    }\n\n    const array = new RecordArray(page, results.slice(0, size));\n\n    // Method overloading does not provide type inference for the return type.\n    return array as unknown as RecordArray<Result>;\n  }\n\n  /**\n   * Performs the query in the database and returns all the results.\n   * Warning: If there are a large number of results, this method can have performance implications.\n   * @returns An array of records from the database.\n   */\n  getAll(): Promise<Result[]>;\n\n  /**\n   * Performs the query in the database and returns all the results.\n   * Warning: If there are a large number of results, this method can have performance implications.\n   * @param options Additional options to be used when performing the query.\n   * @returns An array of records from the database.\n   */\n  getAll<Options extends RequiredBy<OmitBy<QueryOptions<Record>, 'pagination'>, 'columns'> & { batchSize?: number }>(\n    options: Options\n  ): Promise<SelectedPick<Record, typeof options['columns']>[]>;\n\n  /**\n   * Performs the query in the database and returns all the results.\n   * Warning: If there are a large number of results, this method can have performance implications.\n   * @param options Additional options to be used when performing the query.\n   * @returns An array of records from the database.\n   */\n  getAll(options: OmitBy<QueryOptions<Record>, 'columns' | 'pagination'> & { batchSize?: number }): Promise<Result[]>;\n\n  async getAll<Result extends XataRecord>(\n    options: QueryOptions<Record> & { batchSize?: number } = {}\n  ): Promise<Result[]> {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n\n    // Method overloading does not provide type inference for the return type.\n    return results as unknown as Result[];\n  }\n\n  /**\n   * Performs the query in the database and returns the first result.\n   * @returns The first record that matches the query, or null if no record matched the query.\n   */\n  getFirst(): Promise<Result | null>;\n\n  /**\n   * Performs the query in the database and returns the first result.\n   * @param options Additional options to be used when performing the query.\n   * @returns The first record that matches the query, or null if no record matched the query.\n   */\n  getFirst<Options extends RequiredBy<OmitBy<QueryOptions<Record>, 'pagination'>, 'columns'>>(\n    options: Options\n  ): Promise<SelectedPick<Record, typeof options['columns']> | null>;\n\n  /**\n   * Performs the query in the database and returns the first result.\n   * @param options Additional options to be used when performing the query.\n   * @returns The first record that matches the query, or null if no record matched the query.\n   */\n  getFirst(options: OmitBy<QueryOptions<Record>, 'columns' | 'pagination'>): Promise<Result | null>;\n\n  async getFirst<Result extends XataRecord>(options: QueryOptions<Record> = {}): Promise<Result | null> {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n\n    // Method overloading does not provide type inference for the return type.\n    return (records[0] as unknown as Result) ?? null;\n  }\n\n  /**\n   * Performs the query in the database and returns the first result.\n   * @returns The first record that matches the query, or null if no record matched the query.\n   * @throws if there are no results.\n   */\n  getFirstOrThrow(): Promise<Result>;\n\n  /**\n   * Performs the query in the database and returns the first result.\n   * @param options Additional options to be used when performing the query.\n   * @returns The first record that matches the query, or null if no record matched the query.\n   * @throws if there are no results.\n   */\n  getFirstOrThrow<Options extends RequiredBy<OmitBy<QueryOptions<Record>, 'pagination'>, 'columns'>>(\n    options: Options\n  ): Promise<SelectedPick<Record, typeof options['columns']>>;\n\n  /**\n   * Performs the query in the database and returns the first result.\n   * @param options Additional options to be used when performing the query.\n   * @returns The first record that matches the query, or null if no record matched the query.\n   * @throws if there are no results.\n   */\n  getFirstOrThrow(options: OmitBy<QueryOptions<Record>, 'columns' | 'pagination'>): Promise<Result>;\n\n  async getFirstOrThrow<Result extends XataRecord>(options: QueryOptions<Record> = {}): Promise<Result> {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === undefined) throw new Error('No results found.');\n\n    // Method overloading does not provide type inference for the return type.\n    return records[0] as unknown as Result;\n  }\n\n  async summarize<\n    Expression extends Dictionary<SummarizeExpression<Record>>,\n    Columns extends SelectableColumn<Record>[]\n  >(params: SummarizeParams<Record, Expression, Columns> = {}): Promise<SummarizeResult<Record, Expression, Columns>> {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new Query<Record, Result>(\n      this.#repository,\n      this.#table,\n      options as Partial<QueryOptions<Record>>,\n      this.#data\n    );\n\n    return this.#repository.summarizeTable(query, summaries, summariesFilter as Schemas.FilterExpression) as any;\n  }\n\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl: number): Query<Record, Result> {\n    return new Query<Record, Result>(this.#repository, this.#table, { cache: ttl }, this.#data);\n  }\n\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size?: number, offset?: number): Promise<Page<Record, Result>> {\n    return this.firstPage(size, offset);\n  }\n\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size?: number, offset?: number): Promise<Page<Record, Result>> {\n    return this.firstPage(size, offset);\n  }\n\n  /**\n   * Retrieve first page of records\n   *\n   * @returns A new page object\n   */\n  firstPage(size?: number, offset?: number): Promise<Page<Record, Result>> {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  lastPage(size?: number, offset?: number): Promise<Page<Record, Result>> {\n    return this.getPaginated({ pagination: { size, offset, before: 'end' } });\n  }\n\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage(): boolean {\n    return this.meta.page.more;\n  }\n}\n\n// When using cursor based pagination, it is not allowed to send new sorting/filtering\n// We removed the sorting/filtering from the query options to avoid the error from the API\nfunction cleanParent<Record extends XataRecord>(\n  data: Partial<QueryOptions<Record>>,\n  parent?: Partial<QueryOptions<Record>>\n) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: undefined, filter: undefined };\n  }\n\n  return parent;\n}\n","import { isObject, isString } from '../util/lang';\nimport { SelectableColumn, SelectedPick } from './selection';\n\n/**\n * Represents an identifiable record from the database.\n */\nexport interface Identifiable {\n  /**\n   * Unique id of this record.\n   */\n  id: string;\n}\n\nexport interface BaseData {\n  [key: string]: any;\n}\n\n/**\n * Represents a persisted record from the database.\n */\nexport interface XataRecord<OriginalRecord extends XataRecord<any> = XataRecord<any>> extends Identifiable {\n  /**\n   * Get metadata of this record.\n   */\n  getMetadata(): XataRecordMetadata;\n\n  /**\n   * Retrieves a refreshed copy of the current record from the database.\n   * @param columns The columns to retrieve. If not specified, all first level properties are retrieved.\n   * @returns The persisted record with the selected columns, null if not found.\n   */\n  read<K extends SelectableColumn<OriginalRecord>>(\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<OriginalRecord, typeof columns>> | null>;\n\n  /**\n   * Retrieves a refreshed copy of the current record from the database.\n   * @returns The persisted record with all first level properties, null if not found.\n   */\n  read(): Promise<Readonly<SelectedPick<OriginalRecord, ['*']>> | null>;\n\n  /**\n   * Performs a partial update of the current record. On success a new object is\n   * returned and the current object is not mutated.\n   * @param partialUpdate The columns and their values that have to be updated.\n   * @param columns The columns to retrieve. If not specified, all first level properties are retrieved.\n   * @returns The persisted record with the selected columns, null if not found.\n   */\n  update<K extends SelectableColumn<OriginalRecord>>(\n    partialUpdate: Partial<EditableData<OriginalRecord>>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<OriginalRecord, typeof columns>> | null>;\n\n  /**\n   * Performs a partial update of the current record. On success a new object is\n   * returned and the current object is not mutated.\n   * @param partialUpdate The columns and their values that have to be updated.\n   * @returns The persisted record with all first level properties, null if not found.\n   */\n  update(\n    partialUpdate: Partial<EditableData<OriginalRecord>>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<OriginalRecord, ['*']>> | null>;\n\n  /**\n   * Performs a replace of the current record. On success a new object is\n   * returned and the current object is not mutated.\n   * @param partialUpdate The columns and their values that have to be updated.\n   * @param columns The columns to retrieve. If not specified, all first level properties are retrieved.\n   * @returns The persisted record with the selected columns, null if not found.\n   */\n  replace<K extends SelectableColumn<OriginalRecord>>(\n    object: Partial<EditableData<OriginalRecord>>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<OriginalRecord, typeof columns>> | null>;\n\n  /**\n   * Performs a replace of the current record. On success a new object is\n   * returned and the current object is not mutated.\n   * @param partialUpdate The columns and their values that have to be updated.\n   * @returns The persisted record with all first level properties, null if not found.\n   */\n  replace(\n    object: Partial<EditableData<OriginalRecord>>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<OriginalRecord, ['*']>> | null>;\n\n  /**\n   * Performs a deletion of the current record in the database.\n   * @param columns The columns to retrieve. If not specified, all first level properties are retrieved.\n   * @returns The deleted record, null if not found.\n   */\n  delete<K extends SelectableColumn<OriginalRecord>>(\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<OriginalRecord, typeof columns>> | null>;\n\n  /**\n   * Performs a deletion of the current record in the database.\n   * @returns The deleted record, null if not found.\n\n   */\n  delete(): Promise<Readonly<SelectedPick<OriginalRecord, ['*']>> | null>;\n}\n\nexport type Link<Record extends XataRecord> = XataRecord<Record>;\n\nexport type XataRecordMetadata = {\n  /**\n   * Number that is increased every time the record is updated.\n   */\n  version: number;\n  /*\n   * Encoding/Decoding errors\n   */\n  warnings?: string[];\n};\n\nexport function isIdentifiable(x: any): x is Identifiable & Record<string, unknown> {\n  return isObject(x) && isString((x as Partial<Identifiable>)?.id);\n}\n\nexport function isXataRecord(x: any): x is XataRecord & Record<string, unknown> {\n  const record = x as XataRecord & Record<string, unknown>;\n  const metadata = record?.getMetadata();\n\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === 'number';\n}\n\nexport type EditableData<O extends XataRecord> = Identifiable &\n  Omit<\n    {\n      [K in keyof O]: O[K] extends XataRecord\n        ? { id: string } | string\n        : NonNullable<O[K]> extends XataRecord\n        ? { id: string } | string | null | undefined\n        : O[K];\n    },\n    keyof XataRecord\n  >;\n","import { isObject, isString } from '../util/lang';\nimport { SingleOrArray, Values } from '../util/types';\nimport { XataRecord } from './record';\nimport { ColumnsByValue } from './selection';\n\nexport type SortDirection = 'asc' | 'desc';\nexport type SortFilterExtended<T extends XataRecord, Columns extends string = ColumnsByValue<T, any>> = {\n  column: Columns;\n  direction?: SortDirection;\n};\n\nexport type SortFilter<T extends XataRecord, Columns extends string = ColumnsByValue<T, any>> =\n  | Columns\n  | SortFilterExtended<T, Columns>\n  | SortFilterBase<T, Columns>;\n\ntype SortFilterBase<T extends XataRecord, Columns extends string = ColumnsByValue<T, any>> = Values<{\n  [Key in Columns]: { [K in Key]: SortDirection };\n}>;\n\nexport type ApiSortFilter<T extends XataRecord, Columns extends string = ColumnsByValue<T, any>> = SingleOrArray<\n  Values<{\n    [Key in Columns]: { [K in Key]: SortDirection };\n  }>\n>;\n\nexport function isSortFilterString<T extends XataRecord>(value: any): value is ColumnsByValue<T, any> {\n  return isString(value);\n}\n\nexport function isSortFilterBase<T extends XataRecord>(filter: SortFilter<T, any>): filter is SortFilterBase<T> {\n  return isObject(filter) && Object.values(filter).every((value) => value === 'asc' || value === 'desc');\n}\n\nexport function isSortFilterObject<T extends XataRecord>(filter: SortFilter<T, any>): filter is SortFilterExtended<T> {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== undefined;\n}\n\nexport function buildSortFilter<T extends XataRecord>(\n  filter: SingleOrArray<SortFilter<T, any>>\n): ApiSortFilter<T, any> {\n  if (isSortFilterString(filter)) {\n    return { [filter]: 'asc' } as { [key in ColumnsByValue<T, any>]: SortDirection };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item)) as { [key in ColumnsByValue<T, any>]: SortDirection }[];\n  } else if (isSortFilterBase(filter)) {\n    return filter as { [key in ColumnsByValue<T, any>]: SortDirection };\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? 'asc' } as { [key in ColumnsByValue<T, any>]: SortDirection };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n","import { SchemaPluginResult } from '.';\nimport {\n  aggregateTable,\n  ApiExtraProps,\n  bulkInsertTableRecords,\n  deleteRecord,\n  getBranchDetails,\n  getRecord,\n  insertRecord,\n  insertRecordWithID,\n  queryTable,\n  Schemas,\n  searchTable,\n  summarizeTable,\n  updateRecordWithID,\n  upsertRecordWithID\n} from '../api';\nimport { FuzzinessExpression, HighlightExpression, PrefixExpression, RecordsMetadata } from '../api/schemas';\nimport { XataPluginOptions } from '../plugins';\nimport { SearchXataRecord } from '../search';\nimport { Boosters } from '../search/boosters';\nimport { compact, isNumber, isObject, isString, isStringArray } from '../util/lang';\nimport { Dictionary } from '../util/types';\nimport { generateUUID } from '../util/uuid';\nimport { VERSION } from '../version';\nimport { AggregationExpression, AggregationResult } from './aggregate';\nimport { CacheImpl } from './cache';\nimport { cleanFilter, Filter } from './filters';\nimport { Page } from './pagination';\nimport { Query } from './query';\nimport { EditableData, Identifiable, isIdentifiable, XataRecord } from './record';\nimport { SelectableColumn, SelectedPick } from './selection';\nimport { buildSortFilter } from './sorting';\nimport { SummarizeExpression } from './summarize';\nimport { AttributeDictionary, defaultTrace, TraceAttributes, TraceFunction } from './tracing';\n\n/**\n * Common interface for performing operations on a table.\n */\nexport abstract class Repository<Record extends XataRecord> extends Query<\n  Record,\n  Readonly<SelectedPick<Record, ['*']>>\n> {\n  /*\n   * Creates a single record in the table.\n   * @param object Object containing the column names with their values to be stored in the table.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record.\n   */\n  abstract create<K extends SelectableColumn<Record>>(\n    object: Omit<EditableData<Record>, 'id'> & Partial<Identifiable>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /*\n   * Creates a single record in the table.\n   * @param object Object containing the column names with their values to be stored in the table.\n   * @returns The full persisted record.\n   */\n  abstract create(\n    object: Omit<EditableData<Record>, 'id'> & Partial<Identifiable>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Creates a single record in the table with a unique id.\n   * @param id The unique id.\n   * @param object Object containing the column names with their values to be stored in the table.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record.\n   */\n  abstract create<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Creates a single record in the table with a unique id.\n   * @param id The unique id.\n   * @param object Object containing the column names with their values to be stored in the table.\n   * @returns The full persisted record.\n   */\n  abstract create(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Creates multiple records in the table.\n   * @param objects Array of objects with the column names and the values to be stored in the table.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the persisted records in order.\n   */\n  abstract create<K extends SelectableColumn<Record>>(\n    objects: Array<Omit<EditableData<Record>, 'id'> & Partial<Identifiable>>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>[]>;\n\n  /**\n   * Creates multiple records in the table.\n   * @param objects Array of objects with the column names and the values to be stored in the table.\n   * @returns Array of the persisted records in order.\n   */\n  abstract create(\n    objects: Array<Omit<EditableData<Record>, 'id'> & Partial<Identifiable>>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>[]>;\n\n  /**\n   * Queries a single record from the table given its unique id.\n   * @param id The unique id.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The persisted record for the given id or null if the record could not be found.\n   */\n  abstract read<K extends SelectableColumn<Record>>(\n    id: string,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns> | null>>;\n\n  /**\n   * Queries a single record from the table given its unique id.\n   * @param id The unique id.\n   * @returns The persisted record for the given id or null if the record could not be found.\n   */\n  abstract read(id: string): Promise<Readonly<SelectedPick<Record, ['*']> | null>>;\n\n  /**\n   * Queries multiple records from the table given their unique id.\n   * @param ids The unique ids array.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The persisted records for the given ids in order (if a record could not be found null is returned).\n   */\n  abstract read<K extends SelectableColumn<Record>>(\n    ids: string[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n\n  /**\n   * Queries multiple records from the table given their unique id.\n   * @param ids The unique ids array.\n   * @returns The persisted records for the given ids in order (if a record could not be found null is returned).\n   */\n  abstract read(ids: string[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n\n  /**\n   * Queries a single record from the table by the id in the object.\n   * @param object Object containing the id of the record.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The persisted record for the given id or null if the record could not be found.\n   */\n  abstract read<K extends SelectableColumn<Record>>(\n    object: Identifiable,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns> | null>>;\n\n  /**\n   * Queries a single record from the table by the id in the object.\n   * @param object Object containing the id of the record.\n   * @returns The persisted record for the given id or null if the record could not be found.\n   */\n  abstract read(object: Identifiable): Promise<Readonly<SelectedPick<Record, ['*']> | null>>;\n\n  /**\n   * Queries multiple records from the table by the ids in the objects.\n   * @param objects Array of objects containing the ids of the records.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The persisted records for the given ids in order (if a record could not be found null is returned).\n   */\n  abstract read<K extends SelectableColumn<Record>>(\n    objects: Identifiable[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n\n  /**\n   * Queries multiple records from the table by the ids in the objects.\n   * @param objects Array of objects containing the ids of the records.\n   * @returns The persisted records for the given ids in order (if a record could not be found null is returned).\n   */\n  abstract read(objects: Identifiable[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n\n  /**\n   * Queries a single record from the table given its unique id.\n   * @param id The unique id.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The persisted record for the given id.\n   * @throws If the record could not be found.\n   */\n  abstract readOrThrow<K extends SelectableColumn<Record>>(\n    id: string,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Queries a single record from the table given its unique id.\n   * @param id The unique id.\n   * @returns The persisted record for the given id.\n   * @throws If the record could not be found.\n   */\n  abstract readOrThrow(id: string): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Queries multiple records from the table given their unique id.\n   * @param ids The unique ids array.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The persisted records for the given ids in order.\n   * @throws If one or more records could not be found.\n   */\n  abstract readOrThrow<K extends SelectableColumn<Record>>(\n    ids: string[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>>>>;\n\n  /**\n   * Queries multiple records from the table given their unique id.\n   * @param ids The unique ids array.\n   * @returns The persisted records for the given ids in order.\n   * @throws If one or more records could not be found.\n   */\n  abstract readOrThrow(ids: string[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>>>>;\n\n  /**\n   * Queries a single record from the table by the id in the object.\n   * @param object Object containing the id of the record.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The persisted record for the given id.\n   * @throws If the record could not be found.\n   */\n  abstract readOrThrow<K extends SelectableColumn<Record>>(\n    object: Identifiable,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Queries a single record from the table by the id in the object.\n   * @param object Object containing the id of the record.\n   * @returns The persisted record for the given id.\n   * @throws If the record could not be found.\n   */\n  abstract readOrThrow(object: Identifiable): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Queries multiple records from the table by the ids in the objects.\n   * @param objects Array of objects containing the ids of the records.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The persisted records for the given ids in order.\n   * @throws If one or more records could not be found.\n   */\n  abstract readOrThrow<K extends SelectableColumn<Record>>(\n    objects: Identifiable[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>>>>;\n\n  /**\n   * Queries multiple records from the table by the ids in the objects.\n   * @param objects Array of objects containing the ids of the records.\n   * @returns The persisted records for the given ids in order.\n   * @throws If one or more records could not be found.\n   */\n  abstract readOrThrow(objects: Identifiable[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>>>>;\n\n  /**\n   * Partially update a single record.\n   * @param object An object with its id and the columns to be updated.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record, null if the record could not be found.\n   */\n  abstract update<K extends SelectableColumn<Record>>(\n    object: Partial<EditableData<Record>> & Identifiable,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>> | null>;\n\n  /**\n   * Partially update a single record.\n   * @param object An object with its id and the columns to be updated.\n   * @returns The full persisted record, null if the record could not be found.\n   */\n  abstract update(\n    object: Partial<EditableData<Record>> & Identifiable,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>> | null>;\n\n  /**\n   * Partially update a single record given its unique id.\n   * @param id The unique id.\n   * @param object The column names and their values that have to be updated.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record, null if the record could not be found.\n   */\n  abstract update<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Partial<EditableData<Record>>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>> | null>;\n\n  /**\n   * Partially update a single record given its unique id.\n   * @param id The unique id.\n   * @param object The column names and their values that have to be updated.\n   * @returns The full persisted record, null if the record could not be found.\n   */\n  abstract update(\n    id: string,\n    object: Partial<EditableData<Record>>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>> | null>;\n\n  /**\n   * Partially updates multiple records.\n   * @param objects An array of objects with their ids and columns to be updated.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the persisted records in order (if a record could not be found null is returned).\n   */\n  abstract update<K extends SelectableColumn<Record>>(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>,\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n\n  /**\n   * Partially updates multiple records.\n   * @param objects An array of objects with their ids and columns to be updated.\n   * @returns Array of the persisted records in order (if a record could not be found null is returned).\n   */\n  abstract update(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>\n  ): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n\n  /**\n   * Partially update a single record.\n   * @param object An object with its id and the columns to be updated.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record.\n   * @throws If the record could not be found.\n   */\n  abstract updateOrThrow<K extends SelectableColumn<Record>>(\n    object: Partial<EditableData<Record>> & Identifiable,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Partially update a single record.\n   * @param object An object with its id and the columns to be updated.\n   * @returns The full persisted record.\n   * @throws If the record could not be found.\n   */\n  abstract updateOrThrow(\n    object: Partial<EditableData<Record>> & Identifiable,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Partially update a single record given its unique id.\n   * @param id The unique id.\n   * @param object The column names and their values that have to be updated.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record.\n   * @throws If the record could not be found.\n   */\n  abstract updateOrThrow<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Partial<EditableData<Record>>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Partially update a single record given its unique id.\n   * @param id The unique id.\n   * @param object The column names and their values that have to be updated.\n   * @returns The full persisted record.\n   * @throws If the record could not be found.\n   */\n  abstract updateOrThrow(\n    id: string,\n    object: Partial<EditableData<Record>>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Partially updates multiple records.\n   * @param objects An array of objects with their ids and columns to be updated.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the persisted records in order.\n   * @throws If one or more records could not be found.\n   */\n  abstract updateOrThrow<K extends SelectableColumn<Record>>(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>[]>;\n\n  /**\n   * Partially updates multiple records.\n   * @param objects An array of objects with their ids and columns to be updated.\n   * @returns Array of the persisted records in order.\n   * @throws If one or more records could not be found.\n   */\n  abstract updateOrThrow(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>[]>;\n\n  /**\n   * Creates or updates a single record. If a record exists with the given id,\n   * it will be partially updated, otherwise a new record will be created.\n   * @param object Object containing the column names with their values to be persisted in the table.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record.\n   */\n  abstract createOrUpdate<K extends SelectableColumn<Record>>(\n    object: EditableData<Record> & Identifiable,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Creates or updates a single record. If a record exists with the given id,\n   * it will be partially updated, otherwise a new record will be created.\n   * @param object Object containing the column names with their values to be persisted in the table.\n   * @returns The full persisted record.\n   */\n  abstract createOrUpdate(\n    object: EditableData<Record> & Identifiable,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Creates or updates a single record. If a record exists with the given id,\n   * it will be partially updated, otherwise a new record will be created.\n   * @param id A unique id.\n   * @param object The column names and the values to be persisted.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record.\n   */\n  abstract createOrUpdate<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Creates or updates a single record. If a record exists with the given id,\n   * it will be partially updated, otherwise a new record will be created.\n   * @param id A unique id.\n   * @param object The column names and the values to be persisted.\n   * @returns The full persisted record.\n   */\n  abstract createOrUpdate(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Creates or updates a single record. If a record exists with the given id,\n   * it will be partially updated, otherwise a new record will be created.\n   * @param objects Array of objects with the column names and the values to be stored in the table.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the persisted records.\n   */\n  abstract createOrUpdate<K extends SelectableColumn<Record>>(\n    objects: Array<EditableData<Record> & Identifiable>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>[]>;\n\n  /**\n   * Creates or updates a single record. If a record exists with the given id,\n   * it will be partially updated, otherwise a new record will be created.\n   * @param objects Array of objects with the column names and the values to be stored in the table.\n   * @returns Array of the persisted records.\n   */\n  abstract createOrUpdate(\n    objects: Array<EditableData<Record> & Identifiable>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>[]>;\n\n  /**\n   * Creates or replaces a single record. If a record exists with the given id,\n   * it will be replaced, otherwise a new record will be created.\n   * @param object Object containing the column names with their values to be persisted in the table.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record.\n   */\n  abstract createOrReplace<K extends SelectableColumn<Record>>(\n    object: EditableData<Record> & Identifiable,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Creates or replaces a single record. If a record exists with the given id,\n   * it will be replaced, otherwise a new record will be created.\n   * @param object Object containing the column names with their values to be persisted in the table.\n   * @returns The full persisted record.\n   */\n  abstract createOrReplace(\n    object: EditableData<Record> & Identifiable,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Creates or replaces a single record. If a record exists with the given id,\n   * it will be replaced, otherwise a new record will be created.\n   * @param id A unique id.\n   * @param object The column names and the values to be persisted.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The full persisted record.\n   */\n  abstract createOrReplace<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Creates or replaces a single record. If a record exists with the given id,\n   * it will be replaced, otherwise a new record will be created.\n   * @param id A unique id.\n   * @param object The column names and the values to be persisted.\n   * @returns The full persisted record.\n   */\n  abstract createOrReplace(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Creates or replaces a single record. If a record exists with the given id,\n   * it will be replaced, otherwise a new record will be created.\n   * @param objects Array of objects with the column names and the values to be stored in the table.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the persisted records.\n   */\n  abstract createOrReplace<K extends SelectableColumn<Record>>(\n    objects: Array<EditableData<Record> & Identifiable>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>[]>;\n\n  /**\n   * Creates or replaces a single record. If a record exists with the given id,\n   * it will be replaced, otherwise a new record will be created.\n   * @param objects Array of objects with the column names and the values to be stored in the table.\n   * @returns Array of the persisted records.\n   */\n  abstract createOrReplace(\n    objects: Array<EditableData<Record> & Identifiable>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>[]>;\n\n  /**\n   * Deletes a record given its unique id.\n   * @param object An object with a unique id.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The deleted record, null if the record could not be found.\n   */\n  abstract delete<K extends SelectableColumn<Record>>(\n    object: Identifiable & Partial<EditableData<Record>>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>> | null>;\n\n  /**\n   * Deletes a record given its unique id.\n   * @param object An object with a unique id.\n   * @returns The deleted record, null if the record could not be found.\n   */\n  abstract delete(\n    object: Identifiable & Partial<EditableData<Record>>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>> | null>;\n\n  /**\n   * Deletes a record given a unique id.\n   * @param id The unique id.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The deleted record, null if the record could not be found.\n   */\n  abstract delete<K extends SelectableColumn<Record>>(\n    id: string,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>> | null>;\n\n  /**\n   * Deletes a record given a unique id.\n   * @param id The unique id.\n   * @returns The deleted record, null if the record could not be found.\n   */\n  abstract delete(id: string): Promise<Readonly<SelectedPick<Record, ['*']>> | null>;\n\n  /**\n   * Deletes multiple records given an array of objects with ids.\n   * @param objects An array of objects with unique ids.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the deleted records in order (if a record could not be found null is returned).\n   */\n  abstract delete<K extends SelectableColumn<Record>>(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>,\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n\n  /**\n   * Deletes multiple records given an array of objects with ids.\n   * @param objects An array of objects with unique ids.\n   * @returns Array of the deleted records in order (if a record could not be found null is returned).\n   */\n  abstract delete(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>\n  ): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n\n  /**\n   * Deletes multiple records given an array of unique ids.\n   * @param objects An array of ids.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the deleted records in order (if a record could not be found null is returned).\n   */\n  abstract delete<K extends SelectableColumn<Record>>(\n    objects: string[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n\n  /**\n   * Deletes multiple records given an array of unique ids.\n   * @param objects An array of ids.\n   * @returns Array of the deleted records in order (if a record could not be found null is returned).\n   */\n  abstract delete(objects: string[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n\n  /**\n   * Deletes a record given its unique id.\n   * @param object An object with a unique id.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The deleted record, null if the record could not be found.\n   * @throws If the record could not be found.\n   */\n  abstract deleteOrThrow<K extends SelectableColumn<Record>>(\n    object: Identifiable,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Deletes a record given its unique id.\n   * @param object An object with a unique id.\n   * @returns The deleted record, null if the record could not be found.\n   * @throws If the record could not be found.\n   */\n  abstract deleteOrThrow(object: Identifiable): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Deletes a record given a unique id.\n   * @param id The unique id.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns The deleted record, null if the record could not be found.\n   * @throws If the record could not be found.\n   */\n  abstract deleteOrThrow<K extends SelectableColumn<Record>>(\n    id: string,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n\n  /**\n   * Deletes a record given a unique id.\n   * @param id The unique id.\n   * @returns The deleted record, null if the record could not be found.\n   * @throws If the record could not be found.\n   */\n  abstract deleteOrThrow(id: string): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n\n  /**\n   * Deletes multiple records given an array of objects with ids.\n   * @param objects An array of objects with unique ids.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the deleted records in order (if a record could not be found null is returned).\n   * @throws If one or more records could not be found.\n   */\n  abstract deleteOrThrow<K extends SelectableColumn<Record>>(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>,\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>>>>;\n\n  /**\n   * Deletes multiple records given an array of objects with ids.\n   * @param objects An array of objects with unique ids.\n   * @returns Array of the deleted records in order (if a record could not be found null is returned).\n   * @throws If one or more records could not be found.\n   */\n  abstract deleteOrThrow(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>\n  ): Promise<Array<Readonly<SelectedPick<Record, ['*']>>>>;\n\n  /**\n   * Deletes multiple records given an array of unique ids.\n   * @param objects An array of ids.\n   * @param columns Array of columns to be returned. If not specified, first level columns will be returned.\n   * @returns Array of the deleted records in order (if a record could not be found null is returned).\n   * @throws If one or more records could not be found.\n   */\n  abstract deleteOrThrow<K extends SelectableColumn<Record>>(\n    objects: string[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>>>>;\n\n  /**\n   * Deletes multiple records given an array of unique ids.\n   * @param objects An array of ids.\n   * @returns Array of the deleted records in order.\n   * @throws If one or more records could not be found.\n   */\n  abstract deleteOrThrow(objects: string[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>>>>;\n\n  /**\n   * Search for records in the table.\n   * @param query The query to search for.\n   * @param options The options to search with (like: fuzziness)\n   * @returns The found records.\n   */\n  abstract search(\n    query: string,\n    options?: {\n      fuzziness?: FuzzinessExpression;\n      prefix?: PrefixExpression;\n      highlight?: HighlightExpression;\n      filter?: Filter<Record>;\n      boosters?: Boosters<Record>[];\n    }\n  ): Promise<SearchXataRecord<SelectedPick<Record, ['*']>>[]>;\n\n  /**\n   * Aggregates records in the table.\n   * @param expression The aggregations to perform.\n   * @param filter The filter to apply to the queried records.\n   * @returns The requested aggregations.\n   */\n  abstract aggregate<Expression extends Dictionary<AggregationExpression<Record>>>(\n    expression?: Expression,\n    filter?: Filter<Record>\n  ): Promise<AggregationResult<Record, Expression>>;\n\n  abstract query<Result extends XataRecord>(query: Query<Record, Result>): Promise<Page<Record, Result>>;\n}\n\nexport class RestRepository<Record extends XataRecord>\n  extends Query<Record, SelectedPick<Record, ['*']>>\n  implements Repository<Record>\n{\n  #table: string;\n  #getFetchProps: () => Promise<ApiExtraProps>;\n  #db: SchemaPluginResult<any>;\n  #cache: CacheImpl;\n  #schemaTables?: Schemas.Table[];\n  #trace: TraceFunction;\n\n  constructor(options: {\n    table: string;\n    db: SchemaPluginResult<any>;\n    pluginOptions: XataPluginOptions;\n    schemaTables?: Schemas.Table[];\n  }) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n\n    this.#table = options.table;\n    this.#db = options.db;\n    this.#cache = options.pluginOptions.cache;\n    this.#schemaTables = options.schemaTables;\n    this.#getFetchProps = async () => {\n      const props = await options.pluginOptions.getFetchProps();\n      return { ...props, sessionID: generateUUID() };\n    };\n\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    this.#trace = async <T>(\n      name: string,\n      fn: (options: { setAttributes: (attrs: AttributeDictionary) => void }) => T,\n      options: AttributeDictionary = {}\n    ) => {\n      return trace<T>(name, fn, {\n        ...options,\n        [TraceAttributes.TABLE]: this.#table,\n        [TraceAttributes.KIND]: 'sdk-operation',\n        [TraceAttributes.VERSION]: VERSION\n      });\n    };\n  }\n\n  async create<K extends SelectableColumn<Record>>(\n    object: EditableData<Record> & Partial<Identifiable>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async create(\n    object: EditableData<Record> & Partial<Identifiable>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async create<K extends SelectableColumn<Record>>(\n    id: string,\n    object: EditableData<Record>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async create(\n    id: string,\n    object: EditableData<Record>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async create<K extends SelectableColumn<Record>>(\n    objects: Array<EditableData<Record> & Partial<Identifiable>>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>[]>;\n  async create(\n    objects: Array<EditableData<Record> & Partial<Identifiable>>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>[]>;\n  async create<K extends SelectableColumn<Record>>(\n    a: string | (EditableData<Record> & Partial<Identifiable>) | Array<EditableData<Record> & Partial<Identifiable>>,\n    b?: EditableData<Record> | K[] | { ifVersion?: number },\n    c?: K[] | { ifVersion?: number },\n    d?: { ifVersion?: number }\n  ): Promise<\n    | Readonly<SelectedPick<Record, K[]>>\n    | Readonly<SelectedPick<Record, K[]>>[]\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Readonly<SelectedPick<Record, ['*']>>[]\n  > {\n    return this.#trace('create', async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n\n      // Create many records\n      if (Array.isArray(a)) {\n        if (a.length === 0) return [];\n\n        const columns = isStringArray(b) ? b : undefined;\n        return this.#bulkInsertTableRecords(a, columns);\n      }\n\n      // Create one record with id as param\n      if (isString(a) && isObject(b)) {\n        if (a === '') throw new Error(\"The id can't be empty\");\n\n        const columns = isStringArray(c) ? c : undefined;\n        return this.#insertRecordWithId(a, b as EditableData<Record>, columns, { createOnly: true, ifVersion });\n      }\n\n      // Create one record with id as property\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === '') throw new Error(\"The id can't be empty\");\n\n        const columns = isStringArray(b) ? b : undefined;\n        return this.#insertRecordWithId(a.id, { ...a, id: undefined }, columns, { createOnly: true, ifVersion });\n      }\n\n      // Create one record without id\n      if (isObject(a)) {\n        const columns = isStringArray(b) ? b : undefined;\n        return this.#insertRecordWithoutId(a, columns);\n      }\n\n      throw new Error('Invalid arguments for create method');\n    });\n  }\n\n  async #insertRecordWithoutId(object: EditableData<Record>, columns: SelectableColumn<Record>[] = ['*']) {\n    const fetchProps = await this.#getFetchProps();\n\n    const record = transformObjectLinks(object);\n\n    const response = await insertRecord({\n      pathParams: {\n        workspace: '{workspaceId}',\n        dbBranchName: '{dbBranch}',\n        region: '{region}',\n        tableName: this.#table\n      },\n      queryParams: { columns },\n      body: record,\n      ...fetchProps\n    });\n\n    const schemaTables = await this.#getSchemaTables();\n    return initObject(this.#db, schemaTables, this.#table, response, columns) as any;\n  }\n\n  async #insertRecordWithId(\n    recordId: string,\n    object: EditableData<Record>,\n    columns: SelectableColumn<Record>[] = ['*'],\n    { createOnly, ifVersion }: { createOnly: boolean; ifVersion?: number }\n  ) {\n    const fetchProps = await this.#getFetchProps();\n\n    const record = transformObjectLinks(object);\n\n    const response = await insertRecordWithID({\n      pathParams: {\n        workspace: '{workspaceId}',\n        dbBranchName: '{dbBranch}',\n        region: '{region}',\n        tableName: this.#table,\n        recordId\n      },\n      body: record,\n      queryParams: { createOnly, columns, ifVersion },\n      ...fetchProps\n    });\n\n    const schemaTables = await this.#getSchemaTables();\n    return initObject(this.#db, schemaTables, this.#table, response, columns) as any;\n  }\n\n  async #bulkInsertTableRecords(objects: EditableData<Record>[], columns: SelectableColumn<Record>[] = ['*']) {\n    const fetchProps = await this.#getFetchProps();\n\n    const records = objects.map((object) => transformObjectLinks(object));\n\n    const response = await bulkInsertTableRecords({\n      pathParams: {\n        workspace: '{workspaceId}',\n        dbBranchName: '{dbBranch}',\n        region: '{region}',\n        tableName: this.#table\n      },\n      queryParams: { columns },\n      body: { records },\n      ...fetchProps\n    });\n\n    if (!isResponseWithRecords(response)) {\n      throw new Error(\"Request included columns but server didn't include them\");\n    }\n\n    const schemaTables = await this.#getSchemaTables();\n    return response.records?.map((item) => initObject(this.#db, schemaTables, this.#table, item, columns)) as any;\n  }\n\n  async read<K extends SelectableColumn<Record>>(\n    id: string,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns> | null>>;\n  async read(id: string): Promise<Readonly<SelectedPick<Record, ['*']> | null>>;\n  async read<K extends SelectableColumn<Record>>(\n    ids: string[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n  async read(ids: string[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n  async read<K extends SelectableColumn<Record>>(\n    object: Identifiable,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns> | null>>;\n  async read(object: Identifiable): Promise<Readonly<SelectedPick<Record, ['*']> | null>>;\n  async read<K extends SelectableColumn<Record>>(\n    objects: Identifiable[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n  async read(objects: Identifiable[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n  async read<K extends SelectableColumn<Record>>(\n    a: string | string[] | Identifiable | Identifiable[],\n    b?: K[]\n  ): Promise<\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Array<Readonly<SelectedPick<Record, ['*']>> | null>\n    | Readonly<SelectedPick<Record, K[]>>\n    | Array<Readonly<SelectedPick<Record, K[]>> | null>\n    | null\n  > {\n    return this.#trace('read', async () => {\n      const columns = isStringArray(b) ? b : ['*' as const];\n\n      // Read many records\n      if (Array.isArray(a)) {\n        if (a.length === 0) return [];\n\n        const ids = a.map((item) => extractId(item));\n\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n\n        // Maintain order of objects\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {} as Dictionary<any>);\n\n        return ids.map((id) => dictionary[id ?? ''] ?? null);\n      }\n\n      // Read one record\n      const id = extractId(a);\n      if (id) {\n        const fetchProps = await this.#getFetchProps();\n\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: '{workspaceId}',\n              dbBranchName: '{dbBranch}',\n              region: '{region}',\n              tableName: this.#table,\n              recordId: id\n            },\n            queryParams: { columns },\n            ...fetchProps\n          });\n\n          const schemaTables = await this.#getSchemaTables();\n          return initObject(this.#db, schemaTables, this.#table, response, columns);\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n\n          throw e;\n        }\n      }\n\n      return null;\n    });\n  }\n\n  async readOrThrow<K extends SelectableColumn<Record>>(\n    id: string,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async readOrThrow(id: string): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async readOrThrow<K extends SelectableColumn<Record>>(\n    ids: string[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>>>>;\n  async readOrThrow(ids: string[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>>>>;\n  async readOrThrow<K extends SelectableColumn<Record>>(\n    object: Identifiable,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async readOrThrow(object: Identifiable): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async readOrThrow<K extends SelectableColumn<Record>>(\n    objects: Identifiable[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>>>>;\n  async readOrThrow(objects: Identifiable[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>>>>;\n  async readOrThrow<K extends SelectableColumn<Record>>(\n    a: string | string[] | Identifiable | Identifiable[],\n    b?: K[]\n  ): Promise<\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Readonly<SelectedPick<Record, ['*']>>[]\n    | Readonly<SelectedPick<Record, K[]>>\n    | Readonly<SelectedPick<Record, K[]>>[]\n  > {\n    return this.#trace('readOrThrow', async () => {\n      const result = await this.read(a as any, b as any);\n\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          (a as Array<string | Identifiable>)\n            .filter((_item, index) => result[index] === null)\n            .map((item) => extractId(item))\n        );\n\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(', ')}`);\n        }\n\n        return result as any;\n      }\n\n      if (result === null) {\n        const id = extractId(a) ?? 'unknown';\n        throw new Error(`Record with id ${id} not found`);\n      }\n\n      return result;\n    });\n  }\n\n  async update<K extends SelectableColumn<Record>>(\n    object: Partial<EditableData<Record>> & Identifiable,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>> | null>;\n  async update(\n    object: Partial<EditableData<Record>> & Identifiable,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>> | null>;\n  async update<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Partial<EditableData<Record>>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>> | null>;\n  async update(\n    id: string,\n    object: Partial<EditableData<Record>>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>> | null>;\n  async update<K extends SelectableColumn<Record>>(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>,\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n  async update(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>\n  ): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n  async update<K extends SelectableColumn<Record>>(\n    a: string | (Partial<EditableData<Record>> & Identifiable) | Array<Partial<EditableData<Record>> & Identifiable>,\n    b?: Partial<EditableData<Record>> | K[] | { ifVersion?: number },\n    c?: K[] | { ifVersion?: number },\n    d?: { ifVersion?: number }\n  ): Promise<\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Array<Readonly<SelectedPick<Record, ['*']>> | null>\n    | Readonly<SelectedPick<Record, K[]>>\n    | Array<Readonly<SelectedPick<Record, K[]>> | null>\n    | null\n  > {\n    return this.#trace('update', async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n\n      // Update many records\n      if (Array.isArray(a)) {\n        if (a.length === 0) return [];\n\n        if (a.length > 100) {\n          // TODO: Implement bulk update when API has support for it\n          console.warn('Bulk update operation is not optimized in the Xata API yet, this request might be slow');\n        }\n\n        const columns = isStringArray(b) ? b : (['*'] as K[]);\n        return Promise.all(a.map((object) => this.update(object, columns)));\n      }\n\n      // Update one record with id as param\n      if (isString(a) && isObject(b)) {\n        const columns = isStringArray(c) ? c : undefined;\n        return this.#updateRecordWithID(a, b as EditableData<Record>, columns, { ifVersion });\n      }\n\n      // Update one record with id as property\n      if (isObject(a) && isString(a.id)) {\n        const columns = isStringArray(b) ? b : undefined;\n        return this.#updateRecordWithID(a.id, { ...a, id: undefined }, columns, { ifVersion });\n      }\n\n      throw new Error('Invalid arguments for update method');\n    });\n  }\n\n  async updateOrThrow<K extends SelectableColumn<Record>>(\n    object: Partial<EditableData<Record>> & Identifiable,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async updateOrThrow(\n    object: Partial<EditableData<Record>> & Identifiable,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async updateOrThrow<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Partial<EditableData<Record>>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async updateOrThrow(\n    id: string,\n    object: Partial<EditableData<Record>>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async updateOrThrow<K extends SelectableColumn<Record>>(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>[]>;\n  async updateOrThrow(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>[]>;\n  async updateOrThrow<K extends SelectableColumn<Record>>(\n    a: string | (Partial<EditableData<Record>> & Identifiable) | Array<Partial<EditableData<Record>> & Identifiable>,\n    b?: Partial<EditableData<Record>> | K[] | { ifVersion?: number },\n    c?: K[] | { ifVersion?: number },\n    d?: { ifVersion?: number }\n  ): Promise<\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Array<Readonly<SelectedPick<Record, ['*']>>>\n    | Readonly<SelectedPick<Record, K[]>>\n    | Array<Readonly<SelectedPick<Record, K[]>>>\n  > {\n    return this.#trace('updateOrThrow', async () => {\n      const result = await this.update(a as any, b as any, c as any, d as any);\n\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          (a as Array<string | Identifiable>)\n            .filter((_item, index) => result[index] === null)\n            .map((item) => extractId(item))\n        );\n\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(', ')}`);\n        }\n\n        return result as any;\n      }\n\n      if (result === null) {\n        const id = extractId(a) ?? 'unknown';\n        throw new Error(`Record with id ${id} not found`);\n      }\n\n      return result;\n    });\n  }\n\n  async #updateRecordWithID(\n    recordId: string,\n    object: Partial<EditableData<Record>>,\n    columns: SelectableColumn<Record>[] = ['*'],\n    { ifVersion }: { ifVersion?: number }\n  ) {\n    const fetchProps = await this.#getFetchProps();\n\n    const record = transformObjectLinks(object);\n\n    try {\n      const response = await updateRecordWithID({\n        pathParams: {\n          workspace: '{workspaceId}',\n          dbBranchName: '{dbBranch}',\n          region: '{region}',\n          tableName: this.#table,\n          recordId\n        },\n        queryParams: { columns, ifVersion },\n        body: record,\n        ...fetchProps\n      });\n\n      const schemaTables = await this.#getSchemaTables();\n      return initObject(this.#db, schemaTables, this.#table, response, columns) as any;\n    } catch (e) {\n      if (isObject(e) && e.status === 404) {\n        return null;\n      }\n\n      throw e;\n    }\n  }\n\n  async createOrUpdate<K extends SelectableColumn<Record>>(\n    object: EditableData<Record> & Identifiable,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async createOrUpdate(\n    object: EditableData<Record> & Identifiable,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async createOrUpdate<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async createOrUpdate(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async createOrUpdate<K extends SelectableColumn<Record>>(\n    objects: Array<EditableData<Record> & Identifiable>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>[]>;\n  async createOrUpdate(\n    objects: Array<EditableData<Record> & Identifiable>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>[]>;\n  async createOrUpdate<K extends SelectableColumn<Record>>(\n    a: string | EditableData<Record> | EditableData<Record>[],\n    b?: EditableData<Record> | Omit<EditableData<Record>, 'id'> | K[] | { ifVersion?: number },\n    c?: K[] | { ifVersion?: number },\n    d?: { ifVersion?: number }\n  ): Promise<\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Array<Readonly<SelectedPick<Record, ['*']>>>\n    | Readonly<SelectedPick<Record, K[]>>\n    | Array<Readonly<SelectedPick<Record, K[]>>>\n  > {\n    return this.#trace('createOrUpdate', async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n\n      // Create or update many records\n      if (Array.isArray(a)) {\n        if (a.length === 0) return [];\n\n        if (a.length > 100) {\n          // TODO: Implement bulk update when API has support for it\n          console.warn('Bulk update operation is not optimized in the Xata API yet, this request might be slow');\n        }\n\n        const columns = isStringArray(b) ? b : (['*'] as K[]);\n        return Promise.all(a.map((object) => this.createOrUpdate(object as any, columns)));\n      }\n\n      // Create or update one record with id as param\n      if (isString(a) && isObject(b)) {\n        const columns = isStringArray(c) ? c : undefined;\n        return this.#upsertRecordWithID(a, b as EditableData<Record>, columns, { ifVersion });\n      }\n\n      // Create or update one record with id as property\n      if (isObject(a) && isString(a.id)) {\n        const columns = isStringArray(c) ? c : undefined;\n        return this.#upsertRecordWithID(a.id, { ...a, id: undefined }, columns, { ifVersion });\n      }\n\n      throw new Error('Invalid arguments for createOrUpdate method');\n    });\n  }\n\n  async #upsertRecordWithID(\n    recordId: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    columns: SelectableColumn<Record>[] = ['*'],\n    { ifVersion }: { ifVersion?: number }\n  ) {\n    const fetchProps = await this.#getFetchProps();\n\n    const response = await upsertRecordWithID({\n      pathParams: {\n        workspace: '{workspaceId}',\n        dbBranchName: '{dbBranch}',\n        region: '{region}',\n        tableName: this.#table,\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: object,\n      ...fetchProps\n    });\n\n    const schemaTables = await this.#getSchemaTables();\n    return initObject(this.#db, schemaTables, this.#table, response, columns) as any;\n  }\n\n  async createOrReplace<K extends SelectableColumn<Record>>(\n    object: EditableData<Record> & Identifiable,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async createOrReplace(\n    object: EditableData<Record> & Identifiable,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async createOrReplace<K extends SelectableColumn<Record>>(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    columns: K[],\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async createOrReplace(\n    id: string,\n    object: Omit<EditableData<Record>, 'id'>,\n    options?: { ifVersion?: number }\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async createOrReplace<K extends SelectableColumn<Record>>(\n    objects: Array<EditableData<Record> & Identifiable>,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>[]>;\n  async createOrReplace(\n    objects: Array<EditableData<Record> & Identifiable>\n  ): Promise<Readonly<SelectedPick<Record, ['*']>>[]>;\n  async createOrReplace<K extends SelectableColumn<Record>>(\n    a: string | EditableData<Record> | EditableData<Record>[],\n    b?: EditableData<Record> | Omit<EditableData<Record>, 'id'> | K[] | { ifVersion?: number },\n    c?: K[] | { ifVersion?: number },\n    d?: { ifVersion?: number }\n  ): Promise<\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Array<Readonly<SelectedPick<Record, ['*']>>>\n    | Readonly<SelectedPick<Record, K[]>>\n    | Array<Readonly<SelectedPick<Record, K[]>>>\n  > {\n    return this.#trace('createOrReplace', async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n\n      // Create or replace many records\n      if (Array.isArray(a)) {\n        if (a.length === 0) return [];\n\n        const columns = isStringArray(b) ? b : (['*'] as K[]);\n        return this.#bulkInsertTableRecords(a, columns);\n      }\n\n      // Create or replace one record with id as param\n      if (isString(a) && isObject(b)) {\n        const columns = isStringArray(c) ? c : undefined;\n        return this.#insertRecordWithId(a, b as EditableData<Record>, columns, { createOnly: false, ifVersion });\n      }\n\n      // Create or replace one record with id as property\n      if (isObject(a) && isString(a.id)) {\n        const columns = isStringArray(c) ? c : undefined;\n        return this.#insertRecordWithId(a.id, { ...a, id: undefined }, columns, { createOnly: false, ifVersion });\n      }\n\n      throw new Error('Invalid arguments for createOrReplace method');\n    });\n  }\n\n  async delete<K extends SelectableColumn<Record>>(\n    object: Identifiable,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>> | null>;\n  async delete(object: Identifiable): Promise<Readonly<SelectedPick<Record, ['*']>> | null>;\n  async delete<K extends SelectableColumn<Record>>(\n    id: string,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>> | null>;\n  async delete(id: string): Promise<Readonly<SelectedPick<Record, ['*']>> | null>;\n  async delete<K extends SelectableColumn<Record>>(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>,\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n  async delete(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>\n  ): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n  async delete<K extends SelectableColumn<Record>>(\n    objects: string[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>> | null>>;\n  async delete(objects: string[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>> | null>>;\n  async delete<K extends SelectableColumn<Record>>(\n    a: string | Identifiable | Array<string | Identifiable>,\n    b?: K[]\n  ): Promise<\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Array<Readonly<SelectedPick<Record, ['*']>> | null>\n    | Readonly<SelectedPick<Record, K[]>>\n    | Array<Readonly<SelectedPick<Record, K[]>> | null>\n    | null\n  > {\n    return this.#trace('delete', async () => {\n      // Delete many records\n      if (Array.isArray(a)) {\n        if (a.length === 0) return [];\n\n        if (a.length > 100) {\n          // TODO: Implement bulk delete when API has support for it\n          console.warn('Bulk delete operation is not optimized in the Xata API yet, this request might be slow');\n        }\n\n        return Promise.all(a.map((id) => this.delete(id as any, b as any)));\n      }\n\n      // Delete one record with id as param\n      if (isString(a)) {\n        return this.#deleteRecord(a, b);\n      }\n\n      // Delete one record with id as property\n      if (isObject(a) && isString(a.id)) {\n        return this.#deleteRecord(a.id, b);\n      }\n\n      throw new Error('Invalid arguments for delete method');\n    });\n  }\n\n  async deleteOrThrow<K extends SelectableColumn<Record>>(\n    object: Identifiable,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async deleteOrThrow(object: Identifiable): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async deleteOrThrow<K extends SelectableColumn<Record>>(\n    id: string,\n    columns: K[]\n  ): Promise<Readonly<SelectedPick<Record, typeof columns>>>;\n  async deleteOrThrow(id: string): Promise<Readonly<SelectedPick<Record, ['*']>>>;\n  async deleteOrThrow<K extends SelectableColumn<Record>>(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>,\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>>>>;\n  async deleteOrThrow(\n    objects: Array<Partial<EditableData<Record>> & Identifiable>\n  ): Promise<Array<Readonly<SelectedPick<Record, ['*']>>>>;\n  async deleteOrThrow<K extends SelectableColumn<Record>>(\n    objects: string[],\n    columns: K[]\n  ): Promise<Array<Readonly<SelectedPick<Record, typeof columns>>>>;\n  async deleteOrThrow(objects: string[]): Promise<Array<Readonly<SelectedPick<Record, ['*']>>>>;\n  async deleteOrThrow<K extends SelectableColumn<Record>>(\n    a: string | Identifiable | Array<string | Identifiable>,\n    b?: K[]\n  ): Promise<\n    | Readonly<SelectedPick<Record, ['*']>>\n    | Array<Readonly<SelectedPick<Record, ['*']>>>\n    | Readonly<SelectedPick<Record, K[]>>\n    | Array<Readonly<SelectedPick<Record, K[]>>>\n  > {\n    return this.#trace('deleteOrThrow', async () => {\n      const result = await this.delete(a as any, b as any);\n\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          (a as Array<string | Identifiable>)\n            .filter((_item, index) => result[index] === null)\n            .map((item) => extractId(item))\n        );\n\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(', ')}`);\n        }\n\n        return result as any;\n      } else if (result === null) {\n        const id = extractId(a) ?? 'unknown';\n        throw new Error(`Record with id ${id} not found`);\n      }\n\n      return result;\n    });\n  }\n\n  async #deleteRecord(recordId: string, columns: SelectableColumn<Record>[] = ['*']) {\n    const fetchProps = await this.#getFetchProps();\n\n    try {\n      const response = await deleteRecord({\n        pathParams: {\n          workspace: '{workspaceId}',\n          dbBranchName: '{dbBranch}',\n          region: '{region}',\n          tableName: this.#table,\n          recordId\n        },\n        queryParams: { columns },\n        ...fetchProps\n      });\n\n      const schemaTables = await this.#getSchemaTables();\n      return initObject(this.#db, schemaTables, this.#table, response, columns) as any;\n    } catch (e) {\n      if (isObject(e) && e.status === 404) {\n        return null;\n      }\n\n      throw e;\n    }\n  }\n\n  async search(\n    query: string,\n    options: {\n      fuzziness?: FuzzinessExpression;\n      prefix?: PrefixExpression;\n      highlight?: HighlightExpression;\n      filter?: Filter<Record>;\n      boosters?: Boosters<Record>[];\n    } = {}\n  ) {\n    return this.#trace('search', async () => {\n      const fetchProps = await this.#getFetchProps();\n\n      const { records } = await searchTable({\n        pathParams: {\n          workspace: '{workspaceId}',\n          dbBranchName: '{dbBranch}',\n          region: '{region}',\n          tableName: this.#table\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter as Schemas.FilterExpression,\n          boosters: options.boosters as Schemas.BoosterExpression[]\n        },\n        ...fetchProps\n      });\n\n      const schemaTables = await this.#getSchemaTables();\n\n      // TODO - Column selection not supported by search endpoint yet\n      return records.map((item) => initObject(this.#db, schemaTables, this.#table, item, ['*'])) as any;\n    });\n  }\n\n  async aggregate<Expression extends Dictionary<AggregationExpression<Record>>>(\n    aggs?: Expression,\n    filter?: Filter<Record>\n  ) {\n    return this.#trace('aggregate', async () => {\n      const fetchProps = await this.#getFetchProps();\n\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: '{workspaceId}',\n          dbBranchName: '{dbBranch}',\n          region: '{region}',\n          tableName: this.#table\n        },\n        body: { aggs, filter: filter as Schemas.FilterExpression },\n        ...fetchProps\n      });\n\n      return result as any;\n    });\n  }\n\n  async query<Result extends XataRecord>(query: Query<Record, Result>): Promise<Page<Record, Result>> {\n    return this.#trace('query', async () => {\n      const cacheQuery = await this.#getCacheQuery<Result>(query);\n      if (cacheQuery) return new Page<Record, Result>(query, cacheQuery.meta, cacheQuery.records);\n\n      const data = query.getQueryOptions();\n\n      const fetchProps = await this.#getFetchProps();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: '{workspaceId}',\n          dbBranchName: '{dbBranch}',\n          region: '{region}',\n          tableName: this.#table\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== undefined ? buildSortFilter(data.sort) : undefined,\n          page: data.pagination,\n          columns: data.columns ?? ['*']\n        },\n        ...fetchProps\n      });\n\n      const schemaTables = await this.#getSchemaTables();\n      const records = objects.map((record) =>\n        initObject<Result>(this.#db, schemaTables, this.#table, record, data.columns ?? ['*'])\n      );\n      await this.#setCacheQuery(query, meta, records);\n\n      return new Page<Record, Result>(query, meta, records);\n    });\n  }\n\n  async summarizeTable<Result extends XataRecord>(\n    query: Query<Record, Result>,\n    summaries?: Dictionary<SummarizeExpression<Record>>,\n    summariesFilter?: Schemas.FilterExpression\n  ) {\n    return this.#trace('summarize', async () => {\n      const data = query.getQueryOptions();\n\n      const fetchProps = await this.#getFetchProps();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: '{workspaceId}',\n          dbBranchName: '{dbBranch}',\n          region: '{region}',\n          tableName: this.#table\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== undefined ? buildSortFilter(data.sort) : undefined,\n          columns: data.columns,\n          page: data.pagination?.size !== undefined ? { size: data.pagination?.size } : undefined,\n          summaries,\n          summariesFilter\n        },\n        ...fetchProps\n      });\n\n      return result;\n    });\n  }\n\n  async #setCacheQuery(query: Query<Record, XataRecord>, meta: RecordsMetadata, records: XataRecord[]): Promise<void> {\n    await this.#cache.set(`query_${this.#table}:${query.key()}`, { date: new Date(), meta, records });\n  }\n\n  async #getCacheQuery<T extends XataRecord>(\n    query: Query<Record, XataRecord>\n  ): Promise<{ meta: RecordsMetadata; records: T[] } | null> {\n    const key = `query_${this.#table}:${query.key()}`;\n    const result = await this.#cache.get<{ date: Date; meta: RecordsMetadata; records: T[] }>(key);\n    if (!result) return null;\n\n    const { cache: ttl = this.#cache.defaultQueryTTL } = query.getQueryOptions();\n    if (ttl < 0) return null;\n\n    const hasExpired = result.date.getTime() + ttl < Date.now();\n    return hasExpired ? null : result;\n  }\n\n  async #getSchemaTables(): Promise<Schemas.Table[]> {\n    if (this.#schemaTables) return this.#schemaTables;\n    const fetchProps = await this.#getFetchProps();\n\n    const { schema } = await getBranchDetails({\n      pathParams: { workspace: '{workspaceId}', dbBranchName: '{dbBranch}', region: '{region}' },\n      ...fetchProps\n    });\n\n    this.#schemaTables = schema.tables;\n    return schema.tables;\n  }\n}\n\nconst transformObjectLinks = (object: any) => {\n  return Object.entries(object).reduce((acc, [key, value]) => {\n    // Ignore internal properties\n    if (key === 'xata') return acc;\n\n    // Transform links to identifier\n    return { ...acc, [key]: isIdentifiable(value) ? value.id : value };\n  }, {});\n};\n\nexport const initObject = <T>(\n  db: Record<string, Repository<any>>,\n  schemaTables: Schemas.Table[],\n  table: string,\n  object: Record<string, unknown>,\n  selectedColumns: string[]\n) => {\n  const result: Dictionary<unknown> = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(result, rest);\n\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns) console.error(`Table ${table} not found in schema`);\n\n  for (const column of columns ?? []) {\n    // Ignore columns not selected\n    if (!isValidColumn(selectedColumns, column)) continue;\n\n    const value = result[column.name];\n\n    switch (column.type) {\n      case 'datetime': {\n        const date = value !== undefined ? new Date(value as string) : undefined;\n\n        if (date && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else if (date) {\n          result[column.name] = date;\n        }\n\n        break;\n      }\n      case 'link': {\n        const linkTable = column.link?.table;\n\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, '*'];\n            }\n\n            if (item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split('.');\n              return [...acc, path.join('.')];\n            }\n\n            return acc;\n          }, [] as string[]);\n\n          result[column.name] = initObject(db, schemaTables, linkTable, value, selectedLinkColumns);\n        } else {\n          result[column.name] = null;\n        }\n\n        break;\n      }\n      default:\n        result[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n\n  result.read = function (columns?: any) {\n    return db[table].read(result['id'] as string, columns);\n  };\n\n  result.update = function (data: any, b?: any, c?: any) {\n    const columns = isStringArray(b) ? b : ['*'];\n    const ifVersion = parseIfVersion(b, c);\n\n    return db[table].update(result['id'] as string, data, columns, { ifVersion });\n  };\n\n  result.replace = function (data: any, b?: any, c?: any) {\n    const columns = isStringArray(b) ? b : ['*'];\n    const ifVersion = parseIfVersion(b, c);\n\n    return db[table].createOrReplace(result['id'] as string, data, columns, { ifVersion });\n  };\n\n  result.delete = function () {\n    return db[table].delete(result['id'] as string);\n  };\n\n  result.getMetadata = function () {\n    return xata;\n  };\n\n  for (const prop of ['read', 'update', 'replace', 'delete', 'getMetadata']) {\n    Object.defineProperty(result, prop, { enumerable: false });\n  }\n\n  Object.freeze(result);\n  return result as T;\n};\n\nfunction isResponseWithRecords(value: any): value is { records: Schemas.XataRecord[] } {\n  return isObject(value) && Array.isArray(value.records);\n}\n\nfunction extractId(value: any): string | undefined {\n  if (isString(value)) return value;\n  if (isObject(value) && isString(value.id)) return value.id;\n  return undefined;\n}\n\nfunction isValidColumn(columns: string[], column: Schemas.Column) {\n  // Every column alias\n  if (columns.includes('*')) return true;\n\n  // Link columns\n  if (column.type === 'link') {\n    const linkColumns = columns.filter((item) => item.startsWith(column.name));\n\n    return linkColumns.length > 0;\n  }\n\n  // Normal columns\n  return columns.includes(column.name);\n}\n\nfunction parseIfVersion(...args: any[]): number | undefined {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n\n  return undefined;\n}\n","export interface CacheImpl {\n  defaultQueryTTL: number;\n\n  getAll(): Promise<Record<string, unknown>>;\n  get: <T>(key: string) => Promise<T | null>;\n  set: <T>(key: string, value: T) => Promise<void>;\n  delete: (key: string) => Promise<void>;\n  clear: () => Promise<void>;\n}\n\nexport interface SimpleCacheOptions {\n  max?: number;\n  defaultQueryTTL?: number;\n}\n\nexport class SimpleCache implements CacheImpl {\n  #map: Map<string, unknown>;\n\n  capacity: number;\n  defaultQueryTTL: number;\n\n  constructor(options: SimpleCacheOptions = {}) {\n    this.#map = new Map();\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1000;\n  }\n\n  async getAll(): Promise<Record<string, unknown>> {\n    return Object.fromEntries(this.#map);\n  }\n\n  async get<T>(key: string): Promise<T | null> {\n    return (this.#map.get(key) ?? null) as T | null;\n  }\n\n  async set<T>(key: string, value: T): Promise<void> {\n    await this.delete(key);\n    this.#map.set(key, value);\n\n    if (this.#map.size > this.capacity) {\n      const leastRecentlyUsed = this.#map.keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n\n  async delete(key: string): Promise<void> {\n    this.#map.delete(key);\n  }\n\n  async clear(): Promise<void> {\n    return this.#map.clear();\n  }\n}\n","import type { Schemas } from '../api';\nimport { XataPlugin, XataPluginOptions } from '../plugins';\nimport { isString } from '../util/lang';\nimport { XataRecord } from './record';\nimport { Repository, RestRepository } from './repository';\n\nexport * from './cache';\nexport * from './inference';\nexport * from './operators';\nexport * from './pagination';\nexport { Query } from './query';\nexport { isIdentifiable, isXataRecord } from './record';\nexport type { BaseData, EditableData, Identifiable, Link, XataRecord } from './record';\nexport { Repository, RestRepository } from './repository';\nexport * from './selection';\n\nexport type SchemaDefinition = {\n  table: string;\n};\n\nexport type SchemaPluginResult<Schemas extends Record<string, XataRecord>> = {\n  [Key in keyof Schemas]: Repository<Schemas[Key]>;\n};\n\nexport class SchemaPlugin<Schemas extends Record<string, XataRecord>> extends XataPlugin {\n  #tables: Record<string, Repository<any>> = {};\n  #schemaTables?: Schemas.Table[];\n\n  constructor(schemaTables?: Schemas.Table[]) {\n    super();\n\n    this.#schemaTables = schemaTables;\n  }\n\n  build(pluginOptions: XataPluginOptions): SchemaPluginResult<Schemas> {\n    const db: any = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table)) throw new Error('Invalid table name');\n          if (this.#tables[table] === undefined) {\n            this.#tables[table] = new RestRepository({ db, pluginOptions, table, schemaTables: this.#schemaTables });\n          }\n\n          return this.#tables[table];\n        }\n      }\n    );\n\n    // Inject generated tables for shell to auto-complete\n    const tableNames = this.#schemaTables?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: this.#schemaTables });\n    }\n\n    return db;\n  }\n}\n","import type { Schemas } from '../api';\nimport { getBranchDetails, searchBranch } from '../api';\nimport { FuzzinessExpression, HighlightExpression, PrefixExpression } from '../api/schemas';\nimport { XataPlugin, XataPluginOptions } from '../plugins';\nimport { SchemaPluginResult } from '../schema';\nimport { Filter } from '../schema/filters';\nimport { BaseData, XataRecord, XataRecordMetadata } from '../schema/record';\nimport { initObject } from '../schema/repository';\nimport { SelectedPick } from '../schema/selection';\nimport { GetArrayInnerType, StringKeys, Values } from '../util/types';\nimport { Boosters } from './boosters';\nimport { TargetColumn } from './target';\n\nexport type SearchOptions<Schemas extends Record<string, BaseData>, Tables extends StringKeys<Schemas>> = {\n  fuzziness?: FuzzinessExpression;\n  prefix?: PrefixExpression;\n  highlight?: HighlightExpression;\n  tables?: Array<\n    | Tables\n    | Values<{\n        [Model in GetArrayInnerType<NonNullable<Tables[]>>]: {\n          table: Model;\n          target?: TargetColumn<Schemas[Model] & XataRecord>[];\n          filter?: Filter<SelectedPick<Schemas[Model] & XataRecord, ['*']>>;\n          boosters?: Boosters<Schemas[Model] & XataRecord>[];\n        };\n      }>\n  >;\n};\n\nexport type SearchPluginResult<Schemas extends Record<string, BaseData>> = {\n  all: <Tables extends StringKeys<Schemas>>(\n    query: string,\n    options?: SearchOptions<Schemas, Tables>\n  ) => Promise<\n    Values<{\n      [Model in ExtractTables<\n        Schemas,\n        Tables,\n        GetArrayInnerType<NonNullable<NonNullable<typeof options>['tables']>>\n      >]: {\n        table: Model;\n        record: Awaited<SearchXataRecord<SelectedPick<Schemas[Model] & XataRecord, ['*']>>>;\n      };\n    }>[]\n  >;\n  byTable: <Tables extends StringKeys<Schemas>>(\n    query: string,\n    options?: SearchOptions<Schemas, Tables>\n  ) => Promise<{\n    [Model in ExtractTables<\n      Schemas,\n      Tables,\n      GetArrayInnerType<NonNullable<NonNullable<typeof options>['tables']>>\n    >]?: Awaited<SearchXataRecord<SelectedPick<Schemas[Model] & XataRecord, ['*']>>[]>;\n  }>;\n};\n\nexport class SearchPlugin<Schemas extends Record<string, XataRecord>> extends XataPlugin {\n  #schemaTables?: Schemas.Table[];\n\n  constructor(private db: SchemaPluginResult<Schemas>, schemaTables?: Schemas.Table[]) {\n    super();\n    this.#schemaTables = schemaTables;\n  }\n\n  build({ getFetchProps }: XataPluginOptions): SearchPluginResult<Schemas> {\n    return {\n      all: async <Tables extends StringKeys<Schemas>>(query: string, options: SearchOptions<Schemas, Tables> = {}) => {\n        const records = await this.#search(query, options, getFetchProps);\n        const schemaTables = await this.#getSchemaTables(getFetchProps);\n\n        return records.map((record) => {\n          const { table = 'orphan' } = record.xata;\n\n          // TODO: Search endpoint doesn't support column selection\n          return { table, record: initObject(this.db, schemaTables, table, record, ['*']) } as any;\n        });\n      },\n      byTable: async <Tables extends StringKeys<Schemas>>(\n        query: string,\n        options: SearchOptions<Schemas, Tables> = {}\n      ) => {\n        const records = await this.#search(query, options, getFetchProps);\n        const schemaTables = await this.#getSchemaTables(getFetchProps);\n\n        return records.reduce((acc, record) => {\n          const { table = 'orphan' } = record.xata;\n\n          const items = acc[table] ?? [];\n          // TODO: Search endpoint doesn't support column selection\n          const item = initObject(this.db, schemaTables, table, record, ['*']);\n\n          return { ...acc, [table]: [...items, item] };\n        }, {} as any);\n      }\n    };\n  }\n\n  async #search<Tables extends StringKeys<Schemas>>(\n    query: string,\n    options: SearchOptions<Schemas, Tables>,\n    getFetchProps: XataPluginOptions['getFetchProps']\n  ) {\n    const fetchProps = await getFetchProps();\n    const { tables, fuzziness, highlight, prefix } = options ?? {};\n\n    const { records } = await searchBranch({\n      pathParams: { workspace: '{workspaceId}', dbBranchName: '{dbBranch}', region: '{region}' },\n      // @ts-ignore https://github.com/xataio/client-ts/issues/313\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...fetchProps\n    });\n\n    return records;\n  }\n\n  async #getSchemaTables(getFetchProps: XataPluginOptions['getFetchProps']): Promise<Schemas.Table[]> {\n    if (this.#schemaTables) return this.#schemaTables;\n    const fetchProps = await getFetchProps();\n\n    const { schema } = await getBranchDetails({\n      pathParams: { workspace: '{workspaceId}', dbBranchName: '{dbBranch}', region: '{region}' },\n      ...fetchProps\n    });\n\n    this.#schemaTables = schema.tables;\n    return schema.tables;\n  }\n}\n\nexport type SearchXataRecord<Record extends XataRecord> = Omit<Record, 'getMetadata'> & {\n  getMetadata: () => XataRecordMetadata & SearchExtraProperties;\n};\n\ntype SearchExtraProperties = {\n  /*\n   * The record's table name. APIs that return records from multiple tables will set this field accordingly.\n   */\n  table: string;\n  /*\n   * Highlights of the record. This is used by the search APIs to indicate which fields and parts of the fields have matched the search.\n   */\n  highlight?: {\n    [key: string]:\n      | string[]\n      | {\n          [key: string]: any;\n        };\n  };\n  /*\n   * The record's relevancy score. This is returned by the search APIs.\n   */\n  score?: number;\n};\n\ntype ReturnTable<Table, Tables> = Table extends Tables ? Table : never;\n\ntype ExtractTables<\n  Schemas extends Record<string, BaseData>,\n  Tables extends StringKeys<Schemas>,\n  TableOptions extends GetArrayInnerType<NonNullable<NonNullable<SearchOptions<Schemas, Tables>>['tables']>>\n> = TableOptions extends `${infer Table}`\n  ? ReturnTable<Table, Tables>\n  : TableOptions extends { table: infer Table }\n  ? ReturnTable<Table, Tables>\n  : never;\n","export type BranchStrategyValue = string | undefined | null;\nexport type BranchStrategyBuilder = () => BranchStrategyValue | Promise<BranchStrategyValue>;\nexport type BranchStrategy = BranchStrategyValue | BranchStrategyBuilder;\nexport type BranchStrategyOption = NonNullable<BranchStrategy | BranchStrategy[]>;\n\nexport const isBranchStrategyBuilder = (strategy: BranchStrategy): strategy is BranchStrategyBuilder => {\n  return typeof strategy === 'function';\n};\n","import { getBranchDetails, parseWorkspacesUrlParts, resolveBranch } from '../api';\nimport { FetchImpl } from '../api/fetcher';\nimport { defaultTrace } from '../schema/tracing';\nimport { getAPIKey } from './apiKey';\nimport { getEnvironment, getGitBranch } from './environment';\nimport { getFetchImplementation } from './fetch';\nimport { isObject } from './lang';\n\ntype BranchResolutionOptions = {\n  databaseURL?: string;\n  apiKey?: string;\n  fetchImpl?: FetchImpl;\n};\n\nexport async function getCurrentBranchName(options?: BranchResolutionOptions): Promise<string> {\n  const { branch, envBranch } = getEnvironment();\n\n  if (branch) {\n    const details = await getDatabaseBranch(branch, options);\n    if (details) return branch;\n\n    console.warn(`Branch ${branch} not found in Xata. Ignoring...`);\n  }\n\n  const gitBranch = envBranch || (await getGitBranch());\n  return resolveXataBranch(gitBranch, options);\n}\n\nexport async function getCurrentBranchDetails(options?: BranchResolutionOptions) {\n  const branch = await getCurrentBranchName(options);\n  return getDatabaseBranch(branch, options);\n}\n\nasync function resolveXataBranch(gitBranch: string | undefined, options?: BranchResolutionOptions): Promise<string> {\n  const databaseURL = options?.databaseURL || getDatabaseURL();\n  const apiKey = options?.apiKey || getAPIKey();\n\n  if (!databaseURL)\n    throw new Error(\n      'A databaseURL was not defined. Either set the XATA_DATABASE_URL env variable or pass the argument explicitely'\n    );\n  if (!apiKey)\n    throw new Error(\n      'An API key was not defined. Either set the XATA_API_KEY env variable or pass the argument explicitely'\n    );\n\n  const [protocol, , host, , dbName] = databaseURL.split('/');\n  const urlParts = parseWorkspacesUrlParts(host);\n  if (!urlParts) throw new Error(`Unable to parse workspace and region: ${databaseURL}`);\n  const { workspace, region } = urlParts;\n\n  const { fallbackBranch } = getEnvironment();\n\n  const { branch } = await resolveBranch({\n    apiKey,\n    apiUrl: databaseURL,\n    fetchImpl: getFetchImplementation(options?.fetchImpl),\n    workspacesApiUrl: `${protocol}//${host}`,\n    pathParams: { dbName, workspace, region },\n    queryParams: { gitBranch, fallbackBranch },\n    trace: defaultTrace\n  });\n\n  return branch;\n}\n\nasync function getDatabaseBranch(branch: string, options?: BranchResolutionOptions) {\n  const databaseURL = options?.databaseURL || getDatabaseURL();\n  const apiKey = options?.apiKey || getAPIKey();\n\n  if (!databaseURL)\n    throw new Error(\n      'A databaseURL was not defined. Either set the XATA_DATABASE_URL env variable or pass the argument explicitely'\n    );\n  if (!apiKey)\n    throw new Error(\n      'An API key was not defined. Either set the XATA_API_KEY env variable or pass the argument explicitely'\n    );\n\n  const [protocol, , host, , database] = databaseURL.split('/');\n  const urlParts = parseWorkspacesUrlParts(host);\n  if (!urlParts) throw new Error(`Unable to parse workspace and region: ${databaseURL}`);\n  const { workspace, region } = urlParts;\n\n  try {\n    return await getBranchDetails({\n      apiKey,\n      apiUrl: databaseURL,\n      fetchImpl: getFetchImplementation(options?.fetchImpl),\n      workspacesApiUrl: `${protocol}//${host}`,\n      pathParams: { dbBranchName: `${database}:${branch}`, workspace, region },\n      trace: defaultTrace\n    });\n  } catch (err) {\n    if (isObject(err) && err.status === 404) return null;\n    throw err;\n  }\n}\n\nexport function getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return undefined;\n  }\n}\n","import { ApiExtraProps, Schemas } from './api';\nimport { FetcherExtraProps, FetchImpl } from './api/fetcher';\nimport { XataPlugin, XataPluginOptions } from './plugins';\nimport { BaseSchema, SchemaPlugin, SchemaPluginResult, XataRecord } from './schema';\nimport { CacheImpl, SimpleCache } from './schema/cache';\nimport { defaultTrace, TraceFunction } from './schema/tracing';\nimport { SearchPlugin, SearchPluginResult } from './search';\nimport { getAPIKey } from './util/apiKey';\nimport { BranchStrategy, BranchStrategyOption, BranchStrategyValue, isBranchStrategyBuilder } from './util/branches';\nimport { getCurrentBranchName, getDatabaseURL } from './util/config';\nimport { getFetchImplementation } from './util/fetch';\nimport { AllRequired, StringKeys } from './util/types';\nimport { generateUUID } from './util/uuid';\n\nexport type BaseClientOptions = {\n  fetch?: FetchImpl;\n  apiKey?: string;\n  databaseURL?: string;\n  branch?: BranchStrategyOption;\n  cache?: CacheImpl;\n  trace?: TraceFunction;\n};\n\ntype SafeOptions = AllRequired<Omit<BaseClientOptions, 'branch'>> & {\n  branch: () => Promise<string | undefined>;\n  clientID: string;\n};\n\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport const buildClient = <Plugins extends Record<string, XataPlugin> = {}>(plugins?: Plugins) =>\n  class {\n    #branch: BranchStrategyValue;\n    #options: SafeOptions;\n\n    db: SchemaPluginResult<any>;\n    search: SearchPluginResult<any>;\n\n    constructor(options: BaseClientOptions = {}, schemaTables?: Schemas.Table[]) {\n      const safeOptions = this.#parseOptions(options);\n      this.#options = safeOptions;\n\n      const pluginOptions: XataPluginOptions = {\n        getFetchProps: () => this.#getFetchProps(safeOptions),\n        cache: safeOptions.cache,\n        trace: safeOptions.trace\n      };\n\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n\n      // We assign the namespaces after creating in case the user overrides the db plugin\n      this.db = db;\n      this.search = search;\n\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === undefined) continue;\n        const result = namespace.build(pluginOptions);\n\n        if (result instanceof Promise) {\n          void result.then((namespace: unknown) => {\n            // @ts-ignore\n            this[key] = namespace;\n          });\n        } else {\n          // @ts-ignore\n          this[key] = result;\n        }\n      }\n    }\n\n    public async getConfig() {\n      const databaseURL = this.#options.databaseURL;\n      const branch = await this.#options.branch();\n\n      return { databaseURL, branch };\n    }\n\n    #parseOptions(options?: BaseClientOptions): SafeOptions {\n      const fetch = getFetchImplementation(options?.fetch);\n      const databaseURL = options?.databaseURL || getDatabaseURL();\n      const apiKey = options?.apiKey || getAPIKey();\n      const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n      const trace = options?.trace ?? defaultTrace;\n      const branch = async () =>\n        options?.branch !== undefined\n          ? await this.#evaluateBranch(options.branch)\n          : await getCurrentBranchName({ apiKey, databaseURL, fetchImpl: options?.fetch });\n\n      if (!apiKey) {\n        throw new Error('Option apiKey is required');\n      }\n\n      if (!databaseURL) {\n        throw new Error('Option databaseURL is required');\n      }\n\n      return { fetch, databaseURL, apiKey, branch, cache, trace, clientID: generateUUID() };\n    }\n\n    async #getFetchProps({ fetch, apiKey, databaseURL, branch, trace, clientID }: SafeOptions): Promise<ApiExtraProps> {\n      const branchValue = await this.#evaluateBranch(branch);\n      if (!branchValue) throw new Error('Unable to resolve branch value');\n\n      return {\n        fetchImpl: fetch,\n        apiKey,\n        apiUrl: '',\n        // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n        workspacesApiUrl: (path, params) => {\n          const hasBranch = params.dbBranchName ?? params.branch;\n          const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== undefined ? `:${branchValue}` : '');\n          return databaseURL + newPath;\n        },\n        trace,\n        clientID\n      };\n    }\n\n    async #evaluateBranch(param?: BranchStrategyOption): Promise<string | undefined> {\n      if (this.#branch) return this.#branch;\n      if (param === undefined) return undefined;\n\n      const strategies = Array.isArray(param) ? [...param] : [param];\n\n      const evaluateBranch = async (strategy: BranchStrategy) => {\n        return isBranchStrategyBuilder(strategy) ? await strategy() : strategy;\n      };\n\n      for await (const strategy of strategies) {\n        const branch = await evaluateBranch(strategy);\n        if (branch) {\n          this.#branch = branch;\n          return branch;\n        }\n      }\n    }\n  } as unknown as ClientConstructor<Plugins>;\n\nexport interface ClientConstructor<Plugins extends Record<string, XataPlugin>> {\n  // eslint-disable-next-line @typescript-eslint/ban-types\n  new <Schemas extends Record<string, XataRecord> = {}>(\n    options?: Partial<BaseClientOptions>,\n    schemaTables?: readonly BaseSchema[]\n  ): Omit<\n    {\n      db: Awaited<ReturnType<SchemaPlugin<Schemas>['build']>>;\n      search: Awaited<ReturnType<SearchPlugin<Schemas>['build']>>;\n    },\n    keyof Plugins\n  > & {\n    [Key in StringKeys<NonNullable<Plugins>>]: Awaited<ReturnType<NonNullable<Plugins>[Key]['build']>>;\n  } & {\n    getConfig(): Promise<{\n      databaseURL: string;\n      branch: string;\n    }>;\n  };\n}\n\nexport class BaseClient extends buildClient()<Record<string, any>> {}\n","// These will be used to set special fields to serialized objects.\n// So objects should not use this field names. I think that's fine. Another approach would be to generate two objects:\n// One containing the \"data tree\" and another containing the a tree with the type information.\nconst META = '__';\nconst VALUE = '___';\n\n// TODO: Add types for the serializer\nexport class Serializer {\n  classes: Record<string, any> = {};\n\n  add(clazz: any) {\n    this.classes[clazz.name] = clazz;\n  }\n\n  toJSON<T>(data: T): string {\n    // We are not using JSON.stringify() and the replacer function here, because the replacer receives\n    // the result of toJSON() if the object has a toJSON() method. This is a problem for the Date type:\n    // we get a string, because Date.toJSON() returns the date formatted into a ISO string alreayd,\n    // so it's not possible to guess the type of the original object.\n    function visit(obj: any): any {\n      if (Array.isArray(obj)) return obj.map(visit);\n\n      const type = typeof obj;\n      if (type === 'undefined') return { [META]: 'undefined' };\n      if (type === 'bigint') return { [META]: 'bigint', [VALUE]: obj.toString() };\n      if (obj === null || type !== 'object') return obj;\n\n      const constructor = obj.constructor;\n      const o: Record<string, any> = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date) o[VALUE] = obj.toISOString();\n      if (constructor === Map) o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set) o[VALUE] = [...obj];\n      return o;\n    }\n\n    return JSON.stringify(visit(data));\n  }\n\n  fromJSON<T>(json: string): T {\n    return JSON.parse(json, (key, value) => {\n      // eslint-disable-next-line @typescript-eslint/strict-boolean-expressions\n      if (value && typeof value === 'object' && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n\n        // eslint-disable-next-line @typescript-eslint/strict-boolean-expressions\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === 'Date') return new Date(val);\n        if (clazz === 'Set') return new Set(val);\n        if (clazz === 'Map') return new Map(Object.entries(val));\n        if (clazz === 'bigint') return BigInt(val);\n        // TODO: this is ignored. In order to support undefined we'd need to traverse the JSON tree ourselves.\n        // Instead of using the JSON.parse() reviver argument.\n        if (clazz === 'undefined') return undefined;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\n\nconst defaultSerializer = new Serializer();\n\nexport const serialize = <T>(data: T): string => {\n  return defaultSerializer.toJSON<T>(data);\n};\n\nexport const deserialize = <T>(json: string): T => {\n  return defaultSerializer.fromJSON<T>(json);\n};\n","export class XataError extends Error {\n  readonly status: number;\n\n  constructor(message: string, status: number) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport * from './api';\nexport * from './plugins';\nexport * from './client';\nexport * from './schema';\nexport * from './search';\nexport * from './serializer';\nexport * from './util/config';\nexport * from './util/apiKey';\nexport * from './workers';\n","// Generated by Xata Codegen 0.18.0. Please do not edit.\nimport { buildClient } from \"@xata.io/client\";\n/** @typedef { import('./types').SchemaTables } SchemaTables */\n/** @type { SchemaTables } */\nconst tables = [\n  {\n    name: \"users\",\n    columns: [\n      { name: \"password\", type: \"string\" },\n      { name: \"email\", type: \"email\" },\n      { name: \"username\", type: \"string\" },\n    ],\n  },\n];\n/** @type { import('@xata.io/client').ClientConstructor<{}> } */\nconst DatabaseClient = buildClient();\nconst defaultOptions = {\n  databaseURL:\n    \"https://Olufunke-Moronfolu-s-workspace-vj48pf.us-east-1.xata.sh/db/invoice-generator\",\n  apiKey: \"add your api key here\"\n\n};\n/** @typedef { import('./types').DatabaseSchema } DatabaseSchema */\n/** @extends DatabaseClient<DatabaseSchema> */\nexport class XataClient extends DatabaseClient {\n  constructor(options) {\n    super({ ...defaultOptions, ...options }, tables);\n  }\n}\nlet instance = undefined;\n/** @type { () => XataClient } */\nexport const getXataClient = () => {\n  if (instance) return instance;\n  instance = new XataClient();\n  return instance;\n};\n"],"names":["render","_vm","this","_c","_self","staticClass","on","$event","preventDefault","signIn","apply","arguments","_v","attrs","directives","name","rawName","value","email","expression","domProps","target","composing","password","staticRenderFns","data","methods","type","text","path","params","component","signUp","username","_m","webpackEmptyAsyncContext","req","Promise","resolve","then","e","Error","code","keys","id","module","exports","defaultTrace","async","_name","fn","_options","setAttributes","TraceAttributes","KIND","VERSION","TABLE","HTTP_REQUEST_ID","HTTP_STATUS_CODE","HTTP_HOST","HTTP_SCHEME","HTTP_USER_AGENT","HTTP_METHOD","HTTP_URL","HTTP_ROUTE","HTTP_TARGET","notEmpty","compact","arr","filter","isObject","Boolean","Array","isArray","isDefined","isString","isStringArray","every","isNumber","toBase64","btoa","err","buf","Buffer","from","toString","deepMerge","a","b","result","key","Object","entries","getEnvironment","process","apiKey","XATA_API_KEY","getGlobalApiKey","databaseURL","XATA_DATABASE_URL","getGlobalDatabaseURL","branch","XATA_BRANCH","getGlobalBranch","envBranch","VERCEL_GIT_COMMIT_REF","CF_PAGES_BRANCH","BRANCH","fallbackBranch","XATA_FALLBACK_BRANCH","getGlobalFallbackBranch","Deno","env","get","getGitBranch","cmd","fullCmd","join","nodeModule","execOptions","encoding","stdio","require","execSync","trim","run","stdout","stderr","TextDecoder","decode","output","getAPIKey","getFetchImplementation","userFetch","globalFetch","fetch","fetchImpl","ErrorWithCause","constructor","message","options","super","FetcherError","status","requestId","getMessage","errors","isBulkError","stack","cause","error","isErrorWithMessage","resolveUrl","url","queryParams","pathParams","cleanQueryParams","reduce","acc","query","URLSearchParams","queryString","length","cleanPathParams","encodeURIComponent","String","replace","slice","buildBaseUrl","endpoint","workspacesApiUrl","apiUrl","urlWithWorkspace","workspace","region","hostHeader","pattern","groups","exec","host","Host","method","body","headers","trace","signal","clientID","sessionID","toUpperCase","baseUrl","fullUrl","includes","response","JSON","stringify","Authorization","protocol","parseUrl","jsonResponse","json","ok","URL","dataPlaneFetch","dEPRECATEDgetDatabaseList","variables","getBranchList","dEPRECATEDcreateDatabase","dEPRECATEDdeleteDatabase","dEPRECATEDgetDatabaseMetadata","dEPRECATEDupdateDatabaseMetadata","getBranchDetails","createBranch","deleteBranch","updateBranchMetadata","getBranchMetadata","getBranchStats","getGitBranchesMapping","addGitBranchesEntry","removeGitBranchesEntry","resolveBranch","getBranchMigrationHistory","getBranchMigrationPlan","executeBranchMigrationPlan","queryMigrationRequests","createMigrationRequest","getMigrationRequest","updateMigrationRequest","listMigrationRequestsCommits","compareMigrationRequest","getMigrationRequestIsMerged","mergeMigrationRequest","getBranchSchemaHistory","compareBranchWithUserSchema","compareBranchSchemas","updateBranchSchema","previewBranchSchemaEdit","applyBranchSchemaEdit","createTable","deleteTable","updateTable","getTableSchema","setTableSchema","getTableColumns","addTableColumn","getColumn","updateColumn","deleteColumn","insertRecord","getRecord","insertRecordWithID","updateRecordWithID","upsertRecordWithID","deleteRecord","bulkInsertTableRecords","queryTable","searchBranch","searchTable","summarizeTable","aggregateTable","operationsByTag","database","migrations","migrationRequests","table","records","searchAndFilter","controlPlaneFetch","getUser","updateUser","deleteUser","getUserAPIKeys","createUserAPIKey","deleteUserAPIKey","getWorkspacesList","createWorkspace","getWorkspace","updateWorkspace","deleteWorkspace","getWorkspaceMembersList","updateWorkspaceMemberRole","removeWorkspaceMember","inviteWorkspaceMember","updateWorkspaceMemberInvite","cancelWorkspaceMemberInvite","acceptWorkspaceMemberInvite","resendWorkspaceMemberInvite","getDatabaseList","createDatabase","deleteDatabase","getDatabaseMetadata","updateDatabaseMetadata","listRegions","users","authentication","workspaces","invites","databases","controlPlaneOperations","parseWorkspacesUrlParts","regex","regexStaging","match","_extraProps","_namespaces","XataPlugin","generateUUID","c","r","Math","random","v","cleanFilter","values","Page","meta","__privateAdd","__privateSet","_query","RecordArray","size","offset","__privateGet","getPaginated","pagination","after","page","cursor","before","first","last","hasNextPage","more","PAGINATION_MAX_SIZE","PAGINATION_DEFAULT_SIZE","isCursorPaginationOptions","_RecordArray","args","parseConstructorParams","static","toArray","map","callbackfn","thisArg","newPage","_page","nextPage","previousPage","firstPage","lastPage","_Query","repository","rawParent","_table","_repository","parent","cleanParent","_data","$any","$all","$not","$none","sort","columns","cache","any","bind","all","not","none","defineProperty","enumerable","getQueryOptions","queries","constraints","column","constraint","__privateMethod","call","flat","concat","direction","originalSort","select","Symbol","asyncIterator","record","getIterator","batchSize","rest","results","console","array","getMany","summaries","summariesFilter","ttl","Query","isIdentifiable","x","isSortFilterString","isSortFilterBase","isSortFilterObject","buildSortFilter","item","_cleanFilterConstraint","cleanFilterConstraint_fn","columnType","schema","find","$includes","RestRepository","schemaTables","_db","db","pluginOptions","_schemaTables","_getFetchProps","props","getFetchProps","_trace","d","ifVersion","parseIfVersion","_bulkInsertTableRecords","_insertRecordWithId","createOnly","_insertRecordWithoutId","ids","extractId","finalObjects","getAll","dictionary","object","fetchProps","dbBranchName","tableName","recordId","_getSchemaTables","initObject","read","missingIds","_item","index","warn","update","_updateRecordWithID","createOrUpdate","_upsertRecordWithID","delete","_deleteRecord","fuzziness","prefix","highlight","boosters","aggs","cacheQuery","objects","_cache","insertRecordWithoutId_fn","transformObjectLinks","insertRecordWithId_fn","bulkInsertTableRecords_fn","isResponseWithRecords","updateRecordWithID_fn","upsertRecordWithID_fn","deleteRecord_fn","_setCacheQuery","setCacheQuery_fn","set","date","Date","_getCacheQuery","getCacheQuery_fn","defaultQueryTTL","hasExpired","getTime","now","getSchemaTables_fn","tables","selectedColumns","xata","isValidColumn","isNaN","linkTable","link","selectedLinkColumns","startsWith","split","notNull","createOrReplace","getMetadata","prop","freeze","linkColumns","arg","SimpleCache","Map","capacity","max","fromEntries","_map","leastRecentlyUsed","next","clear","SchemaPlugin","build","Proxy","_target","_tables","tableNames","SearchPlugin","_search","byTable","items","search_fn","isBranchStrategyBuilder","strategy","getCurrentBranchName","details","getDatabaseBranch","gitBranch","resolveXataBranch","getDatabaseURL","dbName","urlParts","buildClient","plugins","safeOptions","search","namespace","_evaluateBranch","branchValue","hasBranch","newPath","param","strategies","evaluateBranch","_branch","BaseClient","META","VALUE","Serializer","classes","add","clazz","toJSON","visit","obj","o","toISOString","Set","fromJSON","parse","val","assign","create","prototype","BigInt","XataError","DatabaseClient","defaultOptions","XataClient","instance","getXataClient"],"sourceRoot":""}